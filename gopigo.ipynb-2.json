{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import regularizers\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (4.1.2.30)\r\n",
      "Requirement already satisfied: numpy>=1.11.3 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from opencv-python) (1.16.2)\r\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "ws = Workspace.from_config()\n",
    "from azureml.core import Experiment\n",
    "experiment = Experiment(workspace=ws, name=\"Oct25Alex\")\n",
    "\n",
    "!{sys.executable} -m pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modeln = load_model(\"my_modelDec8_n.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X=[]\n",
    "Y=[]\n",
    "\n",
    "\n",
    "for root, dirs, files in os.walk(\"result\", topdown=True):\n",
    "    for file in files:\n",
    "        if os.path.basename(root)[-2:] != \"ta\":\n",
    "            print(root)\n",
    "            c += 1\n",
    "            #if os.path.basename(root)[-1] == \"w\": wCount += 1\n",
    "            #if wCount <= 300 and os.path.basename(root)[-1] == \"w\": continue\n",
    "            label = os.path.basename(root)[-1]\n",
    "            labelSet.add(label)\n",
    "            img = cv2.imread(os.path.join(root,file))\n",
    "            #plt.imshow(img)\n",
    "            #plt.show()\n",
    "            #img = Image.open(os.path.join(root,file))\n",
    "            \"\"\"\n",
    "       \n",
    "            hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "            lower_black = np.array([0, 0, 0])\n",
    "            upper_black = np.array([359, 100, 100])\n",
    "            mask = cv2.inRange(hsv, lower_black, upper_black)\n",
    "            \n",
    "            #edges = cv2.Canny(mask, 200, 400)\n",
    "            \n",
    "            img = region_of_interest(mask)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "            \"\"\"\n",
    "            \n",
    "            img = cv2.resize(img,(resize,resize))\n",
    "            img = np.asarray(img)\n",
    "            img = img.astype(np.float32)\n",
    "            img = (img / 127.5) - 1\n",
    "            X.append(img)\n",
    "            Y.append(label)\n",
    "            \n",
    "X = np.asarray(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['w', 'w', 'w', 'w', 'a', 'a', 'a', 'a', 'w', 'w', 'w', 'a', 'a', 'a', 'w', 'w', 'w', 'w', 'w', 'a', 'a', 'w', 'w', 'w', 'w', 'w', 'a', 'a', 'w', 'w', 'w', 'w', 'w', 'w', 'w']\n"
     ]
    }
   ],
   "source": [
    "X = np.asarray(X)\n",
    "#im = np.expand_dims(img, axis=0)\n",
    "y_prob = model3.predict(X)\n",
    "#print(y_prob[:,0])\n",
    "\n",
    "labelList = [\"a\", \"w\", \"d\"]\n",
    "\n",
    "Y_prob = []\n",
    "\n",
    "for i in range(y_prob.shape[0]):\n",
    "    row = y_prob[i, : ]\n",
    "    index = np.argmax(row)\n",
    "    label = labelList[index]\n",
    "    Y_prob.append(label)\n",
    "\n",
    "print(Y_prob)\n",
    "#print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def region_of_interest(edges):\n",
    "    height, width = edges.shape\n",
    "    mask = np.zeros_like(edges)\n",
    "\n",
    "    # only focus bottom half of the screen\n",
    "    polygon = np.array([[\n",
    "        (0, height * 1 / 2),\n",
    "        (width, height * 1 / 2),\n",
    "        (width, height),\n",
    "        (0, height),\n",
    "    ]], np.int32)\n",
    "\n",
    "    cv2.fillPoly(mask, polygon, 255)\n",
    "    cropped_edges = cv2.bitwise_and(edges, mask)\n",
    "    return cropped_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def nvidia_model():\n",
    "    model = Sequential(name='Nvidia_Model')\n",
    "    \n",
    "    # elu=Expenential Linear Unit, similar to leaky Relu\n",
    "    # skipping 1st hiddel layer (nomralization layer), as we have normalized the data\n",
    "    \n",
    "    # Convolution Layers\n",
    "    model.add(Conv2D(24, (5, 5), strides=(2, 2), input_shape=(66, 200, 3), activation='elu')) \n",
    "    model.add(Conv2D(36, (5, 5), strides=(2, 2), activation='elu')) \n",
    "    model.add(Conv2D(48, (5, 5), strides=(2, 2), activation='elu')) \n",
    "    model.add(Conv2D(64, (3, 3), activation='elu')) \n",
    "    model.add(Dropout(0.2)) # not in original model. added for more robustness\n",
    "    model.add(Conv2D(64, (3, 3), activation='elu')) \n",
    "    \n",
    "    # Fully Connected Layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.2)) # not in original model. added for more robustness\n",
    "    model.add(Dense(100, activation='elu'))\n",
    "    model.add(Dense(50, activation='elu'))\n",
    "    model.add(Dense(10, activation='elu'))\n",
    "    \n",
    "    ## output layer: turn angle (from 45-135, 90 is straight, <90 turn left, >90 turn right)\n",
    "    model.add(Dense(3))#, kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    # since this is a regression problem not classification problem,\n",
    "    # we use MSE (Mean Squared Error) as loss function\n",
    "    optimizer = Adam(lr=1e-4) # lr is learning rate\n",
    "    model.compile(loss='mse', optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def alex():\n",
    "    #Instantiate an empty model\n",
    "    model = Sequential()\n",
    "\n",
    "    # 1st Convolutional Layer\n",
    "    model.add(Conv2D(filters=96, input_shape=(227,227,3), kernel_size=(11,11), strides=(4,4), padding='valid'))#, kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Activation('relu'))\n",
    "    # Max Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "\n",
    "    # 2nd Convolutional Layer\n",
    "    model.add(Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='same'))#, kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Activation('relu'))\n",
    "    # Max Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "\n",
    "    # 3rd Convolutional Layer\n",
    "    model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))#, kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # 4th Convolutional Layer\n",
    "    model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))#, kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # 5th Convolutional Layer\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))#, kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Activation('relu'))\n",
    "    # Max Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "    # Passing it to a Fully Connected layer\n",
    "    model.add(Flatten())\n",
    "    # 1st Fully Connected Layer\n",
    "    model.add(Dense(4096, input_shape=(227*227*3,)))#, kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Activation('relu'))\n",
    "    # Add Dropout to prevent overfitting\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # 2nd Fully Connected Layer\n",
    "    model.add(Dense(4096))#, kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Activation('relu'))\n",
    "    # Add Dropout\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # 3rd Fully Connected Layer\n",
    "    model.add(Dense(1000))#, kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(Dense(3))#, kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    # Compile the model\n",
    "    opt = Adadelta(learning_rate = 0.005, rho = 0.97)\n",
    "    model.compile(loss=keras.losses.mean_squared_error, optimizer=opt, metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def leNet():\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    model.add(Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(32,32,1)))\n",
    "    model.add(AveragePooling2D())\n",
    "\n",
    "    model.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(AveragePooling2D())\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(units=120, activation='relu'))\n",
    "\n",
    "    model.add(Dense(units=84, activation='relu'))\n",
    "\n",
    "    model.add(Dense(units=43, activation = 'softmax'))\n",
    "    \n",
    "    optimizer = Adam(lr=1e-3) # lr is learning rate\n",
    "    model.compile(loss='mse', optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "lines_to_next_cell": 2,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "600\n",
      "900\n",
      "1200\n",
      "1500\n",
      "1800\n",
      "2100\n",
      "2400\n",
      "2700\n",
      "3000\n",
      "3300\n",
      "3600\n",
      "3900\n",
      "4200\n",
      "4500\n",
      "4800\n",
      "5100\n",
      "5400\n",
      "5700\n",
      "6000\n",
      "6300\n",
      "6600\n",
      "6900\n",
      "7200\n",
      "7500\n",
      "7800\n",
      "8100\n",
      "8400\n",
      "8700\n",
      "9000\n",
      "9300\n",
      "9600\n",
      "9900\n",
      "10200\n",
      "10500\n",
      "10800\n",
      "11100\n",
      "11400\n",
      "11700\n",
      "12000\n",
      "12300\n",
      "12600\n",
      "12900\n",
      "13200\n",
      "13500\n",
      "13800\n",
      "14100\n",
      "14400\n",
      "14700\n",
      "15000\n",
      "15300\n",
      "15600\n",
      "15900\n",
      "16200\n",
      "16500\n",
      "16800\n",
      "17100\n",
      "17400\n",
      "17700\n",
      "18000\n",
      "18300\n",
      "18600\n",
      "18900\n",
      "19200\n",
      "19500\n",
      "19800\n",
      "20100\n",
      "20400\n",
      "20700\n",
      "21000\n",
      "21300\n",
      "21600\n",
      "21900\n",
      "22200\n",
      "22500\n",
      "22800\n",
      "23100\n",
      "23400\n",
      "23700\n",
      "24000\n",
      "24300\n",
      "24600\n",
      "24900\n",
      "25200\n",
      "25500\n",
      "25800\n",
      "26100\n",
      "26400\n",
      "26700\n",
      "27000\n",
      "27300\n",
      "27600\n",
      "27900\n",
      "28200\n",
      "28500\n",
      "28800\n",
      "29100\n",
      "29400\n",
      "29700\n",
      "30000\n",
      "30300\n",
      "30600\n",
      "30900\n",
      "31200\n",
      "31500\n",
      "31800\n",
      "32100\n",
      "32400\n",
      "32700\n",
      "33000\n",
      "33300\n",
      "33600\n",
      "33900\n",
      "34200\n",
      "34500\n",
      "34800\n",
      "35100\n",
      "35400\n",
      "35700\n",
      "36000\n",
      "36300\n",
      "36600\n",
      "36900\n",
      "37200\n",
      "37500\n",
      "37800\n",
      "38100\n",
      "38400\n",
      "38700\n",
      "39000\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1000)\n",
    "trainPercent = 0.75\n",
    "X = []\n",
    "Y = []\n",
    "resize = 227\n",
    "labelSet = set()\n",
    "count=0\n",
    "wCount = 0\n",
    "c=0\n",
    "\n",
    "nvidia_size = (200,66)\n",
    "alex_size = (227,227)\n",
    "le_size = (32,32)\n",
    "\n",
    "for root, dirs, files in os.walk(\"Images\", topdown=True):\n",
    "    #if c>100: break\n",
    "    for file in files:\n",
    "        c += 1\n",
    "        if not c%3==0: continue\n",
    "        if os.path.basename(root)[-5] == \"0\" and file[-3:] == \"ppm\":\n",
    "            if c%300==0: print(c)\n",
    "            #if os.path.basename(root)[-1] == \"w\": wCount += 1\n",
    "            #if os.path.basename(root)[-1] in \"aw\": continue\n",
    "            label = int(os.path.basename(root)[-2:])\n",
    "            #print(label)\n",
    "            labelSet.add(label)\n",
    "            img = cv2.imread(os.path.join(root,file))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            #img = Image.open(os.path.join(root,file))\n",
    "            \"\"\"\n",
    "            hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "            lower_black = np.array([0, 0, 0])\n",
    "            upper_black = np.array([359, 100, 70])\n",
    "            mask = cv2.inRange(hsv, lower_black, upper_black)\n",
    "            #edges = cv2.Canny(mask, 200, 400)\n",
    "            img = region_of_interest(mask)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "            \"\"\"\n",
    "            \n",
    "            #plt.imshow(img)\n",
    "            #plt.show()\n",
    "            \n",
    "    #        break\n",
    "    #if c==10: break\n",
    "            \n",
    "\n",
    "            \"\"\" #Flip track images for data augmentation:\n",
    "            \n",
    "            if label == \"a\":\n",
    "                mirror = cv2.flip(img, 1)\n",
    "                mirror = cv2.resize(mirror,(200, 66))\n",
    "                mirror = np.asarray(mirror)\n",
    "                mirror = mirror.astype(np.float32)\n",
    "                mirror = (mirror / 127.5) - 1\n",
    "                X.append(mirror)\n",
    "                Y.append(\"d\")\n",
    "            if label == \"d\":\n",
    "                mirror = cv2.flip(img, 1)\n",
    "                mirror = cv2.resize(mirror,(200, 66))\n",
    "                mirror = np.asarray(mirror)\n",
    "                mirror = mirror.astype(np.float32)\n",
    "                mirror = (mirror / 127.5) - 1\n",
    "                X.append(mirror)\n",
    "                Y.append(\"a\")\n",
    "            \"\"\"\n",
    "            \n",
    "            img = cv2.resize(img, le_size)\n",
    "            img = np.expand_dims(img, axis = 2)\n",
    "            img = np.asarray(img)\n",
    "            img = img.astype(np.float32)\n",
    "            img = (img / 127.5) - 1\n",
    "            X.append(img)\n",
    "            Y.append(label)\n",
    "\n",
    "#print(labelSet)\n",
    "labelList = list(labelSet)\n",
    "labelList.sort()\n",
    "#print(labelList)\n",
    "#labelList = [\"a\", \"w\", \"d\"]\n",
    "\n",
    "for i in range(len(Y)):\n",
    "   #This is not one-hot\n",
    "   l = [0]*len(labelList)\n",
    "   index = labelList.index(Y[i])\n",
    "   l[index] = 1\n",
    "   Y[i] = l\n",
    "\n",
    "\n",
    "X = np.asarray(X)\n",
    "Y = np.asarray(Y)\n",
    "\n",
    "p = np.random.permutation(X.shape[0])\n",
    "X = X[p]\n",
    "Y = Y[p]\n",
    "\n",
    "print(Y)\n",
    "print(labelList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 1)\n",
      "(32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "np.save(\"X.npy\", X)\n",
    "np.save(\"Y.npy\", Y)\n",
    "\n",
    "X_mean = np.mean(X, axis=0)\n",
    "X_std = np.std(X, axis=0)\n",
    "\n",
    "print(X_mean.shape)\n",
    "print(X_std.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13070, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "X_modified = (X-X_mean)/X_std\n",
    "\n",
    "np.save(\"X_modified.npy\",X_modified)\n",
    "print(X_modified.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = X_modified[2,:,:,:]\n",
    "i = np.squeeze(i, axis = 2)\n",
    "i = (i+1)*127.5\n",
    "plt.imshow(i)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainPercent = 0.9\n",
    "\n",
    "X_train = X_modified[:int(X.shape[0]*trainPercent),:,:,:]\n",
    "X_test = X_modified[int(X.shape[0]*trainPercent):,:,:,:]\n",
    "Y_train = Y[:int(Y.shape[0]*trainPercent),:]\n",
    "Y_test = Y[int(Y.shape[0]*trainPercent):,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "lines_to_next_cell": 0,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_28 (Conv2D)           (None, 30, 30, 6)         60        \n",
      "_________________________________________________________________\n",
      "average_pooling2d_21 (Averag (None, 15, 15, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 13, 13, 16)        880       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_22 (Averag (None, 6, 6, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 120)               69240     \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 43)                3655      \n",
      "=================================================================\n",
      "Total params: 83,999\n",
      "Trainable params: 83,999\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      " - 1s - loss: 0.0204 - accuracy: 0.2258\n",
      "Epoch 2/1000\n",
      " - 1s - loss: 0.0131 - accuracy: 0.5725\n",
      "Epoch 3/1000\n",
      " - 1s - loss: 0.0089 - accuracy: 0.7291\n",
      "Epoch 4/1000\n",
      " - 1s - loss: 0.0069 - accuracy: 0.7970\n",
      "Epoch 5/1000\n",
      " - 1s - loss: 0.0059 - accuracy: 0.8301\n",
      "Epoch 6/1000\n",
      " - 1s - loss: 0.0052 - accuracy: 0.8489\n",
      "Epoch 7/1000\n",
      " - 1s - loss: 0.0047 - accuracy: 0.8652\n",
      "Epoch 8/1000\n",
      " - 1s - loss: 0.0043 - accuracy: 0.8779\n",
      "Epoch 9/1000\n",
      " - 1s - loss: 0.0041 - accuracy: 0.8796\n",
      "Epoch 10/1000\n",
      " - 1s - loss: 0.0039 - accuracy: 0.8875\n",
      "Epoch 11/1000\n",
      " - 1s - loss: 0.0038 - accuracy: 0.8908\n",
      "Epoch 12/1000\n",
      " - 1s - loss: 0.0036 - accuracy: 0.8938\n",
      "Epoch 13/1000\n",
      " - 1s - loss: 0.0034 - accuracy: 0.8977\n",
      "Epoch 14/1000\n",
      " - 1s - loss: 0.0033 - accuracy: 0.9025\n",
      "Epoch 15/1000\n",
      " - 1s - loss: 0.0032 - accuracy: 0.9029\n",
      "Epoch 16/1000\n",
      " - 1s - loss: 0.0030 - accuracy: 0.9075\n",
      "Epoch 17/1000\n",
      " - 1s - loss: 0.0029 - accuracy: 0.9116\n",
      "Epoch 18/1000\n",
      " - 1s - loss: 0.0028 - accuracy: 0.9139\n",
      "Epoch 19/1000\n",
      " - 1s - loss: 0.0028 - accuracy: 0.9123\n",
      "Epoch 20/1000\n",
      " - 1s - loss: 0.0025 - accuracy: 0.9236\n",
      "Epoch 21/1000\n",
      " - 1s - loss: 0.0024 - accuracy: 0.9253\n",
      "Epoch 22/1000\n",
      " - 1s - loss: 0.0024 - accuracy: 0.9264\n",
      "Epoch 23/1000\n",
      " - 1s - loss: 0.0022 - accuracy: 0.9307\n",
      "Epoch 24/1000\n",
      " - 1s - loss: 0.0020 - accuracy: 0.9395\n",
      "Epoch 25/1000\n",
      " - 1s - loss: 0.0018 - accuracy: 0.9440\n",
      "Epoch 26/1000\n",
      " - 1s - loss: 0.0018 - accuracy: 0.9456\n",
      "Epoch 27/1000\n",
      " - 1s - loss: 0.0017 - accuracy: 0.9489\n",
      "Epoch 28/1000\n",
      " - 1s - loss: 0.0018 - accuracy: 0.9452\n",
      "Epoch 29/1000\n",
      " - 1s - loss: 0.0017 - accuracy: 0.9477\n",
      "Epoch 30/1000\n",
      " - 1s - loss: 0.0016 - accuracy: 0.9514\n",
      "Epoch 31/1000\n",
      " - 1s - loss: 0.0016 - accuracy: 0.9505\n",
      "Epoch 32/1000\n",
      " - 1s - loss: 0.0015 - accuracy: 0.9550\n",
      "Epoch 33/1000\n",
      " - 1s - loss: 0.0014 - accuracy: 0.9567\n",
      "Epoch 34/1000\n",
      " - 1s - loss: 0.0013 - accuracy: 0.9590\n",
      "Epoch 35/1000\n",
      " - 1s - loss: 0.0012 - accuracy: 0.9613\n",
      "Epoch 36/1000\n",
      " - 1s - loss: 0.0013 - accuracy: 0.9583\n",
      "Epoch 37/1000\n",
      " - 1s - loss: 0.0011 - accuracy: 0.9646\n",
      "Epoch 38/1000\n",
      " - 1s - loss: 0.0012 - accuracy: 0.9614\n",
      "Epoch 39/1000\n",
      " - 1s - loss: 0.0013 - accuracy: 0.9593\n",
      "Epoch 40/1000\n",
      " - 1s - loss: 0.0012 - accuracy: 0.9627\n",
      "Epoch 41/1000\n",
      " - 1s - loss: 0.0011 - accuracy: 0.9635\n",
      "Epoch 42/1000\n",
      " - 1s - loss: 0.0011 - accuracy: 0.9624\n",
      "Epoch 43/1000\n",
      " - 1s - loss: 0.0011 - accuracy: 0.9621\n",
      "Epoch 44/1000\n",
      " - 1s - loss: 0.0010 - accuracy: 0.9649\n",
      "Epoch 45/1000\n",
      " - 1s - loss: 0.0012 - accuracy: 0.9611\n",
      "Epoch 46/1000\n",
      " - 1s - loss: 0.0013 - accuracy: 0.9612\n",
      "Epoch 47/1000\n",
      " - 1s - loss: 9.0885e-04 - accuracy: 0.9697\n",
      "Epoch 48/1000\n",
      " - 1s - loss: 8.4797e-04 - accuracy: 0.9715\n",
      "Epoch 49/1000\n",
      " - 1s - loss: 0.0011 - accuracy: 0.9648\n",
      "Epoch 50/1000\n",
      " - 1s - loss: 0.0010 - accuracy: 0.9665\n",
      "Epoch 51/1000\n",
      " - 1s - loss: 8.1660e-04 - accuracy: 0.9722\n",
      "Epoch 52/1000\n",
      " - 1s - loss: 7.7635e-04 - accuracy: 0.9726\n",
      "Epoch 53/1000\n",
      " - 1s - loss: 7.7241e-04 - accuracy: 0.9728\n",
      "Epoch 54/1000\n",
      " - 1s - loss: 7.8728e-04 - accuracy: 0.9724\n",
      "Epoch 55/1000\n",
      " - 1s - loss: 8.4847e-04 - accuracy: 0.9709\n",
      "Epoch 56/1000\n",
      " - 1s - loss: 0.0012 - accuracy: 0.9634\n",
      "Epoch 57/1000\n",
      " - 1s - loss: 0.0010 - accuracy: 0.9662\n",
      "Epoch 58/1000\n",
      " - 1s - loss: 9.5939e-04 - accuracy: 0.9682\n",
      "Epoch 59/1000\n",
      " - 1s - loss: 8.0725e-04 - accuracy: 0.9725\n",
      "Epoch 60/1000\n",
      " - 1s - loss: 8.0830e-04 - accuracy: 0.9717\n",
      "Epoch 61/1000\n",
      " - 1s - loss: 6.3717e-04 - accuracy: 0.9788\n",
      "Epoch 62/1000\n",
      " - 1s - loss: 5.8517e-04 - accuracy: 0.9806\n",
      "Epoch 63/1000\n",
      " - 1s - loss: 6.3950e-04 - accuracy: 0.9791\n",
      "Epoch 64/1000\n",
      " - 1s - loss: 6.5723e-04 - accuracy: 0.9786\n",
      "Epoch 65/1000\n",
      " - 1s - loss: 6.6093e-04 - accuracy: 0.9784\n",
      "Epoch 66/1000\n",
      " - 1s - loss: 6.8893e-04 - accuracy: 0.9782\n",
      "Epoch 67/1000\n",
      " - 1s - loss: 7.0405e-04 - accuracy: 0.9772\n",
      "Epoch 68/1000\n",
      " - 1s - loss: 7.0364e-04 - accuracy: 0.9777\n",
      "Epoch 69/1000\n",
      " - 1s - loss: 6.7658e-04 - accuracy: 0.9780\n",
      "Epoch 70/1000\n",
      " - 1s - loss: 6.5368e-04 - accuracy: 0.9788\n",
      "Epoch 71/1000\n",
      " - 1s - loss: 5.5587e-04 - accuracy: 0.9810\n",
      "Epoch 72/1000\n",
      " - 1s - loss: 5.5091e-04 - accuracy: 0.9815\n",
      "Epoch 73/1000\n",
      " - 1s - loss: 4.3457e-04 - accuracy: 0.9861\n",
      "Epoch 74/1000\n",
      " - 1s - loss: 4.4781e-04 - accuracy: 0.9854\n",
      "Epoch 75/1000\n",
      " - 1s - loss: 4.9520e-04 - accuracy: 0.9849\n",
      "Epoch 76/1000\n",
      " - 1s - loss: 6.6656e-04 - accuracy: 0.9802\n",
      "Epoch 77/1000\n",
      " - 1s - loss: 4.6983e-04 - accuracy: 0.9851\n",
      "Epoch 78/1000\n",
      " - 1s - loss: 5.0603e-04 - accuracy: 0.9852\n",
      "Epoch 79/1000\n",
      " - 1s - loss: 2.7372e-04 - accuracy: 0.9933\n",
      "Epoch 80/1000\n",
      " - 1s - loss: 2.1562e-04 - accuracy: 0.9940\n",
      "Epoch 81/1000\n",
      " - 1s - loss: 1.4601e-04 - accuracy: 0.9958\n",
      "Epoch 82/1000\n",
      " - 1s - loss: 1.3740e-04 - accuracy: 0.9963\n",
      "Epoch 83/1000\n",
      " - 1s - loss: 2.4666e-04 - accuracy: 0.9932\n",
      "Epoch 84/1000\n",
      " - 1s - loss: 2.6841e-04 - accuracy: 0.9928\n",
      "Epoch 85/1000\n",
      " - 1s - loss: 2.2065e-04 - accuracy: 0.9944\n",
      "Epoch 86/1000\n",
      " - 1s - loss: 2.4540e-04 - accuracy: 0.9935\n",
      "Epoch 87/1000\n",
      " - 1s - loss: 2.8168e-04 - accuracy: 0.9924\n",
      "Epoch 88/1000\n",
      " - 1s - loss: 2.0979e-04 - accuracy: 0.9941\n",
      "Epoch 89/1000\n",
      " - 1s - loss: 1.3275e-04 - accuracy: 0.9963\n",
      "Epoch 90/1000\n",
      " - 1s - loss: 1.1372e-04 - accuracy: 0.9968\n",
      "Epoch 91/1000\n",
      " - 1s - loss: 1.0463e-04 - accuracy: 0.9969\n",
      "Epoch 92/1000\n",
      " - 1s - loss: 1.0456e-04 - accuracy: 0.9969\n",
      "Epoch 93/1000\n",
      " - 1s - loss: 1.0930e-04 - accuracy: 0.9969\n",
      "Epoch 94/1000\n",
      " - 1s - loss: 9.7153e-05 - accuracy: 0.9969\n",
      "Epoch 95/1000\n",
      " - 1s - loss: 1.0165e-04 - accuracy: 0.9969\n",
      "Epoch 96/1000\n",
      " - 1s - loss: 1.0664e-04 - accuracy: 0.9969\n",
      "Epoch 97/1000\n",
      " - 1s - loss: 4.0660e-04 - accuracy: 0.9886\n",
      "Epoch 98/1000\n",
      " - 1s - loss: 4.8915e-04 - accuracy: 0.9863\n",
      "Epoch 99/1000\n",
      " - 1s - loss: 3.9742e-04 - accuracy: 0.9887\n",
      "Epoch 100/1000\n",
      " - 1s - loss: 2.5688e-04 - accuracy: 0.9930\n",
      "Epoch 101/1000\n",
      " - 1s - loss: 1.8209e-04 - accuracy: 0.9952\n",
      "Epoch 102/1000\n",
      " - 1s - loss: 1.3606e-04 - accuracy: 0.9963\n",
      "Epoch 103/1000\n",
      " - 1s - loss: 1.1139e-04 - accuracy: 0.9970\n",
      "Epoch 104/1000\n",
      " - 1s - loss: 1.0095e-04 - accuracy: 0.9970\n",
      "Epoch 105/1000\n",
      " - 1s - loss: 9.7481e-05 - accuracy: 0.9970\n",
      "Epoch 106/1000\n",
      " - 1s - loss: 1.0225e-04 - accuracy: 0.9969\n",
      "Epoch 107/1000\n",
      " - 1s - loss: 9.5516e-05 - accuracy: 0.9971\n",
      "Epoch 108/1000\n",
      " - 1s - loss: 1.0079e-04 - accuracy: 0.9971\n",
      "Epoch 109/1000\n",
      " - 1s - loss: 4.9876e-04 - accuracy: 0.9858\n",
      "Epoch 110/1000\n",
      " - 1s - loss: 2.9825e-04 - accuracy: 0.9919\n",
      "Epoch 111/1000\n",
      " - 1s - loss: 1.7677e-04 - accuracy: 0.9949\n",
      "Epoch 112/1000\n",
      " - 1s - loss: 2.2449e-04 - accuracy: 0.9934\n",
      "Epoch 113/1000\n",
      " - 1s - loss: 9.9139e-05 - accuracy: 0.9970\n",
      "Epoch 114/1000\n",
      " - 1s - loss: 8.9930e-05 - accuracy: 0.9972\n",
      "Epoch 115/1000\n",
      " - 1s - loss: 8.5699e-05 - accuracy: 0.9973\n",
      "Epoch 116/1000\n",
      " - 1s - loss: 8.4362e-05 - accuracy: 0.9973\n",
      "Epoch 117/1000\n",
      " - 1s - loss: 8.7731e-05 - accuracy: 0.9973\n",
      "Epoch 118/1000\n",
      " - 1s - loss: 8.3332e-05 - accuracy: 0.9973\n",
      "Epoch 119/1000\n",
      " - 1s - loss: 8.0959e-05 - accuracy: 0.9973\n",
      "Epoch 120/1000\n",
      " - 1s - loss: 8.2472e-05 - accuracy: 0.9973\n",
      "Epoch 121/1000\n",
      " - 1s - loss: 8.4160e-05 - accuracy: 0.9972\n",
      "Epoch 122/1000\n",
      " - 1s - loss: 4.8897e-04 - accuracy: 0.9864\n",
      "Epoch 123/1000\n",
      " - 1s - loss: 5.0427e-04 - accuracy: 0.9863\n",
      "Epoch 124/1000\n",
      " - 1s - loss: 3.0920e-04 - accuracy: 0.9916\n",
      "Epoch 125/1000\n",
      " - 1s - loss: 2.4862e-04 - accuracy: 0.9930\n",
      "Epoch 126/1000\n",
      " - 1s - loss: 1.4547e-04 - accuracy: 0.9960\n",
      "Epoch 127/1000\n",
      " - 1s - loss: 1.6724e-04 - accuracy: 0.9952\n",
      "Epoch 128/1000\n",
      " - 1s - loss: 1.5097e-04 - accuracy: 0.9958\n",
      "Epoch 129/1000\n",
      " - 1s - loss: 8.6383e-05 - accuracy: 0.9973\n",
      "Epoch 130/1000\n",
      " - 1s - loss: 7.7828e-05 - accuracy: 0.9974\n",
      "Epoch 131/1000\n",
      " - 1s - loss: 7.8688e-05 - accuracy: 0.9974\n",
      "Epoch 132/1000\n",
      " - 1s - loss: 7.9097e-05 - accuracy: 0.9974\n",
      "Epoch 133/1000\n",
      " - 1s - loss: 7.5689e-05 - accuracy: 0.9975\n",
      "Epoch 134/1000\n",
      " - 1s - loss: 7.5405e-05 - accuracy: 0.9975\n",
      "Epoch 135/1000\n",
      " - 1s - loss: 7.3333e-05 - accuracy: 0.9975\n",
      "Epoch 136/1000\n",
      " - 1s - loss: 7.3663e-05 - accuracy: 0.9975\n",
      "Epoch 137/1000\n",
      " - 1s - loss: 7.8272e-05 - accuracy: 0.9976\n",
      "Epoch 138/1000\n",
      " - 1s - loss: 7.4304e-05 - accuracy: 0.9976\n",
      "Epoch 139/1000\n",
      " - 1s - loss: 7.2583e-05 - accuracy: 0.9976\n",
      "Epoch 140/1000\n",
      " - 1s - loss: 8.4030e-05 - accuracy: 0.9974\n",
      "Epoch 141/1000\n",
      " - 1s - loss: 7.3225e-04 - accuracy: 0.9793\n",
      "Epoch 142/1000\n",
      " - 1s - loss: 2.6306e-04 - accuracy: 0.9933\n",
      "Epoch 143/1000\n",
      " - 1s - loss: 1.5647e-04 - accuracy: 0.9957\n",
      "Epoch 144/1000\n",
      " - 1s - loss: 1.1864e-04 - accuracy: 0.9964\n",
      "Epoch 145/1000\n",
      " - 1s - loss: 9.7973e-05 - accuracy: 0.9970\n",
      "Epoch 146/1000\n",
      " - 1s - loss: 9.9611e-05 - accuracy: 0.9970\n",
      "Epoch 147/1000\n",
      " - 1s - loss: 9.3704e-05 - accuracy: 0.9973\n",
      "Epoch 148/1000\n",
      " - 1s - loss: 8.7061e-05 - accuracy: 0.9975\n",
      "Epoch 149/1000\n",
      " - 1s - loss: 2.4305e-04 - accuracy: 0.9929\n",
      "Epoch 150/1000\n",
      " - 1s - loss: 1.7574e-04 - accuracy: 0.9952\n",
      "Epoch 151/1000\n",
      " - 1s - loss: 9.0829e-05 - accuracy: 0.9974\n",
      "Epoch 152/1000\n",
      " - 1s - loss: 7.4144e-05 - accuracy: 0.9976\n",
      "Epoch 153/1000\n",
      " - 1s - loss: 9.2066e-05 - accuracy: 0.9973\n",
      "Epoch 154/1000\n",
      " - 1s - loss: 1.8746e-04 - accuracy: 0.9942\n",
      "Epoch 155/1000\n",
      " - 1s - loss: 2.2567e-04 - accuracy: 0.9934\n",
      "Epoch 156/1000\n",
      " - 1s - loss: 1.8566e-04 - accuracy: 0.9946\n",
      "Epoch 157/1000\n",
      " - 1s - loss: 9.1940e-05 - accuracy: 0.9974\n",
      "Epoch 158/1000\n",
      " - 1s - loss: 7.6800e-05 - accuracy: 0.9978\n",
      "Epoch 159/1000\n",
      " - 1s - loss: 7.1903e-05 - accuracy: 0.9978\n",
      "Epoch 160/1000\n",
      " - 1s - loss: 6.8617e-05 - accuracy: 0.9978\n",
      "Epoch 161/1000\n",
      " - 1s - loss: 6.9766e-05 - accuracy: 0.9978\n",
      "Epoch 162/1000\n",
      " - 1s - loss: 7.2537e-05 - accuracy: 0.9978\n",
      "Epoch 163/1000\n",
      " - 1s - loss: 7.1625e-05 - accuracy: 0.9978\n",
      "Epoch 164/1000\n",
      " - 1s - loss: 6.9695e-05 - accuracy: 0.9978\n",
      "Epoch 165/1000\n",
      " - 1s - loss: 6.8718e-05 - accuracy: 0.9978\n",
      "Epoch 166/1000\n",
      " - 1s - loss: 7.0330e-05 - accuracy: 0.9978\n",
      "Epoch 167/1000\n",
      " - 1s - loss: 6.9597e-05 - accuracy: 0.9978\n",
      "Epoch 168/1000\n",
      " - 1s - loss: 6.8600e-05 - accuracy: 0.9978\n",
      "Epoch 169/1000\n",
      " - 1s - loss: 5.3696e-04 - accuracy: 0.9856\n",
      "Epoch 170/1000\n",
      " - 1s - loss: 4.6025e-04 - accuracy: 0.9870\n",
      "Epoch 171/1000\n",
      " - 1s - loss: 1.8840e-04 - accuracy: 0.9948\n",
      "Epoch 172/1000\n",
      " - 1s - loss: 1.3857e-04 - accuracy: 0.9960\n",
      "Epoch 173/1000\n",
      " - 1s - loss: 7.7573e-05 - accuracy: 0.9976\n",
      "Epoch 174/1000\n",
      " - 1s - loss: 6.8727e-05 - accuracy: 0.9977\n",
      "Epoch 175/1000\n",
      " - 1s - loss: 6.7112e-05 - accuracy: 0.9978\n",
      "Epoch 176/1000\n",
      " - 1s - loss: 6.4671e-05 - accuracy: 0.9978\n",
      "Epoch 177/1000\n",
      " - 1s - loss: 6.3729e-05 - accuracy: 0.9978\n",
      "Epoch 178/1000\n",
      " - 1s - loss: 6.4531e-05 - accuracy: 0.9978\n",
      "Epoch 179/1000\n",
      " - 1s - loss: 6.2924e-05 - accuracy: 0.9978\n",
      "Epoch 180/1000\n",
      " - 1s - loss: 6.2466e-05 - accuracy: 0.9978\n",
      "Epoch 181/1000\n",
      " - 1s - loss: 6.2247e-05 - accuracy: 0.9978\n",
      "Epoch 182/1000\n",
      " - 1s - loss: 6.2119e-05 - accuracy: 0.9978\n",
      "Epoch 183/1000\n",
      " - 1s - loss: 6.2550e-05 - accuracy: 0.9979\n",
      "Epoch 184/1000\n",
      " - 1s - loss: 1.7454e-04 - accuracy: 0.9951\n",
      "Epoch 185/1000\n",
      " - 1s - loss: 6.0418e-04 - accuracy: 0.9831\n",
      "Epoch 186/1000\n",
      " - 1s - loss: 2.8058e-04 - accuracy: 0.9923\n",
      "Epoch 187/1000\n",
      " - 1s - loss: 1.3181e-04 - accuracy: 0.9963\n",
      "Epoch 188/1000\n",
      " - 1s - loss: 1.0929e-04 - accuracy: 0.9969\n",
      "Epoch 189/1000\n",
      " - 1s - loss: 7.3931e-05 - accuracy: 0.9979\n",
      "Epoch 190/1000\n",
      " - 1s - loss: 6.5706e-05 - accuracy: 0.9980\n",
      "Epoch 191/1000\n",
      " - 1s - loss: 6.3338e-05 - accuracy: 0.9980\n",
      "Epoch 192/1000\n",
      " - 1s - loss: 6.1611e-05 - accuracy: 0.9980\n",
      "Epoch 193/1000\n",
      " - 1s - loss: 6.1526e-05 - accuracy: 0.9980\n",
      "Epoch 194/1000\n",
      " - 1s - loss: 5.9905e-05 - accuracy: 0.9980\n",
      "Epoch 195/1000\n",
      " - 1s - loss: 5.9166e-05 - accuracy: 0.9980\n",
      "Epoch 196/1000\n",
      " - 1s - loss: 6.0594e-05 - accuracy: 0.9980\n",
      "Epoch 197/1000\n",
      " - 1s - loss: 5.9148e-05 - accuracy: 0.9980\n",
      "Epoch 198/1000\n",
      " - 1s - loss: 5.6490e-05 - accuracy: 0.9980\n",
      "Epoch 199/1000\n",
      " - 1s - loss: 5.9006e-05 - accuracy: 0.9981\n",
      "Epoch 200/1000\n",
      " - 1s - loss: 6.2747e-05 - accuracy: 0.9982\n",
      "Epoch 201/1000\n",
      " - 1s - loss: 3.0658e-04 - accuracy: 0.9915\n",
      "Epoch 202/1000\n",
      " - 1s - loss: 2.3985e-04 - accuracy: 0.9937\n",
      "Epoch 203/1000\n",
      " - 1s - loss: 2.0267e-04 - accuracy: 0.9944\n",
      "Epoch 204/1000\n",
      " - 1s - loss: 9.5611e-05 - accuracy: 0.9971\n",
      "Epoch 205/1000\n",
      " - 1s - loss: 6.9923e-05 - accuracy: 0.9979\n",
      "Epoch 206/1000\n",
      " - 1s - loss: 5.8059e-05 - accuracy: 0.9982\n",
      "Epoch 207/1000\n",
      " - 1s - loss: 5.3378e-05 - accuracy: 0.9982\n",
      "Epoch 208/1000\n",
      " - 1s - loss: 5.3996e-05 - accuracy: 0.9982\n",
      "Epoch 209/1000\n",
      " - 1s - loss: 5.3536e-05 - accuracy: 0.9982\n",
      "Epoch 210/1000\n",
      " - 1s - loss: 5.3854e-05 - accuracy: 0.9982\n",
      "Epoch 211/1000\n",
      " - 1s - loss: 5.3794e-05 - accuracy: 0.9982\n",
      "Epoch 212/1000\n",
      " - 1s - loss: 5.2179e-05 - accuracy: 0.9982\n",
      "Epoch 213/1000\n",
      " - 1s - loss: 5.2695e-05 - accuracy: 0.9982\n",
      "Epoch 214/1000\n",
      " - 1s - loss: 5.1755e-05 - accuracy: 0.9982\n",
      "Epoch 215/1000\n",
      " - 1s - loss: 5.2296e-05 - accuracy: 0.9982\n",
      "Epoch 216/1000\n",
      " - 1s - loss: 5.2484e-05 - accuracy: 0.9982\n",
      "Epoch 217/1000\n",
      " - 1s - loss: 5.2429e-05 - accuracy: 0.9982\n",
      "Epoch 218/1000\n",
      " - 1s - loss: 5.2799e-05 - accuracy: 0.9982\n",
      "Epoch 219/1000\n",
      " - 1s - loss: 2.9058e-04 - accuracy: 0.9923\n",
      "Epoch 220/1000\n",
      " - 1s - loss: 5.2532e-04 - accuracy: 0.9855\n",
      "Epoch 221/1000\n",
      " - 1s - loss: 1.8336e-04 - accuracy: 0.9947\n",
      "Epoch 222/1000\n",
      " - 1s - loss: 1.2521e-04 - accuracy: 0.9965\n",
      "Epoch 223/1000\n",
      " - 1s - loss: 7.9057e-05 - accuracy: 0.9976\n",
      "Epoch 224/1000\n",
      " - 1s - loss: 7.0304e-05 - accuracy: 0.9979\n",
      "Epoch 225/1000\n",
      " - 1s - loss: 5.7382e-05 - accuracy: 0.9980\n",
      "Epoch 226/1000\n",
      " - 1s - loss: 5.3477e-05 - accuracy: 0.9982\n",
      "Epoch 227/1000\n",
      " - 1s - loss: 5.3079e-05 - accuracy: 0.9982\n",
      "Epoch 228/1000\n",
      " - 1s - loss: 5.2056e-05 - accuracy: 0.9983\n",
      "Epoch 229/1000\n",
      " - 1s - loss: 5.0124e-05 - accuracy: 0.9983\n",
      "Epoch 230/1000\n",
      " - 1s - loss: 4.9783e-05 - accuracy: 0.9983\n",
      "Epoch 231/1000\n",
      " - 1s - loss: 5.0706e-05 - accuracy: 0.9983\n",
      "Epoch 232/1000\n",
      " - 1s - loss: 5.0976e-05 - accuracy: 0.9983\n",
      "Epoch 233/1000\n",
      " - 1s - loss: 5.1277e-05 - accuracy: 0.9983\n",
      "Epoch 234/1000\n",
      " - 1s - loss: 5.2148e-05 - accuracy: 0.9983\n",
      "Epoch 235/1000\n",
      " - 1s - loss: 5.1068e-05 - accuracy: 0.9983\n",
      "Epoch 236/1000\n",
      " - 1s - loss: 4.9664e-05 - accuracy: 0.9983\n",
      "Epoch 237/1000\n",
      " - 1s - loss: 5.1165e-05 - accuracy: 0.9983\n",
      "Epoch 238/1000\n",
      " - 1s - loss: 3.8562e-04 - accuracy: 0.9898\n",
      "Epoch 239/1000\n",
      " - 1s - loss: 4.0680e-04 - accuracy: 0.9883\n",
      "Epoch 240/1000\n",
      " - 1s - loss: 1.6587e-04 - accuracy: 0.9952\n",
      "Epoch 241/1000\n",
      " - 1s - loss: 1.0374e-04 - accuracy: 0.9972\n",
      "Epoch 242/1000\n",
      " - 1s - loss: 5.7297e-05 - accuracy: 0.9982\n",
      "Epoch 243/1000\n",
      " - 1s - loss: 5.2782e-05 - accuracy: 0.9983\n",
      "Epoch 244/1000\n",
      " - 1s - loss: 5.0282e-05 - accuracy: 0.9983\n",
      "Epoch 245/1000\n",
      " - 1s - loss: 4.9951e-05 - accuracy: 0.9983\n",
      "Epoch 246/1000\n",
      " - 1s - loss: 5.0386e-05 - accuracy: 0.9983\n",
      "Epoch 247/1000\n",
      " - 1s - loss: 4.9510e-05 - accuracy: 0.9983\n",
      "Epoch 248/1000\n",
      " - 1s - loss: 5.0416e-05 - accuracy: 0.9983\n",
      "Epoch 249/1000\n",
      " - 1s - loss: 4.6859e-05 - accuracy: 0.9984\n",
      "Epoch 250/1000\n",
      " - 1s - loss: 5.2804e-05 - accuracy: 0.9983\n",
      "Epoch 251/1000\n",
      " - 1s - loss: 5.3156e-05 - accuracy: 0.9984\n",
      "Epoch 252/1000\n",
      " - 1s - loss: 5.1733e-05 - accuracy: 0.9984\n",
      "Epoch 253/1000\n",
      " - 1s - loss: 5.2632e-05 - accuracy: 0.9984\n",
      "Epoch 254/1000\n",
      " - 1s - loss: 5.0525e-05 - accuracy: 0.9984\n",
      "Epoch 255/1000\n",
      " - 1s - loss: 4.8703e-05 - accuracy: 0.9984\n",
      "Epoch 256/1000\n",
      " - 1s - loss: 4.8908e-05 - accuracy: 0.9984\n",
      "Epoch 257/1000\n",
      " - 1s - loss: 4.9733e-05 - accuracy: 0.9984\n",
      "Epoch 258/1000\n",
      " - 1s - loss: 4.8507e-05 - accuracy: 0.9984\n",
      "Epoch 259/1000\n",
      " - 1s - loss: 2.1598e-04 - accuracy: 0.9941\n",
      "Epoch 260/1000\n",
      " - 1s - loss: 6.0199e-04 - accuracy: 0.9834\n",
      "Epoch 261/1000\n",
      " - 1s - loss: 1.5361e-04 - accuracy: 0.9956\n",
      "Epoch 262/1000\n",
      " - 1s - loss: 1.4401e-04 - accuracy: 0.9957\n",
      "Epoch 263/1000\n",
      " - 1s - loss: 8.8867e-05 - accuracy: 0.9974\n",
      "Epoch 264/1000\n",
      " - 1s - loss: 6.2302e-05 - accuracy: 0.9981\n",
      "Epoch 265/1000\n",
      " - 1s - loss: 5.3282e-05 - accuracy: 0.9983\n",
      "Epoch 266/1000\n",
      " - 1s - loss: 5.0032e-05 - accuracy: 0.9984\n",
      "Epoch 267/1000\n",
      " - 1s - loss: 4.8440e-05 - accuracy: 0.9984\n",
      "Epoch 268/1000\n",
      " - 1s - loss: 4.7816e-05 - accuracy: 0.9984\n",
      "Epoch 269/1000\n",
      " - 1s - loss: 4.8516e-05 - accuracy: 0.9984\n",
      "Epoch 270/1000\n",
      " - 1s - loss: 4.7552e-05 - accuracy: 0.9984\n",
      "Epoch 271/1000\n",
      " - 1s - loss: 4.3325e-05 - accuracy: 0.9986\n",
      "Epoch 272/1000\n",
      " - 1s - loss: 4.1462e-05 - accuracy: 0.9986\n",
      "Epoch 273/1000\n",
      " - 1s - loss: 4.1500e-05 - accuracy: 0.9986\n",
      "Epoch 274/1000\n",
      " - 1s - loss: 4.1608e-05 - accuracy: 0.9986\n",
      "Epoch 275/1000\n",
      " - 1s - loss: 4.1582e-05 - accuracy: 0.9986\n",
      "Epoch 276/1000\n",
      " - 1s - loss: 4.1562e-05 - accuracy: 0.9986\n",
      "Epoch 277/1000\n",
      " - 1s - loss: 1.4563e-04 - accuracy: 0.9957\n",
      "Epoch 278/1000\n",
      " - 1s - loss: 4.7824e-04 - accuracy: 0.9866\n",
      "Epoch 279/1000\n",
      " - 1s - loss: 2.1600e-04 - accuracy: 0.9941\n",
      "Epoch 280/1000\n",
      " - 1s - loss: 5.9150e-05 - accuracy: 0.9982\n",
      "Epoch 281/1000\n",
      " - 1s - loss: 4.5536e-05 - accuracy: 0.9986\n",
      "Epoch 282/1000\n",
      " - 1s - loss: 4.3479e-05 - accuracy: 0.9986\n",
      "Epoch 283/1000\n",
      " - 1s - loss: 4.1855e-05 - accuracy: 0.9986\n",
      "Epoch 284/1000\n",
      " - 1s - loss: 4.0483e-05 - accuracy: 0.9986\n",
      "Epoch 285/1000\n",
      " - 1s - loss: 3.9733e-05 - accuracy: 0.9986\n",
      "Epoch 286/1000\n",
      " - 1s - loss: 3.9304e-05 - accuracy: 0.9986\n",
      "Epoch 287/1000\n",
      " - 1s - loss: 3.9192e-05 - accuracy: 0.9986\n",
      "Epoch 288/1000\n",
      " - 1s - loss: 3.9235e-05 - accuracy: 0.9986\n",
      "Epoch 289/1000\n",
      " - 1s - loss: 3.9115e-05 - accuracy: 0.9986\n",
      "Epoch 290/1000\n",
      " - 1s - loss: 3.9043e-05 - accuracy: 0.9986\n",
      "Epoch 291/1000\n",
      " - 1s - loss: 3.8991e-05 - accuracy: 0.9986\n",
      "Epoch 292/1000\n",
      " - 1s - loss: 3.8981e-05 - accuracy: 0.9986\n",
      "Epoch 293/1000\n",
      " - 1s - loss: 3.8893e-05 - accuracy: 0.9986\n",
      "Epoch 294/1000\n",
      " - 1s - loss: 3.9036e-05 - accuracy: 0.9986\n",
      "Epoch 295/1000\n",
      " - 1s - loss: 3.8837e-05 - accuracy: 0.9986\n",
      "Epoch 296/1000\n",
      " - 1s - loss: 3.8810e-05 - accuracy: 0.9986\n",
      "Epoch 297/1000\n",
      " - 1s - loss: 3.8854e-05 - accuracy: 0.9986\n",
      "Epoch 298/1000\n",
      " - 1s - loss: 3.8500e-05 - accuracy: 0.9987\n",
      "Epoch 299/1000\n",
      " - 1s - loss: 1.6061e-04 - accuracy: 0.9957\n",
      "Epoch 300/1000\n",
      " - 1s - loss: 7.1399e-04 - accuracy: 0.9796\n",
      "Epoch 301/1000\n",
      " - 1s - loss: 1.3616e-04 - accuracy: 0.9966\n",
      "Epoch 302/1000\n",
      " - 1s - loss: 6.4250e-05 - accuracy: 0.9980\n",
      "Epoch 303/1000\n",
      " - 1s - loss: 7.9226e-05 - accuracy: 0.9976\n",
      "Epoch 304/1000\n",
      " - 1s - loss: 8.1856e-05 - accuracy: 0.9977\n",
      "Epoch 305/1000\n",
      " - 1s - loss: 4.6658e-05 - accuracy: 0.9986\n",
      "Epoch 306/1000\n",
      " - 1s - loss: 4.4896e-05 - accuracy: 0.9986\n",
      "Epoch 307/1000\n",
      " - 1s - loss: 5.7139e-05 - accuracy: 0.9983\n",
      "Epoch 308/1000\n",
      " - 1s - loss: 1.1728e-04 - accuracy: 0.9967\n",
      "Epoch 309/1000\n",
      " - 1s - loss: 1.1385e-04 - accuracy: 0.9965\n",
      "Epoch 310/1000\n",
      " - 1s - loss: 1.2432e-04 - accuracy: 0.9965\n",
      "Epoch 311/1000\n",
      " - 1s - loss: 9.9701e-05 - accuracy: 0.9972\n",
      "Epoch 312/1000\n",
      " - 1s - loss: 1.3651e-04 - accuracy: 0.9964\n",
      "Epoch 313/1000\n",
      " - 1s - loss: 7.8298e-05 - accuracy: 0.9975\n",
      "Epoch 314/1000\n",
      " - 1s - loss: 8.1414e-05 - accuracy: 0.9974\n",
      "Epoch 315/1000\n",
      " - 1s - loss: 4.3647e-05 - accuracy: 0.9986\n",
      "Epoch 316/1000\n",
      " - 1s - loss: 3.7846e-05 - accuracy: 0.9987\n",
      "Epoch 317/1000\n",
      " - 1s - loss: 3.6346e-05 - accuracy: 0.9988\n",
      "Epoch 318/1000\n",
      " - 1s - loss: 3.4985e-05 - accuracy: 0.9988\n",
      "Epoch 319/1000\n",
      " - 1s - loss: 3.4712e-05 - accuracy: 0.9988\n",
      "Epoch 320/1000\n",
      " - 1s - loss: 3.4632e-05 - accuracy: 0.9988\n",
      "Epoch 321/1000\n",
      " - 1s - loss: 3.4570e-05 - accuracy: 0.9988\n",
      "Epoch 322/1000\n",
      " - 1s - loss: 3.4483e-05 - accuracy: 0.9988\n",
      "Epoch 323/1000\n",
      " - 1s - loss: 3.4483e-05 - accuracy: 0.9988\n",
      "Epoch 324/1000\n",
      " - 1s - loss: 3.4403e-05 - accuracy: 0.9988\n",
      "Epoch 325/1000\n",
      " - 1s - loss: 3.4339e-05 - accuracy: 0.9988\n",
      "Epoch 326/1000\n",
      " - 1s - loss: 3.4335e-05 - accuracy: 0.9988\n",
      "Epoch 327/1000\n",
      " - 1s - loss: 3.4348e-05 - accuracy: 0.9988\n",
      "Epoch 328/1000\n",
      " - 1s - loss: 3.4278e-05 - accuracy: 0.9988\n",
      "Epoch 329/1000\n",
      " - 1s - loss: 3.4271e-05 - accuracy: 0.9988\n",
      "Epoch 330/1000\n",
      " - 1s - loss: 3.4265e-05 - accuracy: 0.9988\n",
      "Epoch 331/1000\n",
      " - 1s - loss: 3.4253e-05 - accuracy: 0.9988\n",
      "Epoch 332/1000\n",
      " - 1s - loss: 3.4270e-05 - accuracy: 0.9988\n",
      "Epoch 333/1000\n",
      " - 1s - loss: 3.4476e-05 - accuracy: 0.9988\n",
      "Epoch 334/1000\n",
      " - 1s - loss: 3.4908e-05 - accuracy: 0.9988\n",
      "Epoch 335/1000\n",
      " - 1s - loss: 1.0293e-04 - accuracy: 0.9972\n",
      "Epoch 336/1000\n",
      " - 1s - loss: 6.2112e-04 - accuracy: 0.9834\n",
      "Epoch 337/1000\n",
      " - 1s - loss: 1.4381e-04 - accuracy: 0.9959\n",
      "Epoch 338/1000\n",
      " - 1s - loss: 7.8259e-05 - accuracy: 0.9977\n",
      "Epoch 339/1000\n",
      " - 1s - loss: 4.8259e-05 - accuracy: 0.9985\n",
      "Epoch 340/1000\n",
      " - 1s - loss: 6.5026e-05 - accuracy: 0.9981\n",
      "Epoch 341/1000\n",
      " - 1s - loss: 1.0539e-04 - accuracy: 0.9970\n",
      "Epoch 342/1000\n",
      " - 1s - loss: 7.4727e-05 - accuracy: 0.9979\n",
      "Epoch 343/1000\n",
      " - 1s - loss: 7.6592e-05 - accuracy: 0.9978\n",
      "Epoch 344/1000\n",
      " - 1s - loss: 6.8568e-05 - accuracy: 0.9979\n",
      "Epoch 345/1000\n",
      " - 1s - loss: 5.9814e-05 - accuracy: 0.9981\n",
      "Epoch 346/1000\n",
      " - 1s - loss: 7.7351e-05 - accuracy: 0.9976\n",
      "Epoch 347/1000\n",
      " - 1s - loss: 4.5735e-05 - accuracy: 0.9986\n",
      "Epoch 348/1000\n",
      " - 1s - loss: 3.6470e-05 - accuracy: 0.9988\n",
      "Epoch 349/1000\n",
      " - 1s - loss: 3.5539e-05 - accuracy: 0.9988\n",
      "Epoch 350/1000\n",
      " - 1s - loss: 3.5960e-05 - accuracy: 0.9988\n",
      "Epoch 351/1000\n",
      " - 1s - loss: 3.5447e-05 - accuracy: 0.9988\n",
      "Epoch 352/1000\n",
      " - 1s - loss: 3.5079e-05 - accuracy: 0.9988\n",
      "Epoch 353/1000\n",
      " - 1s - loss: 1.9318e-04 - accuracy: 0.9946\n",
      "Epoch 354/1000\n",
      " - 1s - loss: 2.7745e-04 - accuracy: 0.9923\n",
      "Epoch 355/1000\n",
      " - 1s - loss: 1.3480e-04 - accuracy: 0.9962\n",
      "Epoch 356/1000\n",
      " - 1s - loss: 5.5314e-05 - accuracy: 0.9985\n",
      "Epoch 357/1000\n",
      " - 1s - loss: 5.0252e-05 - accuracy: 0.9985\n",
      "Epoch 358/1000\n",
      " - 1s - loss: 9.8141e-05 - accuracy: 0.9972\n",
      "Epoch 359/1000\n",
      " - 1s - loss: 4.8725e-05 - accuracy: 0.9986\n",
      "Epoch 360/1000\n",
      " - 1s - loss: 3.7751e-05 - accuracy: 0.9988\n",
      "Epoch 361/1000\n",
      " - 1s - loss: 4.0950e-05 - accuracy: 0.9987\n",
      "Epoch 362/1000\n",
      " - 1s - loss: 8.2711e-05 - accuracy: 0.9976\n",
      "Epoch 363/1000\n",
      " - 1s - loss: 8.9553e-05 - accuracy: 0.9975\n",
      "Epoch 364/1000\n",
      " - 1s - loss: 4.2395e-05 - accuracy: 0.9987\n",
      "Epoch 365/1000\n",
      " - 1s - loss: 3.6740e-05 - accuracy: 0.9988\n",
      "Epoch 366/1000\n",
      " - 1s - loss: 3.7075e-05 - accuracy: 0.9988\n",
      "Epoch 367/1000\n",
      " - 1s - loss: 3.6667e-05 - accuracy: 0.9988\n",
      "Epoch 368/1000\n",
      " - 1s - loss: 3.6582e-05 - accuracy: 0.9988\n",
      "Epoch 369/1000\n",
      " - 1s - loss: 3.6777e-05 - accuracy: 0.9988\n",
      "Epoch 370/1000\n",
      " - 1s - loss: 3.6590e-05 - accuracy: 0.9988\n",
      "Epoch 371/1000\n",
      " - 1s - loss: 3.6866e-05 - accuracy: 0.9988\n",
      "Epoch 372/1000\n",
      " - 1s - loss: 3.7274e-05 - accuracy: 0.9988\n",
      "Epoch 373/1000\n",
      " - 1s - loss: 3.6683e-05 - accuracy: 0.9988\n",
      "Epoch 374/1000\n",
      " - 1s - loss: 3.6809e-05 - accuracy: 0.9988\n",
      "Epoch 375/1000\n",
      " - 1s - loss: 3.6599e-05 - accuracy: 0.9988\n",
      "Epoch 376/1000\n",
      " - 1s - loss: 3.6368e-05 - accuracy: 0.9988\n",
      "Epoch 377/1000\n",
      " - 1s - loss: 3.7009e-05 - accuracy: 0.9988\n",
      "Epoch 378/1000\n",
      " - 1s - loss: 3.7605e-05 - accuracy: 0.9988\n",
      "Epoch 379/1000\n",
      " - 1s - loss: 3.7363e-05 - accuracy: 0.9988\n",
      "Epoch 380/1000\n",
      " - 1s - loss: 4.0324e-05 - accuracy: 0.9987\n",
      "Epoch 381/1000\n",
      " - 1s - loss: 3.9982e-04 - accuracy: 0.9893\n",
      "Epoch 382/1000\n",
      " - 1s - loss: 3.7001e-04 - accuracy: 0.9903\n",
      "Epoch 383/1000\n",
      " - 1s - loss: 7.1145e-05 - accuracy: 0.9982\n",
      "Epoch 384/1000\n",
      " - 1s - loss: 1.0399e-04 - accuracy: 0.9971\n",
      "Epoch 385/1000\n",
      " - 1s - loss: 7.0489e-05 - accuracy: 0.9979\n",
      "Epoch 386/1000\n",
      " - 1s - loss: 6.1233e-05 - accuracy: 0.9983\n",
      "Epoch 387/1000\n",
      " - 1s - loss: 7.0933e-05 - accuracy: 0.9977\n",
      "Epoch 388/1000\n",
      " - 1s - loss: 8.0375e-05 - accuracy: 0.9977\n",
      "Epoch 389/1000\n",
      " - 1s - loss: 5.0802e-05 - accuracy: 0.9986\n",
      "Epoch 390/1000\n",
      " - 1s - loss: 4.2619e-05 - accuracy: 0.9987\n",
      "Epoch 391/1000\n",
      " - 1s - loss: 8.1444e-05 - accuracy: 0.9974\n",
      "Epoch 392/1000\n",
      " - 1s - loss: 1.1137e-04 - accuracy: 0.9968\n",
      "Epoch 393/1000\n",
      " - 1s - loss: 6.1240e-05 - accuracy: 0.9980\n",
      "Epoch 394/1000\n",
      " - 1s - loss: 3.8644e-05 - accuracy: 0.9987\n",
      "Epoch 395/1000\n",
      " - 1s - loss: 3.6663e-05 - accuracy: 0.9988\n",
      " - 1s - loss: 3.6208e-05 - accuracy: 0.9988\n",
      "Epoch 397/1000\n",
      " - 1s - loss: 3.6133e-05 - accuracy: 0.9988\n",
      "Epoch 398/1000\n",
      " - 1s - loss: 3.6313e-05 - accuracy: 0.9988\n",
      "Epoch 399/1000\n",
      " - 1s - loss: 3.6813e-05 - accuracy: 0.9988\n",
      "Epoch 400/1000\n",
      " - 1s - loss: 3.6754e-05 - accuracy: 0.9988\n",
      "Epoch 401/1000\n",
      " - 1s - loss: 3.6688e-05 - accuracy: 0.9988\n",
      "Epoch 402/1000\n",
      " - 1s - loss: 3.6349e-05 - accuracy: 0.9988\n",
      "Epoch 403/1000\n",
      " - 1s - loss: 3.6087e-05 - accuracy: 0.9988\n",
      "Epoch 404/1000\n",
      " - 1s - loss: 3.6986e-05 - accuracy: 0.9988\n",
      "Epoch 405/1000\n",
      " - 1s - loss: 3.7360e-05 - accuracy: 0.9988\n",
      "Epoch 406/1000\n",
      " - 1s - loss: 3.6429e-05 - accuracy: 0.9988\n",
      "Epoch 407/1000\n",
      " - 1s - loss: 3.6325e-05 - accuracy: 0.9988\n",
      "Epoch 408/1000\n",
      " - 1s - loss: 3.6134e-05 - accuracy: 0.9988\n",
      "Epoch 409/1000\n",
      " - 1s - loss: 3.6578e-05 - accuracy: 0.9988\n",
      "Epoch 410/1000\n",
      " - 1s - loss: 3.6595e-05 - accuracy: 0.9988\n",
      "Epoch 411/1000\n",
      " - 1s - loss: 3.6554e-05 - accuracy: 0.9988\n",
      "Epoch 412/1000\n",
      " - 1s - loss: 3.5921e-05 - accuracy: 0.9988\n",
      "Epoch 413/1000\n",
      " - 1s - loss: 1.5051e-04 - accuracy: 0.9961\n",
      "Epoch 414/1000\n",
      " - 1s - loss: 4.9649e-04 - accuracy: 0.9874\n",
      "Epoch 415/1000\n",
      " - 1s - loss: 1.8754e-04 - accuracy: 0.9947\n",
      "Epoch 416/1000\n",
      " - 1s - loss: 1.0985e-04 - accuracy: 0.9970\n",
      "Epoch 417/1000\n",
      " - 1s - loss: 5.7726e-05 - accuracy: 0.9983\n",
      "Epoch 418/1000\n",
      " - 1s - loss: 5.6240e-05 - accuracy: 0.9982\n",
      "Epoch 419/1000\n",
      " - 1s - loss: 3.8969e-05 - accuracy: 0.9988\n",
      "Epoch 420/1000\n",
      " - 1s - loss: 3.6220e-05 - accuracy: 0.9988\n",
      "Epoch 421/1000\n",
      " - 1s - loss: 3.5642e-05 - accuracy: 0.9988\n",
      "Epoch 422/1000\n",
      " - 1s - loss: 3.6149e-05 - accuracy: 0.9988\n",
      "Epoch 423/1000\n",
      " - 1s - loss: 3.5458e-05 - accuracy: 0.9988\n",
      "Epoch 424/1000\n",
      " - 1s - loss: 3.5239e-05 - accuracy: 0.9988\n",
      "Epoch 425/1000\n",
      " - 1s - loss: 3.5414e-05 - accuracy: 0.9988\n",
      "Epoch 426/1000\n",
      " - 1s - loss: 3.5897e-05 - accuracy: 0.9988\n",
      "Epoch 427/1000\n",
      " - 1s - loss: 3.5645e-05 - accuracy: 0.9988\n",
      "Epoch 428/1000\n",
      " - 1s - loss: 3.6318e-05 - accuracy: 0.9988\n",
      "Epoch 429/1000\n",
      " - 1s - loss: 3.6193e-05 - accuracy: 0.9988\n",
      "Epoch 430/1000\n",
      " - 1s - loss: 3.6094e-05 - accuracy: 0.9988\n",
      "Epoch 431/1000\n",
      " - 1s - loss: 3.6031e-05 - accuracy: 0.9988\n",
      "Epoch 432/1000\n",
      " - 1s - loss: 3.5965e-05 - accuracy: 0.9988\n",
      "Epoch 433/1000\n",
      " - 1s - loss: 3.5870e-05 - accuracy: 0.9988\n",
      "Epoch 434/1000\n",
      " - 1s - loss: 3.5824e-05 - accuracy: 0.9988\n",
      "Epoch 435/1000\n",
      " - 1s - loss: 4.2624e-04 - accuracy: 0.9887\n",
      "Epoch 436/1000\n",
      " - 1s - loss: 3.3200e-04 - accuracy: 0.9913\n",
      "Epoch 437/1000\n",
      " - 1s - loss: 1.5878e-04 - accuracy: 0.9957\n",
      "Epoch 438/1000\n",
      " - 1s - loss: 7.3886e-05 - accuracy: 0.9978\n",
      "Epoch 439/1000\n",
      " - 1s - loss: 6.0085e-05 - accuracy: 0.9982\n",
      "Epoch 440/1000\n",
      " - 1s - loss: 5.2844e-05 - accuracy: 0.9984\n",
      "Epoch 441/1000\n",
      " - 1s - loss: 4.6348e-05 - accuracy: 0.9986\n",
      "Epoch 442/1000\n",
      " - 1s - loss: 3.5700e-05 - accuracy: 0.9988\n",
      "Epoch 443/1000\n",
      " - 1s - loss: 3.5838e-05 - accuracy: 0.9988\n",
      "Epoch 444/1000\n",
      " - 1s - loss: 3.6453e-05 - accuracy: 0.9988\n",
      "Epoch 445/1000\n",
      " - 1s - loss: 3.6099e-05 - accuracy: 0.9988\n",
      "Epoch 446/1000\n",
      " - 1s - loss: 3.7398e-05 - accuracy: 0.9988\n",
      "Epoch 447/1000\n",
      " - 1s - loss: 3.7505e-05 - accuracy: 0.9988\n",
      "Epoch 448/1000\n",
      " - 1s - loss: 3.5592e-05 - accuracy: 0.9988\n",
      "Epoch 449/1000\n",
      " - 1s - loss: 3.5671e-05 - accuracy: 0.9988\n",
      "Epoch 450/1000\n",
      " - 1s - loss: 3.4954e-05 - accuracy: 0.9988\n",
      "Epoch 451/1000\n",
      " - 1s - loss: 3.5050e-05 - accuracy: 0.9988\n",
      "Epoch 452/1000\n",
      " - 1s - loss: 3.4961e-05 - accuracy: 0.9988\n",
      "Epoch 453/1000\n",
      " - 1s - loss: 3.5118e-05 - accuracy: 0.9988\n",
      "Epoch 454/1000\n",
      " - 1s - loss: 3.5619e-05 - accuracy: 0.9988\n",
      "Epoch 455/1000\n",
      " - 1s - loss: 3.6065e-05 - accuracy: 0.9988\n",
      "Epoch 456/1000\n",
      " - 1s - loss: 3.5996e-05 - accuracy: 0.9988\n",
      "Epoch 457/1000\n",
      " - 1s - loss: 3.5973e-05 - accuracy: 0.9988\n",
      "Epoch 458/1000\n",
      " - 1s - loss: 3.6053e-05 - accuracy: 0.9988\n",
      "Epoch 459/1000\n",
      " - 1s - loss: 3.5997e-05 - accuracy: 0.9988\n",
      "Epoch 460/1000\n",
      " - 1s - loss: 3.5896e-05 - accuracy: 0.9988\n",
      "Epoch 461/1000\n",
      " - 1s - loss: 3.5938e-05 - accuracy: 0.9988\n",
      "Epoch 462/1000\n",
      " - 1s - loss: 3.5913e-05 - accuracy: 0.9988\n",
      "Epoch 463/1000\n",
      " - 1s - loss: 3.6009e-05 - accuracy: 0.9988\n",
      "Epoch 464/1000\n",
      " - 1s - loss: 3.6074e-05 - accuracy: 0.9988\n",
      "Epoch 465/1000\n",
      " - 1s - loss: 3.6192e-05 - accuracy: 0.9988\n",
      "Epoch 466/1000\n",
      " - 1s - loss: 3.7678e-05 - accuracy: 0.9988\n",
      "Epoch 467/1000\n",
      " - 1s - loss: 7.9752e-04 - accuracy: 0.9799\n",
      "Epoch 468/1000\n",
      " - 1s - loss: 3.5655e-04 - accuracy: 0.9904\n",
      "Epoch 469/1000\n",
      " - 1s - loss: 1.4696e-04 - accuracy: 0.9958\n",
      "Epoch 470/1000\n",
      " - 1s - loss: 6.3828e-05 - accuracy: 0.9983\n",
      "Epoch 471/1000\n",
      " - 1s - loss: 4.7382e-05 - accuracy: 0.9985\n",
      "Epoch 472/1000\n",
      " - 1s - loss: 5.0120e-05 - accuracy: 0.9984\n",
      "Epoch 473/1000\n",
      " - 1s - loss: 4.6986e-05 - accuracy: 0.9986\n",
      "Epoch 474/1000\n",
      " - 1s - loss: 1.1014e-04 - accuracy: 0.9971\n",
      "Epoch 475/1000\n",
      " - 1s - loss: 5.0550e-05 - accuracy: 0.9985\n",
      "Epoch 476/1000\n",
      " - 1s - loss: 3.5985e-05 - accuracy: 0.9988\n",
      "Epoch 477/1000\n",
      " - 1s - loss: 3.6188e-05 - accuracy: 0.9988\n",
      "Epoch 478/1000\n",
      " - 1s - loss: 3.5372e-05 - accuracy: 0.9988\n",
      "Epoch 479/1000\n",
      " - 1s - loss: 3.5278e-05 - accuracy: 0.9988\n",
      "Epoch 480/1000\n",
      " - 1s - loss: 3.5665e-05 - accuracy: 0.9988\n",
      "Epoch 481/1000\n",
      " - 1s - loss: 3.5686e-05 - accuracy: 0.9988\n",
      "Epoch 482/1000\n",
      " - 1s - loss: 3.5891e-05 - accuracy: 0.9988\n",
      "Epoch 483/1000\n",
      " - 1s - loss: 3.4949e-05 - accuracy: 0.9988\n",
      "Epoch 484/1000\n",
      " - 1s - loss: 3.5005e-05 - accuracy: 0.9988\n",
      "Epoch 485/1000\n",
      " - 1s - loss: 3.5126e-05 - accuracy: 0.9988\n",
      "Epoch 486/1000\n",
      " - 1s - loss: 3.5538e-05 - accuracy: 0.9988\n",
      "Epoch 487/1000\n",
      " - 1s - loss: 3.5637e-05 - accuracy: 0.9988\n",
      "Epoch 488/1000\n",
      " - 1s - loss: 3.4525e-05 - accuracy: 0.9988\n",
      "Epoch 489/1000\n",
      " - 1s - loss: 3.4410e-05 - accuracy: 0.9988\n",
      "Epoch 490/1000\n",
      " - 1s - loss: 3.4466e-05 - accuracy: 0.9988\n",
      "Epoch 491/1000\n",
      " - 1s - loss: 3.4383e-05 - accuracy: 0.9988\n",
      "Epoch 492/1000\n",
      " - 1s - loss: 3.4869e-05 - accuracy: 0.9988\n",
      "Epoch 493/1000\n",
      " - 1s - loss: 3.5009e-05 - accuracy: 0.9988\n",
      "Epoch 494/1000\n",
      " - 1s - loss: 3.4980e-05 - accuracy: 0.9988\n",
      "Epoch 495/1000\n",
      " - 1s - loss: 3.8516e-04 - accuracy: 0.9901\n",
      "Epoch 496/1000\n",
      " - 1s - loss: 3.1895e-04 - accuracy: 0.9918\n",
      "Epoch 497/1000\n",
      " - 1s - loss: 1.3150e-04 - accuracy: 0.9964\n",
      "Epoch 498/1000\n",
      " - 1s - loss: 1.5576e-04 - accuracy: 0.9957\n",
      "Epoch 499/1000\n",
      " - 1s - loss: 1.4609e-04 - accuracy: 0.9961\n",
      "Epoch 500/1000\n",
      " - 1s - loss: 5.2250e-05 - accuracy: 0.9986\n",
      "Epoch 501/1000\n",
      " - 1s - loss: 4.0348e-05 - accuracy: 0.9987\n",
      "Epoch 502/1000\n",
      " - 1s - loss: 3.6430e-05 - accuracy: 0.9988\n",
      "Epoch 503/1000\n",
      " - 1s - loss: 3.5442e-05 - accuracy: 0.9988\n",
      "Epoch 504/1000\n",
      " - 1s - loss: 3.5096e-05 - accuracy: 0.9988\n",
      "Epoch 505/1000\n",
      " - 1s - loss: 3.4924e-05 - accuracy: 0.9988\n",
      "Epoch 506/1000\n",
      " - 1s - loss: 3.4815e-05 - accuracy: 0.9988\n",
      "Epoch 507/1000\n",
      " - 1s - loss: 3.4726e-05 - accuracy: 0.9988\n",
      "Epoch 508/1000\n",
      " - 1s - loss: 3.4656e-05 - accuracy: 0.9988\n",
      "Epoch 509/1000\n",
      " - 1s - loss: 3.4556e-05 - accuracy: 0.9988\n",
      "Epoch 510/1000\n",
      " - 1s - loss: 3.4570e-05 - accuracy: 0.9988\n",
      "Epoch 511/1000\n",
      " - 1s - loss: 3.4446e-05 - accuracy: 0.9988\n",
      "Epoch 512/1000\n",
      " - 1s - loss: 3.4523e-05 - accuracy: 0.9988\n",
      "Epoch 513/1000\n",
      " - 1s - loss: 3.4576e-05 - accuracy: 0.9988\n",
      "Epoch 514/1000\n",
      " - 1s - loss: 3.4541e-05 - accuracy: 0.9988\n",
      "Epoch 515/1000\n",
      " - 1s - loss: 3.5186e-05 - accuracy: 0.9988\n",
      "Epoch 516/1000\n",
      " - 1s - loss: 3.5524e-05 - accuracy: 0.9988\n",
      "Epoch 517/1000\n",
      " - 1s - loss: 3.5279e-05 - accuracy: 0.9988\n",
      "Epoch 518/1000\n",
      " - 1s - loss: 3.5490e-05 - accuracy: 0.9988\n",
      "Epoch 519/1000\n",
      " - 1s - loss: 3.5928e-05 - accuracy: 0.9988\n",
      "Epoch 520/1000\n",
      " - 1s - loss: 3.5195e-05 - accuracy: 0.9988\n",
      "Epoch 521/1000\n",
      " - 1s - loss: 3.6060e-05 - accuracy: 0.9988\n",
      "Epoch 522/1000\n",
      " - 1s - loss: 3.6128e-05 - accuracy: 0.9988\n",
      "Epoch 523/1000\n",
      " - 1s - loss: 3.5161e-05 - accuracy: 0.9988\n",
      "Epoch 524/1000\n",
      " - 1s - loss: 3.5493e-05 - accuracy: 0.9988\n",
      "Epoch 525/1000\n",
      " - 1s - loss: 3.6083e-05 - accuracy: 0.9988\n",
      "Epoch 526/1000\n",
      " - 1s - loss: 1.8691e-04 - accuracy: 0.9950\n",
      "Epoch 527/1000\n",
      " - 1s - loss: 6.2524e-04 - accuracy: 0.9834\n",
      "Epoch 528/1000\n",
      " - 1s - loss: 2.0212e-04 - accuracy: 0.9946\n",
      "Epoch 529/1000\n",
      " - 1s - loss: 1.3327e-04 - accuracy: 0.9960\n",
      "Epoch 530/1000\n",
      " - 1s - loss: 9.6765e-05 - accuracy: 0.9974\n",
      "Epoch 531/1000\n",
      " - 1s - loss: 4.1916e-05 - accuracy: 0.9987\n",
      "Epoch 532/1000\n",
      " - 1s - loss: 3.6078e-05 - accuracy: 0.9988\n",
      "Epoch 533/1000\n",
      " - 1s - loss: 3.5236e-05 - accuracy: 0.9988\n",
      "Epoch 534/1000\n",
      " - 1s - loss: 3.4956e-05 - accuracy: 0.9988\n",
      "Epoch 535/1000\n",
      " - 1s - loss: 3.4746e-05 - accuracy: 0.9988\n",
      "Epoch 536/1000\n",
      " - 1s - loss: 3.4545e-05 - accuracy: 0.9988\n",
      "Epoch 537/1000\n",
      " - 1s - loss: 3.4568e-05 - accuracy: 0.9988\n",
      "Epoch 538/1000\n",
      " - 1s - loss: 3.4436e-05 - accuracy: 0.9988\n",
      "Epoch 539/1000\n",
      " - 1s - loss: 3.4339e-05 - accuracy: 0.9988\n",
      "Epoch 540/1000\n",
      " - 1s - loss: 3.4283e-05 - accuracy: 0.9988\n",
      "Epoch 541/1000\n",
      " - 1s - loss: 3.4309e-05 - accuracy: 0.9988\n",
      "Epoch 542/1000\n",
      " - 1s - loss: 3.4268e-05 - accuracy: 0.9988\n",
      "Epoch 543/1000\n",
      " - 1s - loss: 3.4235e-05 - accuracy: 0.9988\n",
      "Epoch 544/1000\n",
      " - 1s - loss: 3.4192e-05 - accuracy: 0.9988\n",
      "Epoch 545/1000\n",
      " - 1s - loss: 3.4178e-05 - accuracy: 0.9988\n",
      "Epoch 546/1000\n",
      " - 1s - loss: 3.4189e-05 - accuracy: 0.9988\n",
      "Epoch 547/1000\n",
      " - 1s - loss: 3.4162e-05 - accuracy: 0.9988\n",
      "Epoch 548/1000\n",
      " - 1s - loss: 3.4379e-05 - accuracy: 0.9988\n",
      "Epoch 549/1000\n",
      " - 1s - loss: 3.4215e-05 - accuracy: 0.9988\n",
      "Epoch 550/1000\n",
      " - 1s - loss: 3.8938e-05 - accuracy: 0.9987\n",
      "Epoch 551/1000\n",
      " - 1s - loss: 5.2495e-04 - accuracy: 0.9867\n",
      "Epoch 552/1000\n",
      " - 1s - loss: 2.4027e-04 - accuracy: 0.9935\n",
      "Epoch 553/1000\n",
      " - 1s - loss: 1.0781e-04 - accuracy: 0.9969\n",
      "Epoch 554/1000\n",
      " - 1s - loss: 1.2694e-04 - accuracy: 0.9966\n",
      "Epoch 555/1000\n",
      " - 1s - loss: 7.1310e-05 - accuracy: 0.9980\n",
      "Epoch 556/1000\n",
      " - 1s - loss: 8.0293e-05 - accuracy: 0.9976\n",
      "Epoch 557/1000\n",
      " - 1s - loss: 4.2461e-05 - accuracy: 0.9987\n",
      "Epoch 558/1000\n",
      " - 1s - loss: 4.2877e-05 - accuracy: 0.9986\n",
      "Epoch 559/1000\n",
      " - 1s - loss: 3.4707e-05 - accuracy: 0.9988\n",
      "Epoch 560/1000\n",
      " - 1s - loss: 3.4469e-05 - accuracy: 0.9988\n",
      "Epoch 561/1000\n",
      " - 1s - loss: 3.4307e-05 - accuracy: 0.9988\n",
      "Epoch 562/1000\n",
      " - 1s - loss: 3.4227e-05 - accuracy: 0.9988\n",
      "Epoch 563/1000\n",
      " - 1s - loss: 3.4169e-05 - accuracy: 0.9988\n",
      "Epoch 564/1000\n",
      " - 1s - loss: 3.4134e-05 - accuracy: 0.9988\n",
      "Epoch 565/1000\n",
      " - 1s - loss: 3.4129e-05 - accuracy: 0.9988\n",
      "Epoch 566/1000\n",
      " - 1s - loss: 3.4113e-05 - accuracy: 0.9988\n",
      "Epoch 567/1000\n",
      " - 1s - loss: 3.4101e-05 - accuracy: 0.9988\n",
      "Epoch 568/1000\n",
      " - 1s - loss: 3.4077e-05 - accuracy: 0.9988\n",
      "Epoch 569/1000\n",
      " - 1s - loss: 3.4075e-05 - accuracy: 0.9988\n",
      "Epoch 570/1000\n",
      " - 1s - loss: 3.4015e-05 - accuracy: 0.9988\n",
      "Epoch 571/1000\n",
      " - 1s - loss: 3.3972e-05 - accuracy: 0.9988\n",
      "Epoch 572/1000\n",
      " - 1s - loss: 3.4042e-05 - accuracy: 0.9988\n",
      "Epoch 573/1000\n",
      " - 1s - loss: 3.4048e-05 - accuracy: 0.9988\n",
      "Epoch 574/1000\n",
      " - 1s - loss: 3.3994e-05 - accuracy: 0.9988\n",
      "Epoch 575/1000\n",
      " - 1s - loss: 3.4050e-05 - accuracy: 0.9988\n",
      "Epoch 576/1000\n",
      " - 1s - loss: 3.4295e-05 - accuracy: 0.9988\n",
      "Epoch 577/1000\n",
      " - 1s - loss: 3.9075e-04 - accuracy: 0.9901\n",
      "Epoch 578/1000\n",
      " - 1s - loss: 3.6293e-04 - accuracy: 0.9907\n",
      "Epoch 579/1000\n",
      " - 1s - loss: 1.8070e-04 - accuracy: 0.9953\n",
      "Epoch 580/1000\n",
      " - 1s - loss: 8.3078e-05 - accuracy: 0.9976\n",
      "Epoch 581/1000\n",
      " - 1s - loss: 6.6418e-05 - accuracy: 0.9980\n",
      "Epoch 582/1000\n",
      " - 1s - loss: 4.0760e-05 - accuracy: 0.9987\n",
      "Epoch 583/1000\n",
      " - 1s - loss: 3.5776e-05 - accuracy: 0.9988\n",
      "Epoch 584/1000\n",
      " - 1s - loss: 3.5566e-05 - accuracy: 0.9988\n",
      "Epoch 585/1000\n",
      " - 1s - loss: 3.6057e-05 - accuracy: 0.9988\n",
      "Epoch 586/1000\n",
      " - 1s - loss: 3.4942e-05 - accuracy: 0.9988\n",
      "Epoch 587/1000\n",
      " - 1s - loss: 3.5533e-05 - accuracy: 0.9988\n",
      "Epoch 588/1000\n",
      " - 1s - loss: 3.6009e-05 - accuracy: 0.9988\n",
      "Epoch 589/1000\n",
      " - 1s - loss: 3.5944e-05 - accuracy: 0.9988\n",
      "Epoch 590/1000\n",
      " - 1s - loss: 3.5911e-05 - accuracy: 0.9988\n",
      "Epoch 591/1000\n",
      " - 1s - loss: 3.5878e-05 - accuracy: 0.9988\n",
      "Epoch 592/1000\n",
      " - 1s - loss: 3.5691e-05 - accuracy: 0.9988\n",
      "Epoch 593/1000\n",
      " - 1s - loss: 3.4999e-05 - accuracy: 0.9988\n",
      "Epoch 594/1000\n",
      " - 1s - loss: 3.4887e-05 - accuracy: 0.9988\n",
      "Epoch 595/1000\n",
      " - 1s - loss: 3.5707e-05 - accuracy: 0.9988\n",
      "Epoch 596/1000\n",
      " - 1s - loss: 3.5727e-05 - accuracy: 0.9988\n",
      "Epoch 597/1000\n",
      " - 1s - loss: 3.4732e-05 - accuracy: 0.9988\n",
      "Epoch 598/1000\n",
      " - 1s - loss: 3.5928e-05 - accuracy: 0.9988\n",
      "Epoch 599/1000\n",
      " - 1s - loss: 3.5924e-05 - accuracy: 0.9988\n",
      "Epoch 600/1000\n",
      " - 1s - loss: 3.5551e-05 - accuracy: 0.9988\n",
      "Epoch 601/1000\n",
      " - 1s - loss: 3.5889e-05 - accuracy: 0.9988\n",
      "Epoch 602/1000\n",
      " - 1s - loss: 3.6058e-05 - accuracy: 0.9988\n",
      "Epoch 603/1000\n",
      " - 1s - loss: 3.5900e-05 - accuracy: 0.9988\n",
      "Epoch 604/1000\n",
      " - 1s - loss: 3.6119e-05 - accuracy: 0.9988\n",
      "Epoch 605/1000\n",
      " - 1s - loss: 3.6096e-05 - accuracy: 0.9988\n",
      "Epoch 606/1000\n",
      " - 1s - loss: 4.6860e-04 - accuracy: 0.9887\n",
      "Epoch 607/1000\n",
      " - 1s - loss: 4.3281e-04 - accuracy: 0.9892\n",
      "Epoch 608/1000\n",
      " - 1s - loss: 2.4813e-04 - accuracy: 0.9937\n",
      "Epoch 609/1000\n",
      " - 1s - loss: 1.1707e-04 - accuracy: 0.9970\n",
      "Epoch 610/1000\n",
      " - 1s - loss: 9.8916e-05 - accuracy: 0.9976\n",
      "Epoch 611/1000\n",
      " - 1s - loss: 7.2011e-05 - accuracy: 0.9980\n",
      "Epoch 612/1000\n",
      " - 1s - loss: 4.2610e-05 - accuracy: 0.9988\n",
      "Epoch 613/1000\n",
      " - 1s - loss: 4.2529e-05 - accuracy: 0.9988\n",
      "Epoch 614/1000\n",
      " - 1s - loss: 5.1415e-05 - accuracy: 0.9986\n",
      "Epoch 615/1000\n",
      " - 1s - loss: 1.5378e-04 - accuracy: 0.9957\n",
      "Epoch 616/1000\n",
      " - 1s - loss: 4.1720e-05 - accuracy: 0.9988\n",
      "Epoch 617/1000\n",
      " - 1s - loss: 3.7939e-05 - accuracy: 0.9988\n",
      "Epoch 618/1000\n",
      " - 1s - loss: 3.7719e-05 - accuracy: 0.9988\n",
      "Epoch 619/1000\n",
      " - 1s - loss: 3.7140e-05 - accuracy: 0.9988\n",
      "Epoch 620/1000\n",
      " - 1s - loss: 3.6932e-05 - accuracy: 0.9988\n",
      "Epoch 621/1000\n",
      " - 1s - loss: 3.5613e-05 - accuracy: 0.9988\n",
      "Epoch 622/1000\n",
      " - 1s - loss: 3.5324e-05 - accuracy: 0.9988\n",
      "Epoch 623/1000\n",
      " - 1s - loss: 3.5260e-05 - accuracy: 0.9988\n",
      "Epoch 624/1000\n",
      " - 1s - loss: 3.5854e-05 - accuracy: 0.9988\n",
      "Epoch 625/1000\n",
      " - 1s - loss: 3.5375e-05 - accuracy: 0.9988\n",
      "Epoch 626/1000\n",
      " - 1s - loss: 3.5814e-05 - accuracy: 0.9988\n",
      "Epoch 627/1000\n",
      " - 1s - loss: 3.4884e-05 - accuracy: 0.9988\n",
      "Epoch 628/1000\n",
      " - 1s - loss: 3.4997e-05 - accuracy: 0.9988\n",
      "Epoch 629/1000\n",
      " - 1s - loss: 3.4723e-05 - accuracy: 0.9988\n",
      "Epoch 630/1000\n",
      " - 1s - loss: 3.4494e-05 - accuracy: 0.9988\n",
      "Epoch 631/1000\n",
      " - 1s - loss: 3.4319e-05 - accuracy: 0.9988\n",
      "Epoch 632/1000\n",
      " - 1s - loss: 3.4316e-05 - accuracy: 0.9988\n",
      "Epoch 633/1000\n",
      " - 1s - loss: 3.4277e-05 - accuracy: 0.9988\n",
      "Epoch 634/1000\n",
      " - 1s - loss: 3.4219e-05 - accuracy: 0.9988\n",
      "Epoch 635/1000\n",
      " - 1s - loss: 3.4039e-05 - accuracy: 0.9988\n",
      "Epoch 636/1000\n",
      " - 1s - loss: 3.4019e-05 - accuracy: 0.9988\n",
      "Epoch 637/1000\n",
      " - 1s - loss: 3.3990e-05 - accuracy: 0.9988\n",
      "Epoch 638/1000\n",
      " - 1s - loss: 3.4119e-05 - accuracy: 0.9988\n",
      "Epoch 639/1000\n",
      " - 1s - loss: 3.4025e-05 - accuracy: 0.9988\n",
      "Epoch 640/1000\n",
      " - 1s - loss: 3.4320e-05 - accuracy: 0.9988\n",
      "Epoch 641/1000\n",
      " - 1s - loss: 3.4751e-05 - accuracy: 0.9988\n",
      "Epoch 642/1000\n",
      " - 1s - loss: 3.5885e-05 - accuracy: 0.9988\n",
      "Epoch 643/1000\n",
      " - 1s - loss: 4.0519e-05 - accuracy: 0.9986\n",
      "Epoch 644/1000\n",
      " - 1s - loss: 5.3958e-04 - accuracy: 0.9861\n",
      "Epoch 645/1000\n",
      " - 1s - loss: 2.8318e-04 - accuracy: 0.9927\n",
      "Epoch 646/1000\n",
      " - 1s - loss: 9.8504e-05 - accuracy: 0.9973\n",
      "Epoch 647/1000\n",
      " - 1s - loss: 1.0372e-04 - accuracy: 0.9972\n",
      "Epoch 648/1000\n",
      " - 1s - loss: 5.0929e-05 - accuracy: 0.9985\n",
      "Epoch 649/1000\n",
      " - 1s - loss: 3.6316e-05 - accuracy: 0.9988\n",
      "Epoch 650/1000\n",
      " - 1s - loss: 4.1418e-05 - accuracy: 0.9986\n",
      "Epoch 651/1000\n",
      " - 1s - loss: 3.5320e-05 - accuracy: 0.9988\n",
      "Epoch 652/1000\n",
      " - 1s - loss: 3.4629e-05 - accuracy: 0.9988\n",
      "Epoch 653/1000\n",
      " - 1s - loss: 3.4573e-05 - accuracy: 0.9988\n",
      "Epoch 654/1000\n",
      " - 1s - loss: 3.4626e-05 - accuracy: 0.9988\n",
      "Epoch 655/1000\n",
      " - 1s - loss: 3.4597e-05 - accuracy: 0.9988\n",
      "Epoch 656/1000\n",
      " - 1s - loss: 3.4708e-05 - accuracy: 0.9988\n",
      "Epoch 657/1000\n",
      " - 1s - loss: 3.4750e-05 - accuracy: 0.9988\n",
      "Epoch 658/1000\n",
      " - 1s - loss: 3.4931e-05 - accuracy: 0.9988\n",
      "Epoch 659/1000\n",
      " - 1s - loss: 3.4799e-05 - accuracy: 0.9988\n",
      "Epoch 660/1000\n",
      " - 1s - loss: 3.4774e-05 - accuracy: 0.9988\n",
      "Epoch 661/1000\n",
      " - 1s - loss: 3.4583e-05 - accuracy: 0.9988\n",
      "Epoch 662/1000\n",
      " - 1s - loss: 3.4535e-05 - accuracy: 0.9988\n",
      "Epoch 663/1000\n",
      " - 1s - loss: 3.4650e-05 - accuracy: 0.9988\n",
      "Epoch 664/1000\n",
      " - 1s - loss: 3.4283e-05 - accuracy: 0.9988\n",
      "Epoch 665/1000\n",
      " - 1s - loss: 3.4071e-05 - accuracy: 0.9988\n",
      "Epoch 666/1000\n",
      " - 1s - loss: 3.3952e-05 - accuracy: 0.9988\n",
      "Epoch 667/1000\n",
      " - 1s - loss: 3.4043e-05 - accuracy: 0.9988\n",
      "Epoch 668/1000\n",
      " - 1s - loss: 3.4215e-05 - accuracy: 0.9988\n",
      "Epoch 669/1000\n",
      " - 1s - loss: 3.4160e-05 - accuracy: 0.9988\n",
      "Epoch 670/1000\n",
      " - 1s - loss: 3.4208e-05 - accuracy: 0.9988\n",
      "Epoch 671/1000\n",
      " - 1s - loss: 3.4314e-05 - accuracy: 0.9988\n",
      "Epoch 672/1000\n",
      " - 1s - loss: 3.4176e-05 - accuracy: 0.9988\n",
      "Epoch 673/1000\n",
      " - 1s - loss: 3.3974e-05 - accuracy: 0.9988\n",
      "Epoch 674/1000\n",
      " - 1s - loss: 6.5832e-05 - accuracy: 0.9980\n",
      "Epoch 675/1000\n",
      " - 1s - loss: 7.6378e-04 - accuracy: 0.9809\n",
      "Epoch 676/1000\n",
      " - 1s - loss: 1.4427e-04 - accuracy: 0.9963\n",
      "Epoch 677/1000\n",
      " - 1s - loss: 7.9674e-05 - accuracy: 0.9976\n",
      "Epoch 678/1000\n",
      " - 1s - loss: 5.0065e-05 - accuracy: 0.9984\n",
      "Epoch 679/1000\n",
      " - 1s - loss: 7.7357e-05 - accuracy: 0.9975\n",
      "Epoch 680/1000\n",
      " - 1s - loss: 5.4985e-05 - accuracy: 0.9983\n",
      "Epoch 681/1000\n",
      " - 1s - loss: 5.4022e-05 - accuracy: 0.9984\n",
      "Epoch 682/1000\n",
      " - 1s - loss: 5.7224e-05 - accuracy: 0.9983\n",
      "Epoch 683/1000\n",
      " - 1s - loss: 8.5765e-05 - accuracy: 0.9975\n",
      "Epoch 684/1000\n",
      " - 1s - loss: 4.3998e-05 - accuracy: 0.9986\n",
      "Epoch 685/1000\n",
      " - 1s - loss: 3.5559e-05 - accuracy: 0.9988\n",
      "Epoch 686/1000\n",
      " - 1s - loss: 3.5298e-05 - accuracy: 0.9988\n",
      "Epoch 687/1000\n",
      " - 1s - loss: 3.4883e-05 - accuracy: 0.9988\n",
      "Epoch 688/1000\n",
      " - 1s - loss: 3.4750e-05 - accuracy: 0.9988\n",
      "Epoch 689/1000\n",
      " - 1s - loss: 3.4713e-05 - accuracy: 0.9988\n",
      "Epoch 690/1000\n",
      " - 1s - loss: 3.4419e-05 - accuracy: 0.9988\n",
      "Epoch 691/1000\n",
      " - 1s - loss: 3.4352e-05 - accuracy: 0.9988\n",
      "Epoch 692/1000\n",
      " - 1s - loss: 3.4315e-05 - accuracy: 0.9988\n",
      "Epoch 693/1000\n",
      " - 1s - loss: 3.4125e-05 - accuracy: 0.9988\n",
      "Epoch 694/1000\n",
      " - 1s - loss: 3.4016e-05 - accuracy: 0.9988\n",
      "Epoch 695/1000\n",
      " - 1s - loss: 3.3988e-05 - accuracy: 0.9988\n",
      "Epoch 696/1000\n",
      " - 1s - loss: 3.4017e-05 - accuracy: 0.9988\n",
      "Epoch 697/1000\n",
      " - 1s - loss: 3.4694e-05 - accuracy: 0.9988\n",
      "Epoch 698/1000\n",
      " - 1s - loss: 3.4900e-05 - accuracy: 0.9988\n",
      "Epoch 699/1000\n",
      " - 1s - loss: 3.5225e-05 - accuracy: 0.9988\n",
      "Epoch 700/1000\n",
      " - 1s - loss: 3.5021e-05 - accuracy: 0.9988\n",
      "Epoch 701/1000\n",
      " - 1s - loss: 3.4393e-05 - accuracy: 0.9989\n",
      "Epoch 702/1000\n",
      " - 1s - loss: 3.3824e-05 - accuracy: 0.9989\n",
      "Epoch 703/1000\n",
      " - 1s - loss: 3.3563e-05 - accuracy: 0.9989\n",
      "Epoch 704/1000\n",
      " - 1s - loss: 3.3321e-05 - accuracy: 0.9989\n",
      "Epoch 705/1000\n",
      " - 1s - loss: 3.2630e-05 - accuracy: 0.9989\n",
      "Epoch 706/1000\n",
      " - 1s - loss: 3.4651e-05 - accuracy: 0.9989\n",
      "Epoch 707/1000\n",
      " - 1s - loss: 3.6667e-05 - accuracy: 0.9988\n",
      "Epoch 708/1000\n",
      " - 1s - loss: 6.7411e-04 - accuracy: 0.9833\n",
      "Epoch 709/1000\n",
      " - 1s - loss: 2.8375e-04 - accuracy: 0.9928\n",
      "Epoch 710/1000\n",
      " - 1s - loss: 1.4292e-04 - accuracy: 0.9965\n",
      "Epoch 711/1000\n",
      " - 1s - loss: 9.5382e-05 - accuracy: 0.9974\n",
      "Epoch 712/1000\n",
      " - 1s - loss: 6.8728e-05 - accuracy: 0.9980\n",
      "Epoch 713/1000\n",
      " - 1s - loss: 5.2387e-05 - accuracy: 0.9985\n",
      "Epoch 714/1000\n",
      " - 1s - loss: 6.3323e-05 - accuracy: 0.9982\n",
      "Epoch 715/1000\n",
      " - 1s - loss: 7.3746e-05 - accuracy: 0.9980\n",
      "Epoch 716/1000\n",
      " - 1s - loss: 5.7620e-05 - accuracy: 0.9984\n",
      "Epoch 717/1000\n",
      " - 1s - loss: 3.8708e-05 - accuracy: 0.9988\n",
      "Epoch 718/1000\n",
      " - 1s - loss: 3.8645e-05 - accuracy: 0.9988\n",
      "Epoch 719/1000\n",
      " - 1s - loss: 3.6794e-05 - accuracy: 0.9988\n",
      "Epoch 720/1000\n",
      " - 1s - loss: 3.6696e-05 - accuracy: 0.9988\n",
      "Epoch 721/1000\n",
      " - 1s - loss: 3.7050e-05 - accuracy: 0.9988\n",
      "Epoch 722/1000\n",
      " - 1s - loss: 3.6082e-05 - accuracy: 0.9988\n",
      "Epoch 723/1000\n",
      " - 1s - loss: 3.5857e-05 - accuracy: 0.9988\n",
      "Epoch 724/1000\n",
      " - 1s - loss: 3.5800e-05 - accuracy: 0.9988\n",
      "Epoch 725/1000\n",
      " - 1s - loss: 3.5735e-05 - accuracy: 0.9988\n",
      "Epoch 726/1000\n",
      " - 1s - loss: 3.5666e-05 - accuracy: 0.9988\n",
      "Epoch 727/1000\n",
      " - 1s - loss: 3.5613e-05 - accuracy: 0.9988\n",
      "Epoch 728/1000\n",
      " - 1s - loss: 3.5548e-05 - accuracy: 0.9988\n",
      "Epoch 729/1000\n",
      " - 1s - loss: 3.5509e-05 - accuracy: 0.9988\n",
      "Epoch 730/1000\n",
      " - 1s - loss: 3.5476e-05 - accuracy: 0.9988\n",
      "Epoch 731/1000\n",
      " - 1s - loss: 3.5455e-05 - accuracy: 0.9988\n",
      "Epoch 732/1000\n",
      " - 1s - loss: 3.5458e-05 - accuracy: 0.9988\n",
      "Epoch 733/1000\n",
      " - 1s - loss: 3.5450e-05 - accuracy: 0.9988\n",
      "Epoch 734/1000\n",
      " - 1s - loss: 3.5474e-05 - accuracy: 0.9988\n",
      "Epoch 735/1000\n",
      " - 1s - loss: 3.5451e-05 - accuracy: 0.9988\n",
      "Epoch 736/1000\n",
      " - 1s - loss: 3.5448e-05 - accuracy: 0.9988\n",
      "Epoch 737/1000\n",
      " - 1s - loss: 3.5455e-05 - accuracy: 0.9988\n",
      "Epoch 738/1000\n",
      " - 1s - loss: 3.5564e-05 - accuracy: 0.9988\n",
      "Epoch 739/1000\n",
      " - 1s - loss: 5.9273e-04 - accuracy: 0.9856\n",
      "Epoch 740/1000\n",
      " - 1s - loss: 2.4646e-04 - accuracy: 0.9936\n",
      "Epoch 741/1000\n",
      " - 1s - loss: 2.3553e-04 - accuracy: 0.9939\n",
      "Epoch 742/1000\n",
      " - 1s - loss: 2.9852e-04 - accuracy: 0.9923\n",
      "Epoch 743/1000\n",
      " - 1s - loss: 7.6218e-05 - accuracy: 0.9979\n",
      "Epoch 744/1000\n",
      " - 1s - loss: 1.2247e-04 - accuracy: 0.9967\n",
      "Epoch 745/1000\n",
      " - 1s - loss: 1.4585e-04 - accuracy: 0.9959\n",
      "Epoch 746/1000\n",
      " - 1s - loss: 5.2347e-05 - accuracy: 0.9983\n",
      "Epoch 747/1000\n",
      " - 1s - loss: 3.6615e-05 - accuracy: 0.9988\n",
      "Epoch 748/1000\n",
      " - 1s - loss: 3.6151e-05 - accuracy: 0.9988\n",
      "Epoch 749/1000\n",
      " - 1s - loss: 3.6010e-05 - accuracy: 0.9988\n",
      "Epoch 750/1000\n",
      " - 1s - loss: 3.5938e-05 - accuracy: 0.9988\n",
      "Epoch 751/1000\n",
      " - 1s - loss: 3.5913e-05 - accuracy: 0.9988\n",
      "Epoch 752/1000\n",
      " - 1s - loss: 3.5795e-05 - accuracy: 0.9988\n",
      "Epoch 753/1000\n",
      " - 1s - loss: 3.5742e-05 - accuracy: 0.9988\n",
      "Epoch 754/1000\n",
      " - 1s - loss: 3.5708e-05 - accuracy: 0.9988\n",
      "Epoch 755/1000\n",
      " - 1s - loss: 3.5679e-05 - accuracy: 0.9988\n",
      "Epoch 756/1000\n",
      " - 1s - loss: 3.5622e-05 - accuracy: 0.9988\n",
      "Epoch 757/1000\n",
      " - 1s - loss: 3.5593e-05 - accuracy: 0.9988\n",
      "Epoch 758/1000\n",
      " - 1s - loss: 3.5566e-05 - accuracy: 0.9988\n",
      "Epoch 759/1000\n",
      " - 1s - loss: 3.5549e-05 - accuracy: 0.9988\n",
      "Epoch 760/1000\n",
      " - 1s - loss: 3.5522e-05 - accuracy: 0.9988\n",
      "Epoch 761/1000\n",
      " - 1s - loss: 3.5519e-05 - accuracy: 0.9988\n",
      "Epoch 762/1000\n",
      " - 1s - loss: 3.5504e-05 - accuracy: 0.9988\n",
      "Epoch 763/1000\n",
      " - 1s - loss: 3.5510e-05 - accuracy: 0.9988\n",
      "Epoch 764/1000\n",
      " - 1s - loss: 3.5520e-05 - accuracy: 0.9988\n",
      "Epoch 765/1000\n",
      " - 1s - loss: 3.5518e-05 - accuracy: 0.9988\n",
      "Epoch 766/1000\n",
      " - 1s - loss: 3.5543e-05 - accuracy: 0.9988\n",
      "Epoch 767/1000\n",
      " - 1s - loss: 3.5555e-05 - accuracy: 0.9988\n",
      "Epoch 768/1000\n",
      " - 1s - loss: 3.5586e-05 - accuracy: 0.9988\n",
      "Epoch 769/1000\n",
      " - 1s - loss: 3.5567e-05 - accuracy: 0.9988\n",
      "Epoch 770/1000\n",
      " - 1s - loss: 3.5778e-05 - accuracy: 0.9988\n",
      "Epoch 771/1000\n",
      " - 1s - loss: 3.5860e-05 - accuracy: 0.9988\n",
      "Epoch 772/1000\n",
      " - 1s - loss: 3.5898e-05 - accuracy: 0.9988\n",
      "Epoch 773/1000\n",
      " - 1s - loss: 2.2538e-04 - accuracy: 0.9943\n",
      "Epoch 774/1000\n",
      " - 1s - loss: 6.1046e-04 - accuracy: 0.9850\n",
      "Epoch 775/1000\n",
      " - 1s - loss: 1.9424e-04 - accuracy: 0.9951\n",
      "Epoch 776/1000\n",
      " - 1s - loss: 1.5935e-04 - accuracy: 0.9958\n",
      "Epoch 777/1000\n",
      " - 1s - loss: 1.7507e-04 - accuracy: 0.9956\n",
      "Epoch 778/1000\n",
      " - 1s - loss: 1.5099e-04 - accuracy: 0.9962\n",
      "Epoch 779/1000\n",
      " - 1s - loss: 7.8629e-05 - accuracy: 0.9978\n",
      "Epoch 780/1000\n",
      " - 1s - loss: 6.0701e-05 - accuracy: 0.9981\n",
      "Epoch 781/1000\n",
      " - 1s - loss: 5.0206e-05 - accuracy: 0.9986\n",
      "Epoch 782/1000\n",
      " - 1s - loss: 4.0875e-05 - accuracy: 0.9987\n",
      "Epoch 783/1000\n",
      " - 1s - loss: 4.0619e-05 - accuracy: 0.9987\n",
      "Epoch 784/1000\n",
      " - 1s - loss: 4.0377e-05 - accuracy: 0.9987\n",
      "Epoch 785/1000\n",
      " - 1s - loss: 4.0278e-05 - accuracy: 0.9987\n",
      "Epoch 786/1000\n",
      " - 1s - loss: 4.0174e-05 - accuracy: 0.9987\n",
      "Epoch 787/1000\n",
      " - 1s - loss: 4.0181e-05 - accuracy: 0.9987\n",
      "Epoch 788/1000\n",
      " - 1s - loss: 4.0167e-05 - accuracy: 0.9987\n",
      "Epoch 789/1000\n",
      " - 1s - loss: 4.0154e-05 - accuracy: 0.9987\n",
      "Epoch 790/1000\n",
      " - 1s - loss: 4.0024e-05 - accuracy: 0.9987\n",
      "Epoch 791/1000\n",
      " - 1s - loss: 4.0063e-05 - accuracy: 0.9987\n",
      "Epoch 792/1000\n",
      " - 1s - loss: 4.0151e-05 - accuracy: 0.9987\n",
      "Epoch 793/1000\n",
      " - 1s - loss: 4.0276e-05 - accuracy: 0.9987\n",
      "Epoch 794/1000\n",
      " - 1s - loss: 4.0104e-05 - accuracy: 0.9987\n",
      "Epoch 795/1000\n",
      " - 1s - loss: 4.0180e-05 - accuracy: 0.9987\n",
      "Epoch 796/1000\n",
      " - 1s - loss: 4.0502e-05 - accuracy: 0.9987\n",
      "Epoch 797/1000\n",
      " - 1s - loss: 4.0891e-05 - accuracy: 0.9987\n",
      "Epoch 798/1000\n",
      " - 1s - loss: 4.0705e-05 - accuracy: 0.9987\n",
      "Epoch 799/1000\n",
      " - 1s - loss: 4.1095e-05 - accuracy: 0.9987\n",
      "Epoch 800/1000\n",
      " - 1s - loss: 3.8089e-05 - accuracy: 0.9988\n",
      "Epoch 801/1000\n",
      " - 1s - loss: 4.0087e-05 - accuracy: 0.9988\n",
      "Epoch 802/1000\n",
      " - 1s - loss: 4.7646e-04 - accuracy: 0.9884\n",
      "Epoch 803/1000\n",
      " - 1s - loss: 4.0139e-04 - accuracy: 0.9899\n",
      "Epoch 804/1000\n",
      " - 1s - loss: 1.5425e-04 - accuracy: 0.9960\n",
      "Epoch 805/1000\n",
      " - 1s - loss: 9.3755e-05 - accuracy: 0.9973\n",
      "Epoch 806/1000\n",
      " - 1s - loss: 1.1017e-04 - accuracy: 0.9970\n",
      "Epoch 807/1000\n",
      " - 1s - loss: 7.0765e-05 - accuracy: 0.9981\n",
      "Epoch 808/1000\n",
      " - 1s - loss: 4.9278e-05 - accuracy: 0.9986\n",
      "Epoch 809/1000\n",
      " - 1s - loss: 3.6041e-05 - accuracy: 0.9988\n",
      "Epoch 810/1000\n",
      " - 1s - loss: 3.3846e-05 - accuracy: 0.9989\n",
      "Epoch 811/1000\n",
      " - 1s - loss: 3.3695e-05 - accuracy: 0.9989\n",
      "Epoch 812/1000\n",
      " - 1s - loss: 3.2578e-05 - accuracy: 0.9989\n",
      "Epoch 813/1000\n",
      " - 1s - loss: 3.2344e-05 - accuracy: 0.9989\n",
      "Epoch 814/1000\n",
      " - 1s - loss: 3.2465e-05 - accuracy: 0.9989\n",
      "Epoch 815/1000\n",
      " - 1s - loss: 3.2444e-05 - accuracy: 0.9989\n",
      "Epoch 816/1000\n",
      " - 1s - loss: 3.2227e-05 - accuracy: 0.9989\n",
      "Epoch 817/1000\n",
      " - 1s - loss: 3.2125e-05 - accuracy: 0.9989\n",
      "Epoch 818/1000\n",
      " - 1s - loss: 3.1936e-05 - accuracy: 0.9989\n",
      "Epoch 819/1000\n",
      " - 1s - loss: 3.1961e-05 - accuracy: 0.9989\n",
      "Epoch 820/1000\n",
      " - 1s - loss: 3.1917e-05 - accuracy: 0.9989\n",
      "Epoch 821/1000\n",
      " - 1s - loss: 3.1874e-05 - accuracy: 0.9989\n",
      "Epoch 822/1000\n",
      " - 1s - loss: 3.1863e-05 - accuracy: 0.9989\n",
      "Epoch 823/1000\n",
      " - 1s - loss: 3.1979e-05 - accuracy: 0.9989\n",
      "Epoch 824/1000\n",
      " - 1s - loss: 3.2263e-05 - accuracy: 0.9989\n",
      "Epoch 825/1000\n",
      " - 1s - loss: 3.2227e-05 - accuracy: 0.9989\n",
      "Epoch 826/1000\n",
      " - 1s - loss: 3.2996e-05 - accuracy: 0.9989\n",
      "Epoch 827/1000\n",
      " - 1s - loss: 3.2258e-05 - accuracy: 0.9989\n",
      "Epoch 828/1000\n",
      " - 1s - loss: 3.3233e-05 - accuracy: 0.9989\n",
      "Epoch 829/1000\n",
      " - 1s - loss: 3.2697e-05 - accuracy: 0.9989\n",
      "Epoch 830/1000\n",
      " - 1s - loss: 3.2923e-05 - accuracy: 0.9989\n",
      "Epoch 831/1000\n",
      " - 1s - loss: 3.3167e-05 - accuracy: 0.9989\n",
      "Epoch 832/1000\n",
      " - 1s - loss: 3.2469e-05 - accuracy: 0.9989\n",
      "Epoch 833/1000\n",
      " - 1s - loss: 3.2384e-05 - accuracy: 0.9989\n",
      "Epoch 834/1000\n",
      " - 1s - loss: 3.2566e-05 - accuracy: 0.9989\n",
      "Epoch 835/1000\n",
      " - 1s - loss: 3.3317e-05 - accuracy: 0.9989\n",
      "Epoch 836/1000\n",
      " - 1s - loss: 3.3361e-05 - accuracy: 0.9989\n",
      "Epoch 837/1000\n",
      " - 1s - loss: 3.3088e-05 - accuracy: 0.9989\n",
      "Epoch 838/1000\n",
      " - 1s - loss: 3.8038e-04 - accuracy: 0.9905\n",
      "Epoch 839/1000\n",
      " - 1s - loss: 3.2136e-04 - accuracy: 0.9921\n",
      "Epoch 840/1000\n",
      " - 1s - loss: 1.3823e-04 - accuracy: 0.9963\n",
      "Epoch 841/1000\n",
      " - 1s - loss: 7.0183e-05 - accuracy: 0.9980\n",
      "Epoch 842/1000\n",
      " - 1s - loss: 1.6080e-04 - accuracy: 0.9955\n",
      "Epoch 843/1000\n",
      " - 1s - loss: 1.5755e-04 - accuracy: 0.9961\n",
      "Epoch 844/1000\n",
      " - 1s - loss: 6.7948e-05 - accuracy: 0.9979\n",
      "Epoch 845/1000\n",
      " - 1s - loss: 6.9958e-05 - accuracy: 0.9979\n",
      "Epoch 846/1000\n",
      " - 1s - loss: 7.6564e-05 - accuracy: 0.9976\n",
      "Epoch 847/1000\n",
      " - 1s - loss: 3.9532e-05 - accuracy: 0.9988\n",
      "Epoch 848/1000\n",
      " - 1s - loss: 3.9468e-05 - accuracy: 0.9987\n",
      "Epoch 849/1000\n",
      " - 1s - loss: 4.6441e-05 - accuracy: 0.9986\n",
      "Epoch 850/1000\n",
      " - 1s - loss: 3.8467e-05 - accuracy: 0.9987\n",
      "Epoch 851/1000\n",
      " - 1s - loss: 5.1660e-05 - accuracy: 0.9984\n",
      "Epoch 852/1000\n",
      " - 1s - loss: 4.2080e-05 - accuracy: 0.9986\n",
      "Epoch 853/1000\n",
      " - 1s - loss: 4.1586e-05 - accuracy: 0.9986\n",
      "Epoch 854/1000\n",
      " - 1s - loss: 3.2860e-05 - accuracy: 0.9989\n",
      "Epoch 855/1000\n",
      " - 1s - loss: 3.1923e-05 - accuracy: 0.9989\n",
      "Epoch 856/1000\n",
      " - 1s - loss: 3.1777e-05 - accuracy: 0.9989\n",
      "Epoch 857/1000\n",
      " - 1s - loss: 3.1693e-05 - accuracy: 0.9989\n",
      "Epoch 858/1000\n",
      " - 1s - loss: 3.1638e-05 - accuracy: 0.9989\n",
      "Epoch 859/1000\n",
      " - 1s - loss: 3.1613e-05 - accuracy: 0.9989\n",
      "Epoch 860/1000\n",
      " - 1s - loss: 3.1559e-05 - accuracy: 0.9989\n",
      "Epoch 861/1000\n",
      " - 1s - loss: 3.1526e-05 - accuracy: 0.9989\n",
      "Epoch 862/1000\n",
      " - 1s - loss: 3.1486e-05 - accuracy: 0.9989\n",
      "Epoch 863/1000\n",
      " - 1s - loss: 3.1447e-05 - accuracy: 0.9989\n",
      "Epoch 864/1000\n",
      " - 1s - loss: 3.1415e-05 - accuracy: 0.9989\n",
      "Epoch 865/1000\n",
      " - 1s - loss: 3.1316e-05 - accuracy: 0.9989\n",
      "Epoch 866/1000\n",
      " - 1s - loss: 2.9433e-05 - accuracy: 0.9990\n",
      "Epoch 867/1000\n",
      " - 1s - loss: 2.9349e-05 - accuracy: 0.9990\n",
      "Epoch 868/1000\n",
      " - 1s - loss: 2.9312e-05 - accuracy: 0.9990\n",
      "Epoch 869/1000\n",
      " - 1s - loss: 2.9296e-05 - accuracy: 0.9990\n",
      "Epoch 870/1000\n",
      " - 1s - loss: 2.9309e-05 - accuracy: 0.9990\n",
      "Epoch 871/1000\n",
      " - 1s - loss: 2.9285e-05 - accuracy: 0.9990\n",
      "Epoch 872/1000\n",
      " - 1s - loss: 2.9354e-05 - accuracy: 0.9990\n",
      "Epoch 873/1000\n",
      " - 1s - loss: 2.9288e-05 - accuracy: 0.9990\n",
      "Epoch 874/1000\n",
      " - 1s - loss: 2.9304e-05 - accuracy: 0.9990\n",
      "Epoch 875/1000\n",
      " - 1s - loss: 2.9401e-05 - accuracy: 0.9990\n",
      "Epoch 876/1000\n",
      " - 1s - loss: 2.9390e-05 - accuracy: 0.9990\n",
      "Epoch 877/1000\n",
      " - 1s - loss: 2.9333e-05 - accuracy: 0.9990\n",
      "Epoch 878/1000\n",
      " - 1s - loss: 2.9291e-05 - accuracy: 0.9990\n",
      "Epoch 879/1000\n",
      " - 1s - loss: 2.9274e-05 - accuracy: 0.9990\n",
      "Epoch 880/1000\n",
      " - 1s - loss: 2.9290e-05 - accuracy: 0.9990\n",
      "Epoch 881/1000\n",
      " - 1s - loss: 2.9263e-05 - accuracy: 0.9990\n",
      "Epoch 882/1000\n",
      " - 1s - loss: 2.9240e-05 - accuracy: 0.9990\n",
      "Epoch 883/1000\n",
      " - 1s - loss: 2.9251e-05 - accuracy: 0.9990\n",
      "Epoch 884/1000\n",
      " - 1s - loss: 2.9372e-05 - accuracy: 0.9990\n",
      "Epoch 885/1000\n",
      " - 1s - loss: 2.9546e-05 - accuracy: 0.9990\n",
      "Epoch 886/1000\n",
      " - 1s - loss: 2.9347e-05 - accuracy: 0.9990\n",
      "Epoch 887/1000\n",
      " - 1s - loss: 2.9244e-05 - accuracy: 0.9990\n",
      "Epoch 888/1000\n",
      " - 1s - loss: 2.9188e-05 - accuracy: 0.9990\n",
      "Epoch 889/1000\n",
      " - 1s - loss: 2.9186e-05 - accuracy: 0.9990\n",
      "Epoch 890/1000\n",
      " - 1s - loss: 2.9245e-05 - accuracy: 0.9990\n",
      "Epoch 891/1000\n",
      " - 1s - loss: 2.9294e-05 - accuracy: 0.9990\n",
      "Epoch 892/1000\n",
      " - 1s - loss: 2.9228e-05 - accuracy: 0.9990\n",
      "Epoch 893/1000\n",
      " - 1s - loss: 2.9262e-05 - accuracy: 0.9990\n",
      "Epoch 894/1000\n",
      " - 1s - loss: 2.9164e-05 - accuracy: 0.9990\n",
      "Epoch 895/1000\n",
      " - 1s - loss: 2.9293e-05 - accuracy: 0.9990\n",
      "Epoch 896/1000\n",
      " - 1s - loss: 1.6769e-04 - accuracy: 0.9957\n",
      "Epoch 897/1000\n",
      " - 1s - loss: 9.1215e-04 - accuracy: 0.9788\n",
      "Epoch 898/1000\n",
      " - 1s - loss: 2.7615e-04 - accuracy: 0.9931\n",
      "Epoch 899/1000\n",
      " - 1s - loss: 1.4199e-04 - accuracy: 0.9963\n",
      "Epoch 900/1000\n",
      " - 1s - loss: 8.8300e-05 - accuracy: 0.9974\n",
      "Epoch 901/1000\n",
      " - 1s - loss: 5.7448e-05 - accuracy: 0.9984\n",
      "Epoch 902/1000\n",
      " - 1s - loss: 4.2220e-05 - accuracy: 0.9987\n",
      "Epoch 903/1000\n",
      " - 1s - loss: 4.5125e-05 - accuracy: 0.9986\n",
      "Epoch 904/1000\n",
      " - 1s - loss: 6.5101e-05 - accuracy: 0.9982\n",
      "Epoch 905/1000\n",
      " - 1s - loss: 4.5046e-05 - accuracy: 0.9986\n",
      "Epoch 906/1000\n",
      " - 1s - loss: 6.7777e-05 - accuracy: 0.9980\n",
      "Epoch 907/1000\n",
      " - 1s - loss: 7.8688e-05 - accuracy: 0.9978\n",
      "Epoch 908/1000\n",
      " - 1s - loss: 1.7194e-04 - accuracy: 0.9955\n",
      "Epoch 909/1000\n",
      " - 1s - loss: 6.2211e-05 - accuracy: 0.9981\n",
      "Epoch 910/1000\n",
      " - 1s - loss: 8.6264e-05 - accuracy: 0.9976\n",
      "Epoch 911/1000\n",
      " - 1s - loss: 8.7657e-05 - accuracy: 0.9976\n",
      "Epoch 912/1000\n",
      " - 1s - loss: 1.1705e-04 - accuracy: 0.9967\n",
      "Epoch 913/1000\n",
      " - 1s - loss: 5.8824e-05 - accuracy: 0.9982\n",
      "Epoch 914/1000\n",
      " - 1s - loss: 6.1599e-05 - accuracy: 0.9983\n",
      "Epoch 915/1000\n",
      " - 1s - loss: 4.1468e-05 - accuracy: 0.9987\n",
      "Epoch 916/1000\n",
      " - 1s - loss: 3.7237e-05 - accuracy: 0.9988\n",
      "Epoch 917/1000\n",
      " - 1s - loss: 3.5666e-05 - accuracy: 0.9989\n",
      "Epoch 918/1000\n",
      " - 1s - loss: 3.5562e-05 - accuracy: 0.9989\n",
      "Epoch 919/1000\n",
      " - 1s - loss: 3.1268e-05 - accuracy: 0.9990\n",
      "Epoch 920/1000\n",
      " - 1s - loss: 3.1153e-05 - accuracy: 0.9990\n",
      "Epoch 921/1000\n",
      " - 1s - loss: 4.3437e-05 - accuracy: 0.9986\n",
      "Epoch 922/1000\n",
      " - 1s - loss: 1.4340e-04 - accuracy: 0.9960\n",
      "Epoch 923/1000\n",
      " - 1s - loss: 2.8371e-04 - accuracy: 0.9931\n",
      "Epoch 924/1000\n",
      " - 1s - loss: 1.0857e-04 - accuracy: 0.9969\n",
      "Epoch 925/1000\n",
      " - 1s - loss: 8.2574e-05 - accuracy: 0.9977\n",
      "Epoch 926/1000\n",
      " - 1s - loss: 6.9529e-05 - accuracy: 0.9980\n",
      "Epoch 927/1000\n",
      " - 1s - loss: 1.4464e-04 - accuracy: 0.9963\n",
      "Epoch 928/1000\n",
      " - 1s - loss: 4.6291e-05 - accuracy: 0.9986\n",
      "Epoch 929/1000\n",
      " - 1s - loss: 3.5391e-05 - accuracy: 0.9989\n",
      "Epoch 930/1000\n",
      " - 1s - loss: 3.5211e-05 - accuracy: 0.9989\n",
      "Epoch 931/1000\n",
      " - 1s - loss: 3.5156e-05 - accuracy: 0.9989\n",
      "Epoch 932/1000\n",
      " - 1s - loss: 3.5129e-05 - accuracy: 0.9989\n",
      "Epoch 933/1000\n",
      " - 1s - loss: 3.5113e-05 - accuracy: 0.9989\n",
      "Epoch 934/1000\n",
      " - 1s - loss: 3.5110e-05 - accuracy: 0.9989\n",
      "Epoch 935/1000\n",
      " - 1s - loss: 3.5105e-05 - accuracy: 0.9989\n",
      "Epoch 936/1000\n",
      " - 1s - loss: 3.5088e-05 - accuracy: 0.9989\n",
      "Epoch 937/1000\n",
      " - 1s - loss: 3.5084e-05 - accuracy: 0.9989\n",
      "Epoch 938/1000\n",
      " - 1s - loss: 3.5074e-05 - accuracy: 0.9989\n",
      "Epoch 939/1000\n",
      " - 1s - loss: 3.5061e-05 - accuracy: 0.9989\n",
      "Epoch 940/1000\n",
      " - 1s - loss: 3.5050e-05 - accuracy: 0.9989\n",
      "Epoch 941/1000\n",
      " - 1s - loss: 3.5044e-05 - accuracy: 0.9989\n",
      "Epoch 942/1000\n",
      " - 1s - loss: 3.5022e-05 - accuracy: 0.9989\n",
      "Epoch 943/1000\n",
      " - 1s - loss: 3.5009e-05 - accuracy: 0.9989\n",
      "Epoch 944/1000\n",
      " - 1s - loss: 3.4994e-05 - accuracy: 0.9989\n",
      "Epoch 945/1000\n",
      " - 1s - loss: 3.4978e-05 - accuracy: 0.9989\n",
      "Epoch 946/1000\n",
      " - 1s - loss: 3.4975e-05 - accuracy: 0.9989\n",
      "Epoch 947/1000\n",
      " - 1s - loss: 3.1021e-05 - accuracy: 0.9990\n",
      "Epoch 948/1000\n",
      " - 1s - loss: 3.1031e-05 - accuracy: 0.9990\n",
      "Epoch 949/1000\n",
      " - 1s - loss: 3.1034e-05 - accuracy: 0.9990\n",
      "Epoch 950/1000\n",
      " - 1s - loss: 3.1059e-05 - accuracy: 0.9990\n",
      "Epoch 951/1000\n",
      " - 1s - loss: 3.1054e-05 - accuracy: 0.9990\n",
      "Epoch 952/1000\n",
      " - 1s - loss: 3.1041e-05 - accuracy: 0.9990\n",
      "Epoch 953/1000\n",
      " - 1s - loss: 3.1015e-05 - accuracy: 0.9990\n",
      "Epoch 954/1000\n",
      " - 1s - loss: 3.0978e-05 - accuracy: 0.9990\n",
      "Epoch 955/1000\n",
      " - 1s - loss: 3.0994e-05 - accuracy: 0.9990\n",
      "Epoch 956/1000\n",
      " - 1s - loss: 3.0981e-05 - accuracy: 0.9990\n",
      "Epoch 957/1000\n",
      " - 1s - loss: 3.0986e-05 - accuracy: 0.9990\n",
      "Epoch 958/1000\n",
      " - 1s - loss: 3.0991e-05 - accuracy: 0.9990\n",
      "Epoch 959/1000\n",
      " - 1s - loss: 3.1000e-05 - accuracy: 0.9990\n",
      "Epoch 960/1000\n",
      " - 1s - loss: 3.0959e-05 - accuracy: 0.9990\n",
      "Epoch 961/1000\n",
      " - 1s - loss: 3.0975e-05 - accuracy: 0.9990\n",
      "Epoch 962/1000\n",
      " - 1s - loss: 3.0974e-05 - accuracy: 0.9990\n",
      "Epoch 963/1000\n",
      " - 1s - loss: 3.1033e-05 - accuracy: 0.9990\n",
      "Epoch 964/1000\n",
      " - 1s - loss: 3.1062e-05 - accuracy: 0.9990\n",
      "Epoch 965/1000\n",
      " - 1s - loss: 3.1026e-05 - accuracy: 0.9990\n",
      "Epoch 966/1000\n",
      " - 1s - loss: 3.1105e-05 - accuracy: 0.9990\n",
      "Epoch 967/1000\n",
      " - 1s - loss: 5.2655e-04 - accuracy: 0.9876\n",
      "Epoch 968/1000\n",
      " - 1s - loss: 5.9040e-04 - accuracy: 0.9857\n",
      "Epoch 969/1000\n",
      " - 1s - loss: 2.3739e-04 - accuracy: 0.9941\n",
      "Epoch 970/1000\n",
      " - 1s - loss: 1.0791e-04 - accuracy: 0.9973\n",
      "Epoch 971/1000\n",
      " - 1s - loss: 4.9418e-05 - accuracy: 0.9986\n",
      "Epoch 972/1000\n",
      " - 1s - loss: 4.1152e-05 - accuracy: 0.9987\n",
      "Epoch 973/1000\n",
      " - 1s - loss: 6.2136e-05 - accuracy: 0.9982\n",
      "Epoch 974/1000\n",
      " - 1s - loss: 3.2364e-05 - accuracy: 0.9990\n",
      "Epoch 975/1000\n",
      " - 1s - loss: 2.8118e-05 - accuracy: 0.9991\n",
      "Epoch 976/1000\n",
      " - 1s - loss: 2.7903e-05 - accuracy: 0.9991\n",
      "Epoch 977/1000\n",
      " - 1s - loss: 2.7736e-05 - accuracy: 0.9991\n",
      "Epoch 978/1000\n",
      " - 1s - loss: 2.7568e-05 - accuracy: 0.9991\n",
      "Epoch 979/1000\n",
      " - 1s - loss: 2.7413e-05 - accuracy: 0.9991\n",
      "Epoch 980/1000\n",
      " - 1s - loss: 2.7380e-05 - accuracy: 0.9991\n",
      "Epoch 981/1000\n",
      " - 1s - loss: 2.7328e-05 - accuracy: 0.9991\n",
      "Epoch 982/1000\n",
      " - 1s - loss: 2.7323e-05 - accuracy: 0.9991\n",
      "Epoch 983/1000\n",
      " - 1s - loss: 2.7284e-05 - accuracy: 0.9991\n",
      "Epoch 984/1000\n",
      " - 1s - loss: 2.7247e-05 - accuracy: 0.9991\n",
      "Epoch 985/1000\n",
      " - 1s - loss: 2.7208e-05 - accuracy: 0.9991\n",
      "Epoch 986/1000\n",
      " - 1s - loss: 2.7177e-05 - accuracy: 0.9991\n",
      "Epoch 987/1000\n",
      " - 1s - loss: 2.7141e-05 - accuracy: 0.9991\n",
      "Epoch 988/1000\n",
      " - 1s - loss: 2.7098e-05 - accuracy: 0.9991\n",
      "Epoch 989/1000\n",
      " - 1s - loss: 2.7000e-05 - accuracy: 0.9991\n",
      "Epoch 990/1000\n",
      " - 1s - loss: 2.6864e-05 - accuracy: 0.9991\n",
      "Epoch 991/1000\n",
      " - 1s - loss: 2.8753e-05 - accuracy: 0.9991\n",
      "Epoch 992/1000\n",
      " - 1s - loss: 2.6453e-05 - accuracy: 0.9991\n",
      "Epoch 993/1000\n",
      " - 1s - loss: 2.5049e-05 - accuracy: 0.9991\n",
      "Epoch 994/1000\n",
      " - 1s - loss: 1.8245e-04 - accuracy: 0.9952\n",
      "Epoch 995/1000\n",
      " - 1s - loss: 4.6442e-04 - accuracy: 0.9889\n",
      "Epoch 996/1000\n",
      " - 1s - loss: 2.6609e-04 - accuracy: 0.9937\n",
      "Epoch 997/1000\n",
      " - 1s - loss: 1.8362e-04 - accuracy: 0.9954\n",
      "Epoch 998/1000\n",
      " - 1s - loss: 1.1598e-04 - accuracy: 0.9969\n",
      "Epoch 999/1000\n",
      " - 1s - loss: 7.8728e-05 - accuracy: 0.9980\n",
      "Epoch 1000/1000\n",
      " - 1s - loss: 1.0279e-04 - accuracy: 0.9971\n",
      "score: [0.0011573573117999558, 0.9732211232185364]\n"
     ]
    }
   ],
   "source": [
    "model = leNet()   # alex(), nvidia_model(), leNet()\n",
    "\n",
    "# 9. Fit model on training data\n",
    "history_mask = model.fit(X_train, Y_train, batch_size = 64, epochs=1000, verbose=2)\n",
    "\n",
    "\n",
    "# 10. Evaluate model on test data\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "print(\"score: \"+str(score))\n",
    "\n",
    "model.save('my_modelDec17_sign_best.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "lines_to_next_cell": 2,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_mask.history['accuracy'])\n",
    "plt.title('Training set accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.5",
    "jupytext_version": "1.3.0"
   }
  },
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
