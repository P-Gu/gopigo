{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import regularizers\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "import keras.metrics\n",
    "from tensorflow import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (4.1.2.30)\r\n",
      "Requirement already satisfied: numpy>=1.11.3 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from opencv-python) (1.16.2)\r\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "ws = Workspace.from_config()\n",
    "from azureml.core import Experiment\n",
    "experiment = Experiment(workspace=ws, name=\"Oct25Alex\")\n",
    "\n",
    "!{sys.executable} -m pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modeln = load_model(\"my_modelDec8_n.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'c' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d60f68cd21c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ta\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0;31m#if os.path.basename(root)[-1] == \"w\": wCount += 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;31m#if wCount <= 300 and os.path.basename(root)[-1] == \"w\": continue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'c' is not defined"
     ]
    }
   ],
   "source": [
    "X=[]\n",
    "Y=[]\n",
    "\n",
    "\n",
    "for root, dirs, files in os.walk(\"result\", topdown=True):\n",
    "    for file in files:\n",
    "        if os.path.basename(root)[-2:] != \"ta\":\n",
    "            print(root)\n",
    "            c += 1\n",
    "            #if os.path.basename(root)[-1] == \"w\": wCount += 1\n",
    "            #if wCount <= 300 and os.path.basename(root)[-1] == \"w\": continue\n",
    "            label = os.path.basename(root)[-1]\n",
    "            labelSet.add(label)\n",
    "            img = cv2.imread(os.path.join(root,file))\n",
    "            #plt.imshow(img)\n",
    "            #plt.show()\n",
    "            #img = Image.open(os.path.join(root,file))\n",
    "            \"\"\"\n",
    "       \n",
    "            hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "            lower_black = np.array([0, 0, 0])\n",
    "            upper_black = np.array([359, 100, 100])\n",
    "            mask = cv2.inRange(hsv, lower_black, upper_black)\n",
    "            \n",
    "            #edges = cv2.Canny(mask, 200, 400)\n",
    "            \n",
    "            img = region_of_interest(mask)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "            \"\"\"\n",
    "            \n",
    "            img = cv2.resize(img,(resize,resize))\n",
    "            img = np.asarray(img)\n",
    "            img = img.astype(np.float32)\n",
    "            img = (img / 127.5) - 1\n",
    "            X.append(img)\n",
    "            Y.append(label)\n",
    "            \n",
    "X = np.asarray(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = np.asarray(X)\n",
    "#im = np.expand_dims(img, axis=0)\n",
    "y_prob = model3.predict(X)\n",
    "#print(y_prob[:,0])\n",
    "\n",
    "labelList = [\"a\", \"w\", \"d\"]\n",
    "\n",
    "Y_prob = []\n",
    "\n",
    "for i in range(y_prob.shape[0]):\n",
    "    row = y_prob[i, : ]\n",
    "    index = np.argmax(row)\n",
    "    label = labelList[index]\n",
    "    Y_prob.append(label)\n",
    "\n",
    "print(Y_prob)\n",
    "#print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def region_of_interest(edges):\n",
    "    height, width = edges.shape\n",
    "    mask = np.zeros_like(edges)\n",
    "\n",
    "    # only focus bottom half of the screen\n",
    "    polygon = np.array([[\n",
    "        (0, height * 1 / 2),\n",
    "        (width, height * 1 / 2),\n",
    "        (width, height),\n",
    "        (0, height),\n",
    "    ]], np.int32)\n",
    "\n",
    "    cv2.fillPoly(mask, polygon, 255)\n",
    "    cropped_edges = cv2.bitwise_and(edges, mask)\n",
    "    return cropped_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def nvidia_model():\n",
    "    model = Sequential(name='Nvidia_Model')\n",
    "    \n",
    "    # elu=Expenential Linear Unit, similar to leaky Relu\n",
    "    # skipping 1st hiddel layer (nomralization layer), as we have normalized the data\n",
    "    \n",
    "    # Convolution Layers\n",
    "    model.add(Conv2D(24, (5, 5), strides=(2, 2), input_shape=(66, 200, 3), activation='elu')) \n",
    "    model.add(Conv2D(36, (5, 5), strides=(2, 2), activation='elu')) \n",
    "    model.add(Conv2D(48, (5, 5), strides=(2, 2), activation='elu')) \n",
    "    model.add(Conv2D(64, (3, 3), activation='elu')) \n",
    "    model.add(Dropout(0.2)) # not in original model. added for more robustness\n",
    "    model.add(Conv2D(64, (3, 3), activation='elu')) \n",
    "    \n",
    "    # Fully Connected Layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.2)) # not in original model. added for more robustness\n",
    "    model.add(Dense(100, activation='elu'))\n",
    "    model.add(Dense(50, activation='elu'))\n",
    "    model.add(Dense(10, activation='elu'))\n",
    "    \n",
    "    ## output layer: turn angle (from 45-135, 90 is straight, <90 turn left, >90 turn right)\n",
    "    model.add(Dense(3))#, kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    # since this is a regression problem not classification problem,\n",
    "    # we use MSE (Mean Squared Error) as loss function\n",
    "    optimizer = Adam(lr=1e-4) # lr is learning rate\n",
    "    model.compile(loss='mse', optimizer=optimizer, metrics=[\"accuracy\"]) #keras.metrics.Recall()\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def alex():\n",
    "    #Instantiate an empty model\n",
    "    model = Sequential()\n",
    "\n",
    "    # 1st Convolutional Layer\n",
    "    model.add(Conv2D(filters=96, input_shape=(227,227,3), kernel_size=(11,11), strides=(4,4), padding='valid'))#, kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Activation('relu'))\n",
    "    # Max Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "\n",
    "    # 2nd Convolutional Layer\n",
    "    model.add(Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='same'))#, kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Activation('relu'))\n",
    "    # Max Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "\n",
    "    # 3rd Convolutional Layer\n",
    "    model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))#, kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # 4th Convolutional Layer\n",
    "    model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))#, kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # 5th Convolutional Layer\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))#, kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Activation('relu'))\n",
    "    # Max Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "    # Passing it to a Fully Connected layer\n",
    "    model.add(Flatten())\n",
    "    # 1st Fully Connected Layer\n",
    "    model.add(Dense(4096, input_shape=(227*227*3,)))#, kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Activation('relu'))\n",
    "    # Add Dropout to prevent overfitting\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # 2nd Fully Connected Layer\n",
    "    model.add(Dense(4096))#, kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Activation('relu'))\n",
    "    # Add Dropout\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # 3rd Fully Connected Layer\n",
    "    model.add(Dense(1000))#, kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(Dense(3))#, kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    # Compile the model\n",
    "    opt = Adadelta(learning_rate = 0.005, rho = 0.97)\n",
    "    #model.compile(loss=keras.losses.mean_squared_error, optimizer=opt, metrics=[\"recall\"])\n",
    "    model.compile(loss='mse', optimizer=Adadelta(learning_rate = 0.005, rho = 0.97), metrics=[keras.metrics.Recall()])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def leNet():\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    model.add(Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(32,32,1)))\n",
    "    model.add(AveragePooling2D())\n",
    "\n",
    "    model.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(AveragePooling2D())\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(units=120, activation='relu'))\n",
    "\n",
    "    model.add(Dense(units=84, activation='relu'))\n",
    "\n",
    "    model.add(Dense(units=43, activation = 'softmax'))\n",
    "    \n",
    "    optimizer = Adam(lr=1e-3) # lr is learning rate\n",
    "    model.compile(loss='mse', optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n",
      "180\n",
      "44\n"
     ]
    }
   ],
   "source": [
    "w=0\n",
    "a=0\n",
    "d=0\n",
    "for root, dirs, files in os.walk(\"Data_sheet\", topdown=True):\n",
    "    for file in files:\n",
    "        label = os.path.basename(root)[-1]\n",
    "        if label==\"w\": w+=1\n",
    "        if label==\"a\": a+=1\n",
    "        if label==\"d\": d+=1\n",
    "\n",
    "print(a)\n",
    "print(w)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "lines_to_next_cell": 2,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n"
     ]
    }
   ],
   "source": [
    "# Go through the file system, get every image, preprocess it and put it into the 4d X array. \n",
    "# Its label goes into Y array and later turned to numerical values.\n",
    "\n",
    "trainPercent = 0.75\n",
    "X = []\n",
    "Y = []\n",
    "resize = 227\n",
    "labelSet = set()\n",
    "count=0\n",
    "wCount = 0\n",
    "c=0\n",
    "\n",
    "nvidia_size = (200,66)\n",
    "alex_size = (227,227)\n",
    "le_size = (32,32)\n",
    "\n",
    "for root, dirs, files in os.walk(\"Data_sheet\", topdown=True):\n",
    "    #if c>=10: break\n",
    "    for file in files:\n",
    "            c += 1\n",
    "        #if not c%3==0: continue\n",
    "        #if os.path.basename(root)[-5] == \"0\" and file[-3:] == \"ppm\":\n",
    "            #if c%300==0: print(c)\n",
    "            #if os.path.basename(root)[-1] == \"w\": wCount += 1\n",
    "            #if os.path.basename(root)[-1] in \"aw\": continue\n",
    "            label = os.path.basename(root)[-1]\n",
    "            #print(label)\n",
    "            labelSet.add(label)\n",
    "            img = cv2.imread(os.path.join(root,file))\n",
    "            #img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            #img = Image.open(os.path.join(root,file))\n",
    "             #This chunk of code lifts the black color from the image and turns the image to grayscale\n",
    "            hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "            lower_black = np.array([0, 0, 0])\n",
    "            upper_black = np.array([359, 100, 70])\n",
    "            mask = cv2.inRange(hsv, lower_black, upper_black)\n",
    "            #edges = cv2.Canny(mask, 200, 400)\n",
    "            img = region_of_interest(mask)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "            \n",
    "            \n",
    "            #plt.imshow(img)\n",
    "            #plt.show()\n",
    "            \n",
    "    #        break\n",
    "            if c%10==0: print(c)\n",
    "            \n",
    "\n",
    "            #Flip track images for data augmentation:\n",
    "            \n",
    "            if label == \"a\":\n",
    "                mirror = cv2.flip(img, 1)\n",
    "                mirror = cv2.resize(mirror,alex_size)\n",
    "                mirror = np.asarray(mirror)\n",
    "                mirror = mirror.astype(np.float32)\n",
    "                mirror = (mirror / 127.5) - 1\n",
    "                X.append(mirror)\n",
    "                Y.append(\"d\")\n",
    "            if label == \"d\":\n",
    "                mirror = cv2.flip(img, 1)\n",
    "                mirror = cv2.resize(mirror,alex_size)\n",
    "                mirror = np.asarray(mirror)\n",
    "                mirror = mirror.astype(np.float32)\n",
    "                mirror = (mirror / 127.5) - 1\n",
    "                X.append(mirror)\n",
    "                Y.append(\"a\")\n",
    "            \n",
    "            \n",
    "            img = cv2.resize(img, alex_size)\n",
    "            #img = np.expand_dims(img, axis = 2)\n",
    "            img = np.asarray(img)\n",
    "            img = img.astype(np.float32)\n",
    "            img = (img / 127.5) - 1\n",
    "            X.append(img)\n",
    "            Y.append(label)\n",
    "\n",
    "#print(labelSet)\n",
    "labelList = list(labelSet)\n",
    "labelList.sort()\n",
    "#print(labelList)\n",
    "labelList = [\"a\", \"w\", \"d\"]\n",
    "\n",
    "for i in range(len(Y)):\n",
    "   #This is not one-hot\n",
    "   l = [0]*len(labelList)\n",
    "   index = labelList.index(Y[i])\n",
    "   l[index] = 1\n",
    "   Y[i] = l\n",
    "\n",
    "\n",
    "X = np.asarray(X)\n",
    "Y = np.asarray(Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " ...\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]]\n",
      "['a', 'w', 'd']\n"
     ]
    }
   ],
   "source": [
    "# Assign random seeds and shuffle\n",
    "np.random.seed(1001)\n",
    "random.set_seed(1001)\n",
    "p = np.random.permutation(X.shape[0])\n",
    "Xn = X[p]\n",
    "Yn = Y[p]\n",
    "\n",
    "print(Y)\n",
    "print(labelList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 1)\n",
      "(32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "np.save(\"X.npy\", X)\n",
    "np.save(\"Y.npy\", Y)\n",
    "\n",
    "X_mean = np.mean(X, axis=0)\n",
    "X_std = np.std(X, axis=0)\n",
    "\n",
    "print(X_mean.shape)\n",
    "print(X_std.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13070, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "X_modified = (X-X_mean)/X_std\n",
    "\n",
    "np.save(\"X_modified.npy\",X_modified)\n",
    "print(X_modified.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(486, 227, 227, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "i = X[2,:,:,:]\n",
    "#i = np.squeeze(i, axis = 2)\n",
    "i = (i+1)*127.5\n",
    "plt.imshow(i)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Separate training set and test set\n",
    "trainPercent = 0.85\n",
    "\n",
    "X_train = Xn[:int(X.shape[0]*trainPercent),:,:,:]\n",
    "X_test = Xn[int(X.shape[0]*trainPercent):,:,:,:]\n",
    "Y_train = Yn[:int(Y.shape[0]*trainPercent),:]\n",
    "Y_test = Yn[int(Y.shape[0]*trainPercent):,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "lines_to_next_cell": 0,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_141 (Conv2D)          (None, 55, 55, 96)        34944     \n",
      "_________________________________________________________________\n",
      "activation_117 (Activation)  (None, 55, 55, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 27, 27, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_142 (Conv2D)          (None, 27, 27, 256)       614656    \n",
      "_________________________________________________________________\n",
      "activation_118 (Activation)  (None, 27, 27, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_143 (Conv2D)          (None, 13, 13, 384)       885120    \n",
      "_________________________________________________________________\n",
      "activation_119 (Activation)  (None, 13, 13, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_144 (Conv2D)          (None, 13, 13, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "activation_120 (Activation)  (None, 13, 13, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_145 (Conv2D)          (None, 13, 13, 256)       884992    \n",
      "_________________________________________________________________\n",
      "activation_121 (Activation)  (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_29 (Flatten)         (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 4096)              37752832  \n",
      "_________________________________________________________________\n",
      "activation_122 (Activation)  (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "activation_123 (Activation)  (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "activation_124 (Activation)  (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 3)                 3003      \n",
      "_________________________________________________________________\n",
      "activation_125 (Activation)  (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 62,381,347\n",
      "Trainable params: 62,381,347\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      " - 2s - loss: 0.2232 - recall_16: 0.0000e+00\n",
      "Epoch 2/1000\n",
      " - 1s - loss: 0.2215 - recall_16: 0.0000e+00\n",
      "Epoch 3/1000\n",
      " - 1s - loss: 0.2225 - recall_16: 0.0000e+00\n",
      "Epoch 4/1000\n",
      " - 1s - loss: 0.2219 - recall_16: 0.0000e+00\n",
      "Epoch 5/1000\n",
      " - 1s - loss: 0.2222 - recall_16: 0.0000e+00\n",
      "Epoch 6/1000\n",
      " - 1s - loss: 0.2220 - recall_16: 0.0000e+00\n",
      "Epoch 7/1000\n",
      " - 1s - loss: 0.2210 - recall_16: 0.0000e+00\n",
      "Epoch 8/1000\n",
      " - 1s - loss: 0.2211 - recall_16: 0.0000e+00\n",
      "Epoch 9/1000\n",
      " - 1s - loss: 0.2219 - recall_16: 0.0000e+00\n",
      "Epoch 10/1000\n",
      " - 1s - loss: 0.2221 - recall_16: 0.0000e+00\n",
      "Epoch 11/1000\n",
      " - 1s - loss: 0.2214 - recall_16: 0.0000e+00\n",
      "Epoch 12/1000\n",
      " - 1s - loss: 0.2210 - recall_16: 0.0000e+00\n",
      "Epoch 13/1000\n",
      " - 1s - loss: 0.2216 - recall_16: 0.0000e+00\n",
      "Epoch 14/1000\n",
      " - 1s - loss: 0.2208 - recall_16: 0.0000e+00\n",
      "Epoch 15/1000\n",
      " - 1s - loss: 0.2213 - recall_16: 0.0000e+00\n",
      "Epoch 16/1000\n",
      " - 1s - loss: 0.2207 - recall_16: 0.0000e+00\n",
      "Epoch 17/1000\n",
      " - 1s - loss: 0.2210 - recall_16: 0.0000e+00\n",
      "Epoch 18/1000\n",
      " - 1s - loss: 0.2203 - recall_16: 0.0000e+00\n",
      "Epoch 19/1000\n",
      " - 1s - loss: 0.2208 - recall_16: 0.0000e+00\n",
      "Epoch 20/1000\n",
      " - 1s - loss: 0.2208 - recall_16: 0.0000e+00\n",
      "Epoch 21/1000\n",
      " - 1s - loss: 0.2207 - recall_16: 0.0000e+00\n",
      "Epoch 22/1000\n",
      " - 1s - loss: 0.2205 - recall_16: 0.0000e+00\n",
      "Epoch 23/1000\n",
      " - 1s - loss: 0.2199 - recall_16: 0.0000e+00\n",
      "Epoch 24/1000\n",
      " - 1s - loss: 0.2204 - recall_16: 0.0000e+00\n",
      "Epoch 25/1000\n",
      " - 1s - loss: 0.2203 - recall_16: 0.0000e+00\n",
      "Epoch 26/1000\n",
      " - 1s - loss: 0.2206 - recall_16: 0.0000e+00\n",
      "Epoch 27/1000\n",
      " - 1s - loss: 0.2210 - recall_16: 0.0000e+00\n",
      "Epoch 28/1000\n",
      " - 1s - loss: 0.2195 - recall_16: 0.0000e+00\n",
      "Epoch 29/1000\n",
      " - 1s - loss: 0.2199 - recall_16: 0.0000e+00\n",
      "Epoch 30/1000\n",
      " - 1s - loss: 0.2201 - recall_16: 0.0000e+00\n",
      "Epoch 31/1000\n",
      " - 1s - loss: 0.2198 - recall_16: 0.0000e+00\n",
      "Epoch 32/1000\n",
      " - 1s - loss: 0.2191 - recall_16: 0.0000e+00\n",
      "Epoch 33/1000\n",
      " - 1s - loss: 0.2191 - recall_16: 0.0000e+00\n",
      "Epoch 34/1000\n",
      " - 1s - loss: 0.2202 - recall_16: 0.0000e+00\n",
      "Epoch 35/1000\n",
      " - 1s - loss: 0.2194 - recall_16: 0.0000e+00\n",
      "Epoch 36/1000\n",
      " - 1s - loss: 0.2200 - recall_16: 0.0000e+00\n",
      "Epoch 37/1000\n",
      " - 1s - loss: 0.2181 - recall_16: 0.0000e+00\n",
      "Epoch 38/1000\n",
      " - 1s - loss: 0.2203 - recall_16: 0.0000e+00\n",
      "Epoch 39/1000\n",
      " - 1s - loss: 0.2183 - recall_16: 0.0000e+00\n",
      "Epoch 40/1000\n",
      " - 1s - loss: 0.2190 - recall_16: 0.0000e+00\n",
      "Epoch 41/1000\n",
      " - 1s - loss: 0.2190 - recall_16: 0.0000e+00\n",
      "Epoch 42/1000\n",
      " - 1s - loss: 0.2190 - recall_16: 0.0000e+00\n",
      "Epoch 43/1000\n",
      " - 1s - loss: 0.2180 - recall_16: 0.0000e+00\n",
      "Epoch 44/1000\n",
      " - 1s - loss: 0.2196 - recall_16: 0.0000e+00\n",
      "Epoch 45/1000\n",
      " - 1s - loss: 0.2182 - recall_16: 0.0000e+00\n",
      "Epoch 46/1000\n",
      " - 1s - loss: 0.2187 - recall_16: 0.0000e+00\n",
      "Epoch 47/1000\n",
      " - 1s - loss: 0.2185 - recall_16: 0.0000e+00\n",
      "Epoch 48/1000\n",
      " - 1s - loss: 0.2181 - recall_16: 0.0000e+00\n",
      "Epoch 49/1000\n",
      " - 1s - loss: 0.2176 - recall_16: 0.0000e+00\n",
      "Epoch 50/1000\n",
      " - 1s - loss: 0.2184 - recall_16: 0.0000e+00\n",
      "Epoch 51/1000\n",
      " - 1s - loss: 0.2169 - recall_16: 0.0000e+00\n",
      "Epoch 52/1000\n",
      " - 1s - loss: 0.2184 - recall_16: 0.0000e+00\n",
      "Epoch 53/1000\n",
      " - 1s - loss: 0.2171 - recall_16: 0.0000e+00\n",
      "Epoch 54/1000\n",
      " - 1s - loss: 0.2166 - recall_16: 0.0000e+00\n",
      "Epoch 55/1000\n",
      " - 1s - loss: 0.2159 - recall_16: 0.0000e+00\n",
      "Epoch 56/1000\n",
      " - 1s - loss: 0.2166 - recall_16: 0.0000e+00\n",
      "Epoch 57/1000\n",
      " - 1s - loss: 0.2166 - recall_16: 0.0000e+00\n",
      "Epoch 58/1000\n",
      " - 1s - loss: 0.2170 - recall_16: 0.0000e+00\n",
      "Epoch 59/1000\n",
      " - 1s - loss: 0.2164 - recall_16: 0.0000e+00\n",
      "Epoch 60/1000\n",
      " - 1s - loss: 0.2164 - recall_16: 0.0000e+00\n",
      "Epoch 61/1000\n",
      " - 1s - loss: 0.2168 - recall_16: 0.0000e+00\n",
      "Epoch 62/1000\n",
      " - 1s - loss: 0.2163 - recall_16: 0.0000e+00\n",
      "Epoch 63/1000\n",
      " - 1s - loss: 0.2152 - recall_16: 0.0000e+00\n",
      "Epoch 64/1000\n",
      " - 1s - loss: 0.2147 - recall_16: 0.0000e+00\n",
      "Epoch 65/1000\n",
      " - 1s - loss: 0.2155 - recall_16: 0.0000e+00\n",
      "Epoch 66/1000\n",
      " - 1s - loss: 0.2142 - recall_16: 0.0000e+00\n",
      "Epoch 67/1000\n",
      " - 1s - loss: 0.2142 - recall_16: 0.0000e+00\n",
      "Epoch 68/1000\n",
      " - 1s - loss: 0.2144 - recall_16: 0.0000e+00\n",
      "Epoch 69/1000\n",
      " - 1s - loss: 0.2152 - recall_16: 0.0000e+00\n",
      "Epoch 70/1000\n",
      " - 1s - loss: 0.2142 - recall_16: 0.0000e+00\n",
      "Epoch 71/1000\n",
      " - 1s - loss: 0.2138 - recall_16: 0.0000e+00\n",
      "Epoch 72/1000\n",
      " - 1s - loss: 0.2134 - recall_16: 0.0000e+00\n",
      "Epoch 73/1000\n",
      " - 1s - loss: 0.2136 - recall_16: 0.0000e+00\n",
      "Epoch 74/1000\n",
      " - 1s - loss: 0.2120 - recall_16: 0.0000e+00\n",
      "Epoch 75/1000\n",
      " - 1s - loss: 0.2128 - recall_16: 0.0000e+00\n",
      "Epoch 76/1000\n",
      " - 1s - loss: 0.2123 - recall_16: 0.0000e+00\n",
      "Epoch 77/1000\n",
      " - 1s - loss: 0.2115 - recall_16: 0.0000e+00\n",
      "Epoch 78/1000\n",
      " - 1s - loss: 0.2129 - recall_16: 0.0000e+00\n",
      "Epoch 79/1000\n",
      " - 1s - loss: 0.2131 - recall_16: 0.0000e+00\n",
      "Epoch 80/1000\n",
      " - 1s - loss: 0.2108 - recall_16: 0.0000e+00\n",
      "Epoch 81/1000\n",
      " - 1s - loss: 0.2117 - recall_16: 0.0000e+00\n",
      "Epoch 82/1000\n",
      " - 1s - loss: 0.2094 - recall_16: 0.0000e+00\n",
      "Epoch 83/1000\n",
      " - 1s - loss: 0.2102 - recall_16: 0.0000e+00\n",
      "Epoch 84/1000\n",
      " - 1s - loss: 0.2087 - recall_16: 0.0000e+00\n",
      "Epoch 85/1000\n",
      " - 1s - loss: 0.2068 - recall_16: 0.0000e+00\n",
      "Epoch 86/1000\n",
      " - 1s - loss: 0.2091 - recall_16: 0.0000e+00\n",
      "Epoch 87/1000\n",
      " - 1s - loss: 0.2070 - recall_16: 0.0000e+00\n",
      "Epoch 88/1000\n",
      " - 1s - loss: 0.2079 - recall_16: 0.0000e+00\n",
      "Epoch 89/1000\n",
      " - 1s - loss: 0.2069 - recall_16: 0.0000e+00\n",
      "Epoch 90/1000\n",
      " - 1s - loss: 0.2056 - recall_16: 0.0000e+00\n",
      "Epoch 91/1000\n",
      " - 1s - loss: 0.2062 - recall_16: 0.0000e+00\n",
      "Epoch 92/1000\n",
      " - 1s - loss: 0.2061 - recall_16: 0.0000e+00\n",
      "Epoch 93/1000\n",
      " - 1s - loss: 0.2041 - recall_16: 0.0024\n",
      "Epoch 94/1000\n",
      " - 1s - loss: 0.2017 - recall_16: 0.0000e+00\n",
      "Epoch 95/1000\n",
      " - 1s - loss: 0.2025 - recall_16: 0.0000e+00\n",
      "Epoch 96/1000\n",
      " - 1s - loss: 0.2018 - recall_16: 0.0048\n",
      "Epoch 97/1000\n",
      " - 1s - loss: 0.2021 - recall_16: 0.0000e+00\n",
      "Epoch 98/1000\n",
      " - 1s - loss: 0.2011 - recall_16: 0.0000e+00\n",
      "Epoch 99/1000\n",
      " - 1s - loss: 0.2010 - recall_16: 0.0073\n",
      "Epoch 100/1000\n",
      " - 1s - loss: 0.1981 - recall_16: 0.0048\n",
      "Epoch 101/1000\n",
      " - 1s - loss: 0.1968 - recall_16: 0.0048\n",
      "Epoch 102/1000\n",
      " - 1s - loss: 0.1981 - recall_16: 0.0121\n",
      "Epoch 103/1000\n",
      " - 1s - loss: 0.1966 - recall_16: 0.0145\n",
      "Epoch 104/1000\n",
      " - 1s - loss: 0.1963 - recall_16: 0.0242\n",
      "Epoch 105/1000\n",
      " - 1s - loss: 0.1928 - recall_16: 0.0242\n",
      "Epoch 106/1000\n",
      " - 1s - loss: 0.1939 - recall_16: 0.0266\n",
      "Epoch 107/1000\n",
      " - 1s - loss: 0.1938 - recall_16: 0.0339\n",
      "Epoch 108/1000\n",
      " - 1s - loss: 0.1904 - recall_16: 0.0291\n",
      "Epoch 109/1000\n",
      " - 1s - loss: 0.1891 - recall_16: 0.0412\n",
      "Epoch 110/1000\n",
      " - 1s - loss: 0.1876 - recall_16: 0.0605\n",
      "Epoch 111/1000\n",
      " - 1s - loss: 0.1832 - recall_16: 0.0847\n",
      "Epoch 112/1000\n",
      " - 1s - loss: 0.1811 - recall_16: 0.1138\n",
      "Epoch 113/1000\n",
      " - 1s - loss: 0.1803 - recall_16: 0.1235\n",
      "Epoch 114/1000\n",
      " - 1s - loss: 0.1798 - recall_16: 0.1671\n",
      "Epoch 115/1000\n",
      " - 1s - loss: 0.1780 - recall_16: 0.1550\n",
      "Epoch 116/1000\n",
      " - 1s - loss: 0.1770 - recall_16: 0.2010\n",
      "Epoch 117/1000\n",
      " - 1s - loss: 0.1732 - recall_16: 0.2470\n",
      "Epoch 118/1000\n",
      " - 1s - loss: 0.1727 - recall_16: 0.2567\n",
      "Epoch 119/1000\n",
      " - 1s - loss: 0.1689 - recall_16: 0.3245\n",
      "Epoch 120/1000\n",
      " - 1s - loss: 0.1691 - recall_16: 0.3148\n",
      "Epoch 121/1000\n",
      " - 1s - loss: 0.1648 - recall_16: 0.3584\n",
      "Epoch 122/1000\n",
      " - 1s - loss: 0.1615 - recall_16: 0.4068\n",
      "Epoch 123/1000\n",
      " - 1s - loss: 0.1582 - recall_16: 0.4310\n",
      "Epoch 124/1000\n",
      " - 1s - loss: 0.1563 - recall_16: 0.4455\n",
      "Epoch 125/1000\n",
      " - 1s - loss: 0.1582 - recall_16: 0.4552\n",
      "Epoch 126/1000\n",
      " - 1s - loss: 0.1531 - recall_16: 0.4939\n",
      "Epoch 127/1000\n",
      " - 1s - loss: 0.1498 - recall_16: 0.5254\n",
      "Epoch 128/1000\n",
      " - 1s - loss: 0.1551 - recall_16: 0.4843\n",
      "Epoch 129/1000\n",
      " - 1s - loss: 0.1446 - recall_16: 0.5521\n",
      "Epoch 130/1000\n",
      " - 1s - loss: 0.1441 - recall_16: 0.5763\n",
      "Epoch 131/1000\n",
      " - 1s - loss: 0.1457 - recall_16: 0.5496\n",
      "Epoch 132/1000\n",
      " - 1s - loss: 0.1381 - recall_16: 0.6053\n",
      "Epoch 133/1000\n",
      " - 1s - loss: 0.1351 - recall_16: 0.6029\n",
      "Epoch 134/1000\n",
      " - 1s - loss: 0.1420 - recall_16: 0.5860\n",
      "Epoch 135/1000\n",
      " - 1s - loss: 0.1390 - recall_16: 0.6077\n",
      "Epoch 136/1000\n",
      " - 1s - loss: 0.1357 - recall_16: 0.6102\n",
      "Epoch 137/1000\n",
      " - 1s - loss: 0.1327 - recall_16: 0.6320\n",
      "Epoch 138/1000\n",
      " - 1s - loss: 0.1244 - recall_16: 0.6634\n",
      "Epoch 139/1000\n",
      " - 1s - loss: 0.1359 - recall_16: 0.6223\n",
      "Epoch 140/1000\n",
      " - 1s - loss: 0.1258 - recall_16: 0.6683\n",
      "Epoch 141/1000\n",
      " - 1s - loss: 0.1317 - recall_16: 0.6271\n",
      "Epoch 142/1000\n",
      " - 1s - loss: 0.1281 - recall_16: 0.6562\n",
      "Epoch 143/1000\n",
      " - 1s - loss: 0.1266 - recall_16: 0.6780\n",
      "Epoch 144/1000\n",
      " - 1s - loss: 0.1302 - recall_16: 0.6441\n",
      "Epoch 145/1000\n",
      " - 1s - loss: 0.1217 - recall_16: 0.6731\n",
      "Epoch 146/1000\n",
      " - 1s - loss: 0.1236 - recall_16: 0.6562\n",
      "Epoch 147/1000\n",
      " - 1s - loss: 0.1275 - recall_16: 0.6562\n",
      "Epoch 148/1000\n",
      " - 1s - loss: 0.1194 - recall_16: 0.6780\n",
      "Epoch 149/1000\n",
      " - 1s - loss: 0.1152 - recall_16: 0.6901\n",
      "Epoch 150/1000\n",
      " - 1s - loss: 0.1275 - recall_16: 0.6586\n",
      "Epoch 151/1000\n",
      " - 1s - loss: 0.1200 - recall_16: 0.6828\n",
      "Epoch 152/1000\n",
      " - 1s - loss: 0.1191 - recall_16: 0.6901\n",
      "Epoch 153/1000\n",
      " - 1s - loss: 0.1136 - recall_16: 0.6998\n",
      "Epoch 154/1000\n",
      " - 1s - loss: 0.1183 - recall_16: 0.6755\n",
      "Epoch 155/1000\n",
      " - 1s - loss: 0.1121 - recall_16: 0.7094\n",
      "Epoch 156/1000\n",
      " - 1s - loss: 0.1179 - recall_16: 0.6998\n",
      "Epoch 157/1000\n",
      " - 1s - loss: 0.1127 - recall_16: 0.7264\n",
      "Epoch 158/1000\n",
      " - 1s - loss: 0.1049 - recall_16: 0.7312\n",
      "Epoch 159/1000\n",
      " - 1s - loss: 0.1129 - recall_16: 0.7070\n",
      "Epoch 160/1000\n",
      " - 1s - loss: 0.1134 - recall_16: 0.7022\n",
      "Epoch 161/1000\n",
      " - 1s - loss: 0.1107 - recall_16: 0.7264\n",
      "Epoch 162/1000\n",
      " - 1s - loss: 0.1076 - recall_16: 0.7167\n",
      "Epoch 163/1000\n",
      " - 1s - loss: 0.0999 - recall_16: 0.7361\n",
      "Epoch 164/1000\n",
      " - 1s - loss: 0.1024 - recall_16: 0.7458\n",
      "Epoch 165/1000\n",
      " - 1s - loss: 0.1031 - recall_16: 0.7409\n",
      "Epoch 166/1000\n",
      " - 1s - loss: 0.1075 - recall_16: 0.7143\n",
      "Epoch 167/1000\n",
      " - 1s - loss: 0.1041 - recall_16: 0.7409\n",
      "Epoch 168/1000\n",
      " - 1s - loss: 0.1010 - recall_16: 0.7312\n",
      "Epoch 169/1000\n",
      " - 1s - loss: 0.1052 - recall_16: 0.7361\n",
      "Epoch 170/1000\n",
      " - 1s - loss: 0.0997 - recall_16: 0.7530\n",
      "Epoch 171/1000\n",
      " - 1s - loss: 0.1055 - recall_16: 0.7264\n",
      "Epoch 172/1000\n",
      " - 1s - loss: 0.1021 - recall_16: 0.7312\n",
      "Epoch 173/1000\n",
      " - 1s - loss: 0.1026 - recall_16: 0.7288\n",
      "Epoch 174/1000\n",
      " - 1s - loss: 0.0961 - recall_16: 0.7579\n",
      "Epoch 175/1000\n",
      " - 1s - loss: 0.0950 - recall_16: 0.7772\n",
      "Epoch 176/1000\n",
      " - 1s - loss: 0.0976 - recall_16: 0.7409\n",
      "Epoch 177/1000\n",
      " - 1s - loss: 0.0971 - recall_16: 0.7676\n",
      "Epoch 178/1000\n",
      " - 1s - loss: 0.0948 - recall_16: 0.7651\n",
      "Epoch 179/1000\n",
      " - 1s - loss: 0.1010 - recall_16: 0.7385\n",
      "Epoch 180/1000\n",
      " - 1s - loss: 0.0971 - recall_16: 0.7700\n",
      "Epoch 181/1000\n",
      " - 1s - loss: 0.0903 - recall_16: 0.7676\n",
      "Epoch 182/1000\n",
      " - 1s - loss: 0.0992 - recall_16: 0.7385\n",
      "Epoch 183/1000\n",
      " - 1s - loss: 0.0983 - recall_16: 0.7651\n",
      "Epoch 184/1000\n",
      " - 1s - loss: 0.0947 - recall_16: 0.7724\n",
      "Epoch 185/1000\n",
      " - 1s - loss: 0.0968 - recall_16: 0.7554\n",
      "Epoch 186/1000\n",
      " - 1s - loss: 0.0937 - recall_16: 0.7724\n",
      "Epoch 187/1000\n",
      " - 1s - loss: 0.0959 - recall_16: 0.7530\n",
      "Epoch 188/1000\n",
      " - 1s - loss: 0.0888 - recall_16: 0.7748\n",
      "Epoch 189/1000\n",
      " - 1s - loss: 0.0924 - recall_16: 0.7676\n",
      "Epoch 190/1000\n",
      " - 1s - loss: 0.0947 - recall_16: 0.7700\n",
      "Epoch 191/1000\n",
      " - 1s - loss: 0.0870 - recall_16: 0.7966\n",
      "Epoch 192/1000\n",
      " - 1s - loss: 0.0948 - recall_16: 0.7676\n",
      "Epoch 193/1000\n",
      " - 1s - loss: 0.0944 - recall_16: 0.7651\n",
      "Epoch 194/1000\n",
      " - 1s - loss: 0.0867 - recall_16: 0.7893\n",
      "Epoch 195/1000\n",
      " - 1s - loss: 0.0917 - recall_16: 0.7724\n",
      "Epoch 196/1000\n",
      " - 1s - loss: 0.0879 - recall_16: 0.7893\n",
      "Epoch 197/1000\n",
      " - 1s - loss: 0.0887 - recall_16: 0.7772\n",
      "Epoch 198/1000\n",
      " - 1s - loss: 0.0873 - recall_16: 0.7724\n",
      "Epoch 199/1000\n",
      " - 1s - loss: 0.0850 - recall_16: 0.8136\n",
      "Epoch 200/1000\n",
      " - 1s - loss: 0.0866 - recall_16: 0.7845\n",
      "Epoch 201/1000\n",
      " - 1s - loss: 0.0887 - recall_16: 0.7966\n",
      "Epoch 202/1000\n",
      " - 1s - loss: 0.0847 - recall_16: 0.7942\n",
      "Epoch 203/1000\n",
      " - 1s - loss: 0.0820 - recall_16: 0.8111\n",
      "Epoch 204/1000\n",
      " - 1s - loss: 0.0831 - recall_16: 0.8015\n",
      "Epoch 205/1000\n",
      " - 1s - loss: 0.0823 - recall_16: 0.7893\n",
      "Epoch 206/1000\n",
      " - 1s - loss: 0.0825 - recall_16: 0.8015\n",
      "Epoch 207/1000\n",
      " - 1s - loss: 0.0823 - recall_16: 0.8063\n",
      "Epoch 208/1000\n",
      " - 1s - loss: 0.0868 - recall_16: 0.7821\n",
      "Epoch 209/1000\n",
      " - 1s - loss: 0.0795 - recall_16: 0.8111\n",
      "Epoch 210/1000\n",
      " - 1s - loss: 0.0811 - recall_16: 0.7942\n",
      "Epoch 211/1000\n",
      " - 1s - loss: 0.0778 - recall_16: 0.8111\n",
      "Epoch 212/1000\n",
      " - 1s - loss: 0.0887 - recall_16: 0.7748\n",
      "Epoch 213/1000\n",
      " - 1s - loss: 0.0820 - recall_16: 0.7845\n",
      "Epoch 214/1000\n",
      " - 1s - loss: 0.0834 - recall_16: 0.7845\n",
      "Epoch 215/1000\n",
      " - 1s - loss: 0.0862 - recall_16: 0.7893\n",
      "Epoch 216/1000\n",
      " - 1s - loss: 0.0815 - recall_16: 0.7966\n",
      "Epoch 217/1000\n",
      " - 1s - loss: 0.0765 - recall_16: 0.8208\n",
      "Epoch 218/1000\n",
      " - 1s - loss: 0.0814 - recall_16: 0.7942\n",
      "Epoch 219/1000\n",
      " - 1s - loss: 0.0833 - recall_16: 0.7942\n",
      "Epoch 220/1000\n",
      " - 1s - loss: 0.0834 - recall_16: 0.8111\n",
      "Epoch 221/1000\n",
      " - 1s - loss: 0.0719 - recall_16: 0.8281\n",
      "Epoch 222/1000\n",
      " - 1s - loss: 0.0766 - recall_16: 0.8136\n",
      "Epoch 223/1000\n",
      " - 1s - loss: 0.0818 - recall_16: 0.7918\n",
      "Epoch 224/1000\n",
      " - 1s - loss: 0.0764 - recall_16: 0.8087\n",
      "Epoch 225/1000\n",
      " - 1s - loss: 0.0737 - recall_16: 0.8111\n",
      "Epoch 226/1000\n",
      " - 1s - loss: 0.0814 - recall_16: 0.8063\n",
      "Epoch 227/1000\n",
      " - 1s - loss: 0.0755 - recall_16: 0.8208\n",
      "Epoch 228/1000\n",
      " - 1s - loss: 0.0808 - recall_16: 0.8039\n",
      "Epoch 229/1000\n",
      " - 1s - loss: 0.0795 - recall_16: 0.8063\n",
      "Epoch 230/1000\n",
      " - 1s - loss: 0.0754 - recall_16: 0.8281\n",
      "Epoch 231/1000\n",
      " - 1s - loss: 0.0786 - recall_16: 0.8160\n",
      "Epoch 232/1000\n",
      " - 1s - loss: 0.0729 - recall_16: 0.8305\n",
      "Epoch 233/1000\n",
      " - 1s - loss: 0.0761 - recall_16: 0.8160\n",
      "Epoch 234/1000\n",
      " - 1s - loss: 0.0750 - recall_16: 0.8208\n",
      "Epoch 235/1000\n",
      " - 1s - loss: 0.0728 - recall_16: 0.8257\n",
      "Epoch 236/1000\n",
      " - 1s - loss: 0.0738 - recall_16: 0.8208\n",
      "Epoch 237/1000\n",
      " - 1s - loss: 0.0741 - recall_16: 0.8329\n",
      "Epoch 238/1000\n",
      " - 1s - loss: 0.0673 - recall_16: 0.8450\n",
      "Epoch 239/1000\n",
      " - 1s - loss: 0.0723 - recall_16: 0.8281\n",
      "Epoch 240/1000\n",
      " - 1s - loss: 0.0756 - recall_16: 0.8184\n",
      "Epoch 241/1000\n",
      " - 1s - loss: 0.0720 - recall_16: 0.8232\n",
      "Epoch 242/1000\n",
      " - 1s - loss: 0.0706 - recall_16: 0.8232\n",
      "Epoch 243/1000\n",
      " - 1s - loss: 0.0723 - recall_16: 0.8208\n",
      "Epoch 244/1000\n",
      " - 1s - loss: 0.0724 - recall_16: 0.8305\n",
      "Epoch 245/1000\n",
      " - 1s - loss: 0.0719 - recall_16: 0.8305\n",
      "Epoch 246/1000\n",
      " - 1s - loss: 0.0729 - recall_16: 0.8160\n",
      "Epoch 247/1000\n",
      " - 1s - loss: 0.0666 - recall_16: 0.8450\n",
      "Epoch 248/1000\n",
      " - 1s - loss: 0.0719 - recall_16: 0.8378\n",
      "Epoch 249/1000\n",
      " - 1s - loss: 0.0690 - recall_16: 0.8184\n",
      "Epoch 250/1000\n",
      " - 1s - loss: 0.0708 - recall_16: 0.8354\n",
      "Epoch 251/1000\n",
      " - 1s - loss: 0.0698 - recall_16: 0.8402\n",
      "Epoch 252/1000\n",
      " - 1s - loss: 0.0669 - recall_16: 0.8426\n",
      "Epoch 253/1000\n",
      " - 1s - loss: 0.0702 - recall_16: 0.8354\n",
      "Epoch 254/1000\n",
      " - 1s - loss: 0.0627 - recall_16: 0.8402\n",
      "Epoch 255/1000\n",
      " - 1s - loss: 0.0674 - recall_16: 0.8402\n",
      "Epoch 256/1000\n",
      " - 1s - loss: 0.0670 - recall_16: 0.8354\n",
      "Epoch 257/1000\n",
      " - 1s - loss: 0.0656 - recall_16: 0.8499\n",
      "Epoch 258/1000\n",
      " - 1s - loss: 0.0682 - recall_16: 0.8329\n",
      "Epoch 259/1000\n",
      " - 1s - loss: 0.0642 - recall_16: 0.8644\n",
      "Epoch 260/1000\n",
      " - 1s - loss: 0.0674 - recall_16: 0.8354\n",
      "Epoch 261/1000\n",
      " - 1s - loss: 0.0716 - recall_16: 0.8257\n",
      "Epoch 262/1000\n",
      " - 1s - loss: 0.0685 - recall_16: 0.8354\n",
      "Epoch 263/1000\n",
      " - 1s - loss: 0.0672 - recall_16: 0.8378\n",
      "Epoch 264/1000\n",
      " - 1s - loss: 0.0673 - recall_16: 0.8475\n",
      "Epoch 265/1000\n",
      " - 1s - loss: 0.0721 - recall_16: 0.8402\n",
      "Epoch 266/1000\n",
      " - 1s - loss: 0.0655 - recall_16: 0.8475\n",
      "Epoch 267/1000\n",
      " - 1s - loss: 0.0635 - recall_16: 0.8571\n",
      "Epoch 268/1000\n",
      " - 1s - loss: 0.0631 - recall_16: 0.8499\n",
      "Epoch 269/1000\n",
      " - 1s - loss: 0.0587 - recall_16: 0.8499\n",
      "Epoch 270/1000\n",
      " - 1s - loss: 0.0637 - recall_16: 0.8475\n",
      "Epoch 271/1000\n",
      " - 1s - loss: 0.0658 - recall_16: 0.8475\n",
      "Epoch 272/1000\n",
      " - 1s - loss: 0.0637 - recall_16: 0.8475\n",
      "Epoch 273/1000\n",
      " - 1s - loss: 0.0628 - recall_16: 0.8402\n",
      "Epoch 274/1000\n",
      " - 1s - loss: 0.0649 - recall_16: 0.8499\n",
      "Epoch 275/1000\n",
      " - 1s - loss: 0.0618 - recall_16: 0.8523\n",
      "Epoch 276/1000\n",
      " - 1s - loss: 0.0646 - recall_16: 0.8450\n",
      "Epoch 277/1000\n",
      " - 1s - loss: 0.0589 - recall_16: 0.8620\n",
      "Epoch 278/1000\n",
      " - 1s - loss: 0.0629 - recall_16: 0.8523\n",
      "Epoch 279/1000\n",
      " - 1s - loss: 0.0618 - recall_16: 0.8450\n",
      "Epoch 280/1000\n",
      " - 1s - loss: 0.0645 - recall_16: 0.8523\n",
      "Epoch 281/1000\n",
      " - 1s - loss: 0.0608 - recall_16: 0.8523\n",
      "Epoch 282/1000\n",
      " - 1s - loss: 0.0664 - recall_16: 0.8402\n",
      "Epoch 283/1000\n",
      " - 1s - loss: 0.0621 - recall_16: 0.8644\n",
      "Epoch 284/1000\n",
      " - 1s - loss: 0.0613 - recall_16: 0.8523\n",
      "Epoch 285/1000\n",
      " - 1s - loss: 0.0577 - recall_16: 0.8668\n",
      "Epoch 286/1000\n",
      " - 1s - loss: 0.0603 - recall_16: 0.8644\n",
      "Epoch 287/1000\n",
      " - 1s - loss: 0.0616 - recall_16: 0.8547\n",
      "Epoch 288/1000\n",
      " - 1s - loss: 0.0583 - recall_16: 0.8596\n",
      "Epoch 289/1000\n",
      " - 1s - loss: 0.0585 - recall_16: 0.8523\n",
      "Epoch 290/1000\n",
      " - 1s - loss: 0.0618 - recall_16: 0.8571\n",
      "Epoch 291/1000\n",
      " - 1s - loss: 0.0565 - recall_16: 0.8644\n",
      "Epoch 292/1000\n",
      " - 1s - loss: 0.0598 - recall_16: 0.8547\n",
      "Epoch 293/1000\n",
      " - 1s - loss: 0.0567 - recall_16: 0.8668\n",
      "Epoch 294/1000\n",
      " - 1s - loss: 0.0559 - recall_16: 0.8620\n",
      "Epoch 295/1000\n",
      " - 1s - loss: 0.0575 - recall_16: 0.8596\n",
      "Epoch 296/1000\n",
      " - 1s - loss: 0.0555 - recall_16: 0.8741\n",
      "Epoch 297/1000\n",
      " - 1s - loss: 0.0613 - recall_16: 0.8523\n",
      "Epoch 298/1000\n",
      " - 1s - loss: 0.0557 - recall_16: 0.8644\n",
      "Epoch 299/1000\n",
      " - 1s - loss: 0.0535 - recall_16: 0.8741\n",
      "Epoch 300/1000\n",
      " - 1s - loss: 0.0560 - recall_16: 0.8838\n",
      "Epoch 301/1000\n",
      " - 1s - loss: 0.0551 - recall_16: 0.8814\n",
      "Epoch 302/1000\n",
      " - 1s - loss: 0.0622 - recall_16: 0.8571\n",
      "Epoch 303/1000\n",
      " - 1s - loss: 0.0548 - recall_16: 0.8692\n",
      "Epoch 304/1000\n",
      " - 1s - loss: 0.0538 - recall_16: 0.8910\n",
      "Epoch 305/1000\n",
      " - 1s - loss: 0.0563 - recall_16: 0.8789\n",
      "Epoch 306/1000\n",
      " - 1s - loss: 0.0571 - recall_16: 0.8741\n",
      "Epoch 307/1000\n",
      " - 1s - loss: 0.0583 - recall_16: 0.8644\n",
      "Epoch 308/1000\n",
      " - 1s - loss: 0.0545 - recall_16: 0.8668\n",
      "Epoch 309/1000\n",
      " - 1s - loss: 0.0529 - recall_16: 0.8692\n",
      "Epoch 310/1000\n",
      " - 1s - loss: 0.0506 - recall_16: 0.8741\n",
      "Epoch 311/1000\n",
      " - 1s - loss: 0.0540 - recall_16: 0.8717\n",
      "Epoch 312/1000\n",
      " - 1s - loss: 0.0538 - recall_16: 0.8741\n",
      "Epoch 313/1000\n",
      " - 1s - loss: 0.0521 - recall_16: 0.8886\n",
      "Epoch 314/1000\n",
      " - 1s - loss: 0.0539 - recall_16: 0.8692\n",
      "Epoch 315/1000\n",
      " - 1s - loss: 0.0540 - recall_16: 0.8814\n",
      "Epoch 316/1000\n",
      " - 1s - loss: 0.0553 - recall_16: 0.8741\n",
      "Epoch 317/1000\n",
      " - 1s - loss: 0.0548 - recall_16: 0.8717\n",
      "Epoch 318/1000\n",
      " - 1s - loss: 0.0535 - recall_16: 0.8741\n",
      "Epoch 319/1000\n",
      " - 1s - loss: 0.0505 - recall_16: 0.8862\n",
      "Epoch 320/1000\n",
      " - 1s - loss: 0.0512 - recall_16: 0.8765\n",
      "Epoch 321/1000\n",
      " - 1s - loss: 0.0523 - recall_16: 0.8741\n",
      "Epoch 322/1000\n",
      " - 1s - loss: 0.0514 - recall_16: 0.8717\n",
      "Epoch 323/1000\n",
      " - 1s - loss: 0.0528 - recall_16: 0.8717\n",
      "Epoch 324/1000\n",
      " - 1s - loss: 0.0527 - recall_16: 0.8789\n",
      "Epoch 325/1000\n",
      " - 1s - loss: 0.0517 - recall_16: 0.8644\n",
      "Epoch 326/1000\n",
      " - 1s - loss: 0.0511 - recall_16: 0.8814\n",
      "Epoch 327/1000\n",
      " - 1s - loss: 0.0525 - recall_16: 0.8717\n",
      "Epoch 328/1000\n",
      " - 1s - loss: 0.0517 - recall_16: 0.8814\n",
      "Epoch 329/1000\n",
      " - 1s - loss: 0.0429 - recall_16: 0.9104\n",
      "Epoch 330/1000\n",
      " - 1s - loss: 0.0494 - recall_16: 0.8765\n",
      "Epoch 331/1000\n",
      " - 1s - loss: 0.0515 - recall_16: 0.8838\n",
      "Epoch 332/1000\n",
      " - 1s - loss: 0.0459 - recall_16: 0.8886\n",
      "Epoch 333/1000\n",
      " - 1s - loss: 0.0529 - recall_16: 0.8765\n",
      "Epoch 334/1000\n",
      " - 1s - loss: 0.0506 - recall_16: 0.8741\n",
      "Epoch 335/1000\n",
      " - 1s - loss: 0.0448 - recall_16: 0.9031\n",
      "Epoch 336/1000\n",
      " - 1s - loss: 0.0476 - recall_16: 0.8935\n",
      "Epoch 337/1000\n",
      " - 1s - loss: 0.0494 - recall_16: 0.8838\n",
      "Epoch 338/1000\n",
      " - 1s - loss: 0.0479 - recall_16: 0.8983\n",
      "Epoch 339/1000\n",
      " - 1s - loss: 0.0468 - recall_16: 0.8935\n",
      "Epoch 340/1000\n",
      " - 1s - loss: 0.0533 - recall_16: 0.8789\n",
      "Epoch 341/1000\n",
      " - 1s - loss: 0.0451 - recall_16: 0.8886\n",
      "Epoch 342/1000\n",
      " - 1s - loss: 0.0486 - recall_16: 0.8935\n",
      "Epoch 343/1000\n",
      " - 1s - loss: 0.0460 - recall_16: 0.8862\n",
      "Epoch 344/1000\n",
      " - 1s - loss: 0.0486 - recall_16: 0.8935\n",
      "Epoch 345/1000\n",
      " - 1s - loss: 0.0467 - recall_16: 0.9007\n",
      "Epoch 346/1000\n",
      " - 1s - loss: 0.0470 - recall_16: 0.8935\n",
      "Epoch 347/1000\n",
      " - 1s - loss: 0.0468 - recall_16: 0.8959\n",
      "Epoch 348/1000\n",
      " - 1s - loss: 0.0478 - recall_16: 0.8886\n",
      "Epoch 349/1000\n",
      " - 1s - loss: 0.0445 - recall_16: 0.9080\n",
      "Epoch 350/1000\n",
      " - 1s - loss: 0.0483 - recall_16: 0.8910\n",
      "Epoch 351/1000\n",
      " - 1s - loss: 0.0440 - recall_16: 0.9104\n",
      "Epoch 352/1000\n",
      " - 1s - loss: 0.0462 - recall_16: 0.8910\n",
      "Epoch 353/1000\n",
      " - 1s - loss: 0.0474 - recall_16: 0.8910\n",
      "Epoch 354/1000\n",
      " - 1s - loss: 0.0494 - recall_16: 0.8814\n",
      "Epoch 355/1000\n",
      " - 1s - loss: 0.0466 - recall_16: 0.8910\n",
      "Epoch 356/1000\n",
      " - 1s - loss: 0.0480 - recall_16: 0.8886\n",
      "Epoch 357/1000\n",
      " - 1s - loss: 0.0448 - recall_16: 0.8935\n",
      "Epoch 358/1000\n",
      " - 1s - loss: 0.0451 - recall_16: 0.8983\n",
      "Epoch 359/1000\n",
      " - 1s - loss: 0.0433 - recall_16: 0.9031\n",
      "Epoch 360/1000\n",
      " - 1s - loss: 0.0448 - recall_16: 0.8983\n",
      "Epoch 361/1000\n",
      " - 1s - loss: 0.0404 - recall_16: 0.9153\n",
      "Epoch 362/1000\n",
      " - 1s - loss: 0.0464 - recall_16: 0.8959\n",
      "Epoch 363/1000\n",
      " - 1s - loss: 0.0458 - recall_16: 0.8983\n",
      "Epoch 364/1000\n",
      " - 1s - loss: 0.0461 - recall_16: 0.8983\n",
      "Epoch 365/1000\n",
      " - 1s - loss: 0.0425 - recall_16: 0.9104\n",
      "Epoch 366/1000\n",
      " - 1s - loss: 0.0437 - recall_16: 0.8886\n",
      "Epoch 367/1000\n",
      " - 1s - loss: 0.0485 - recall_16: 0.8910\n",
      "Epoch 368/1000\n",
      " - 1s - loss: 0.0433 - recall_16: 0.8983\n",
      "Epoch 369/1000\n",
      " - 1s - loss: 0.0441 - recall_16: 0.8983\n",
      "Epoch 370/1000\n",
      " - 1s - loss: 0.0420 - recall_16: 0.8983\n",
      "Epoch 371/1000\n",
      " - 1s - loss: 0.0465 - recall_16: 0.9031\n",
      "Epoch 372/1000\n",
      " - 1s - loss: 0.0457 - recall_16: 0.8959\n",
      "Epoch 373/1000\n",
      " - 1s - loss: 0.0435 - recall_16: 0.9080\n",
      "Epoch 374/1000\n",
      " - 1s - loss: 0.0417 - recall_16: 0.9080\n",
      "Epoch 375/1000\n",
      " - 1s - loss: 0.0420 - recall_16: 0.9056\n",
      "Epoch 376/1000\n",
      " - 1s - loss: 0.0398 - recall_16: 0.9031\n",
      "Epoch 377/1000\n",
      " - 1s - loss: 0.0445 - recall_16: 0.9080\n",
      "Epoch 378/1000\n",
      " - 1s - loss: 0.0434 - recall_16: 0.9056\n",
      "Epoch 379/1000\n",
      " - 1s - loss: 0.0432 - recall_16: 0.9080\n",
      "Epoch 380/1000\n",
      " - 1s - loss: 0.0444 - recall_16: 0.9031\n",
      "Epoch 381/1000\n",
      " - 1s - loss: 0.0403 - recall_16: 0.9128\n",
      "Epoch 382/1000\n",
      " - 1s - loss: 0.0394 - recall_16: 0.9128\n",
      "Epoch 383/1000\n",
      " - 1s - loss: 0.0414 - recall_16: 0.9056\n",
      "Epoch 384/1000\n",
      " - 1s - loss: 0.0391 - recall_16: 0.9201\n",
      "Epoch 385/1000\n",
      " - 1s - loss: 0.0401 - recall_16: 0.9177\n",
      "Epoch 386/1000\n",
      " - 1s - loss: 0.0362 - recall_16: 0.9249\n",
      "Epoch 387/1000\n",
      " - 1s - loss: 0.0422 - recall_16: 0.9201\n",
      "Epoch 388/1000\n",
      " - 1s - loss: 0.0398 - recall_16: 0.9177\n",
      "Epoch 389/1000\n",
      " - 1s - loss: 0.0431 - recall_16: 0.9080\n",
      "Epoch 390/1000\n",
      " - 1s - loss: 0.0406 - recall_16: 0.9104\n",
      "Epoch 391/1000\n",
      " - 1s - loss: 0.0419 - recall_16: 0.9031\n",
      "Epoch 392/1000\n",
      " - 1s - loss: 0.0397 - recall_16: 0.9056\n",
      "Epoch 393/1000\n",
      " - 1s - loss: 0.0421 - recall_16: 0.9128\n",
      "Epoch 394/1000\n",
      " - 1s - loss: 0.0400 - recall_16: 0.9201\n",
      "Epoch 395/1000\n",
      " - 1s - loss: 0.0380 - recall_16: 0.9225\n",
      "Epoch 396/1000\n",
      " - 1s - loss: 0.0379 - recall_16: 0.9080\n",
      "Epoch 397/1000\n",
      " - 1s - loss: 0.0418 - recall_16: 0.9080\n",
      "Epoch 398/1000\n",
      " - 1s - loss: 0.0390 - recall_16: 0.9177\n",
      "Epoch 399/1000\n",
      " - 1s - loss: 0.0400 - recall_16: 0.9201\n",
      "Epoch 400/1000\n",
      " - 1s - loss: 0.0407 - recall_16: 0.9080\n",
      "Epoch 401/1000\n",
      " - 1s - loss: 0.0376 - recall_16: 0.9201\n",
      "Epoch 402/1000\n",
      " - 1s - loss: 0.0409 - recall_16: 0.9080\n",
      "Epoch 403/1000\n",
      " - 1s - loss: 0.0422 - recall_16: 0.9128\n",
      "Epoch 404/1000\n",
      " - 1s - loss: 0.0416 - recall_16: 0.9201\n",
      "Epoch 405/1000\n",
      " - 1s - loss: 0.0422 - recall_16: 0.9201\n",
      "Epoch 406/1000\n",
      " - 1s - loss: 0.0369 - recall_16: 0.9225\n",
      "Epoch 407/1000\n",
      " - 1s - loss: 0.0398 - recall_16: 0.9031\n",
      "Epoch 408/1000\n",
      " - 1s - loss: 0.0380 - recall_16: 0.9128\n",
      "Epoch 409/1000\n",
      " - 1s - loss: 0.0384 - recall_16: 0.9249\n",
      "Epoch 410/1000\n",
      " - 1s - loss: 0.0340 - recall_16: 0.9370\n",
      "Epoch 411/1000\n",
      " - 1s - loss: 0.0393 - recall_16: 0.9177\n",
      "Epoch 412/1000\n",
      " - 1s - loss: 0.0385 - recall_16: 0.9056\n",
      "Epoch 413/1000\n",
      " - 1s - loss: 0.0387 - recall_16: 0.9225\n",
      "Epoch 414/1000\n",
      " - 1s - loss: 0.0367 - recall_16: 0.9104\n",
      "Epoch 415/1000\n",
      " - 1s - loss: 0.0424 - recall_16: 0.9056\n",
      "Epoch 416/1000\n",
      " - 1s - loss: 0.0392 - recall_16: 0.9177\n",
      "Epoch 417/1000\n",
      " - 1s - loss: 0.0373 - recall_16: 0.9177\n",
      "Epoch 418/1000\n",
      " - 1s - loss: 0.0419 - recall_16: 0.9080\n",
      "Epoch 419/1000\n",
      " - 1s - loss: 0.0369 - recall_16: 0.9104\n",
      "Epoch 420/1000\n",
      " - 1s - loss: 0.0386 - recall_16: 0.9249\n",
      "Epoch 421/1000\n",
      " - 1s - loss: 0.0384 - recall_16: 0.9128\n",
      "Epoch 422/1000\n",
      " - 1s - loss: 0.0375 - recall_16: 0.9249\n",
      "Epoch 423/1000\n",
      " - 1s - loss: 0.0360 - recall_16: 0.9201\n",
      "Epoch 424/1000\n",
      " - 1s - loss: 0.0364 - recall_16: 0.9177\n",
      "Epoch 425/1000\n",
      " - 1s - loss: 0.0377 - recall_16: 0.9274\n",
      "Epoch 426/1000\n",
      " - 1s - loss: 0.0357 - recall_16: 0.9298\n",
      "Epoch 427/1000\n",
      " - 1s - loss: 0.0365 - recall_16: 0.9128\n",
      "Epoch 428/1000\n",
      " - 1s - loss: 0.0342 - recall_16: 0.9298\n",
      "Epoch 429/1000\n",
      " - 1s - loss: 0.0335 - recall_16: 0.9298\n",
      "Epoch 430/1000\n",
      " - 1s - loss: 0.0356 - recall_16: 0.9274\n",
      "Epoch 431/1000\n",
      " - 1s - loss: 0.0399 - recall_16: 0.9153\n",
      "Epoch 432/1000\n",
      " - 1s - loss: 0.0411 - recall_16: 0.9177\n",
      "Epoch 433/1000\n",
      " - 1s - loss: 0.0383 - recall_16: 0.9201\n",
      "Epoch 434/1000\n",
      " - 1s - loss: 0.0389 - recall_16: 0.9201\n",
      "Epoch 435/1000\n",
      " - 1s - loss: 0.0371 - recall_16: 0.9177\n",
      "Epoch 436/1000\n",
      " - 1s - loss: 0.0393 - recall_16: 0.9201\n",
      "Epoch 437/1000\n",
      " - 1s - loss: 0.0358 - recall_16: 0.9298\n",
      "Epoch 438/1000\n",
      " - 1s - loss: 0.0372 - recall_16: 0.9249\n",
      "Epoch 439/1000\n",
      " - 1s - loss: 0.0375 - recall_16: 0.9298\n",
      "Epoch 440/1000\n",
      " - 1s - loss: 0.0316 - recall_16: 0.9346\n",
      "Epoch 441/1000\n",
      " - 1s - loss: 0.0352 - recall_16: 0.9249\n",
      "Epoch 442/1000\n",
      " - 1s - loss: 0.0357 - recall_16: 0.9225\n",
      "Epoch 443/1000\n",
      " - 1s - loss: 0.0394 - recall_16: 0.9298\n",
      "Epoch 444/1000\n",
      " - 1s - loss: 0.0350 - recall_16: 0.9322\n",
      "Epoch 445/1000\n",
      " - 1s - loss: 0.0386 - recall_16: 0.9080\n",
      "Epoch 446/1000\n",
      " - 1s - loss: 0.0359 - recall_16: 0.9225\n",
      "Epoch 447/1000\n",
      " - 1s - loss: 0.0348 - recall_16: 0.9346\n",
      "Epoch 448/1000\n",
      " - 1s - loss: 0.0345 - recall_16: 0.9298\n",
      "Epoch 449/1000\n",
      " - 1s - loss: 0.0336 - recall_16: 0.9322\n",
      "Epoch 450/1000\n",
      " - 1s - loss: 0.0352 - recall_16: 0.9298\n",
      "Epoch 451/1000\n",
      " - 1s - loss: 0.0374 - recall_16: 0.9249\n",
      "Epoch 452/1000\n",
      " - 1s - loss: 0.0342 - recall_16: 0.9298\n",
      "Epoch 453/1000\n",
      " - 1s - loss: 0.0349 - recall_16: 0.9274\n",
      "Epoch 454/1000\n",
      " - 1s - loss: 0.0358 - recall_16: 0.9322\n",
      "Epoch 455/1000\n",
      " - 1s - loss: 0.0339 - recall_16: 0.9322\n",
      "Epoch 456/1000\n",
      " - 1s - loss: 0.0339 - recall_16: 0.9370\n",
      "Epoch 457/1000\n",
      " - 1s - loss: 0.0359 - recall_16: 0.9274\n",
      "Epoch 458/1000\n",
      " - 1s - loss: 0.0379 - recall_16: 0.9322\n",
      "Epoch 459/1000\n",
      " - 1s - loss: 0.0378 - recall_16: 0.9249\n",
      "Epoch 460/1000\n",
      " - 1s - loss: 0.0329 - recall_16: 0.9443\n",
      "Epoch 461/1000\n",
      " - 1s - loss: 0.0361 - recall_16: 0.9274\n",
      "Epoch 462/1000\n",
      " - 1s - loss: 0.0343 - recall_16: 0.9225\n",
      "Epoch 463/1000\n",
      " - 1s - loss: 0.0364 - recall_16: 0.9274\n",
      "Epoch 464/1000\n",
      " - 1s - loss: 0.0324 - recall_16: 0.9395\n",
      "Epoch 465/1000\n",
      " - 1s - loss: 0.0323 - recall_16: 0.9322\n",
      "Epoch 466/1000\n",
      " - 1s - loss: 0.0363 - recall_16: 0.9177\n",
      "Epoch 467/1000\n",
      " - 1s - loss: 0.0359 - recall_16: 0.9298\n",
      "Epoch 468/1000\n",
      " - 1s - loss: 0.0343 - recall_16: 0.9274\n",
      "Epoch 469/1000\n",
      " - 1s - loss: 0.0392 - recall_16: 0.9201\n",
      "Epoch 470/1000\n",
      " - 1s - loss: 0.0334 - recall_16: 0.9322\n",
      "Epoch 471/1000\n",
      " - 1s - loss: 0.0386 - recall_16: 0.9225\n",
      "Epoch 472/1000\n",
      " - 1s - loss: 0.0328 - recall_16: 0.9370\n",
      "Epoch 473/1000\n",
      " - 1s - loss: 0.0374 - recall_16: 0.9225\n",
      "Epoch 474/1000\n",
      " - 1s - loss: 0.0317 - recall_16: 0.9395\n",
      "Epoch 475/1000\n",
      " - 1s - loss: 0.0350 - recall_16: 0.9298\n",
      "Epoch 476/1000\n",
      " - 1s - loss: 0.0348 - recall_16: 0.9298\n",
      "Epoch 477/1000\n",
      " - 1s - loss: 0.0333 - recall_16: 0.9274\n",
      "Epoch 478/1000\n",
      " - 1s - loss: 0.0344 - recall_16: 0.9322\n",
      "Epoch 479/1000\n",
      " - 1s - loss: 0.0368 - recall_16: 0.9177\n",
      "Epoch 480/1000\n",
      " - 1s - loss: 0.0359 - recall_16: 0.9274\n",
      "Epoch 481/1000\n",
      " - 1s - loss: 0.0334 - recall_16: 0.9322\n",
      "Epoch 482/1000\n",
      " - 1s - loss: 0.0340 - recall_16: 0.9322\n",
      "Epoch 483/1000\n",
      " - 1s - loss: 0.0354 - recall_16: 0.9298\n",
      "Epoch 484/1000\n",
      " - 1s - loss: 0.0329 - recall_16: 0.9443\n",
      "Epoch 485/1000\n",
      " - 1s - loss: 0.0334 - recall_16: 0.9346\n",
      "Epoch 486/1000\n",
      " - 1s - loss: 0.0357 - recall_16: 0.9274\n",
      "Epoch 487/1000\n",
      " - 1s - loss: 0.0306 - recall_16: 0.9443\n",
      "Epoch 488/1000\n",
      " - 1s - loss: 0.0356 - recall_16: 0.9274\n",
      "Epoch 489/1000\n",
      " - 1s - loss: 0.0334 - recall_16: 0.9322\n",
      "Epoch 490/1000\n",
      " - 1s - loss: 0.0301 - recall_16: 0.9419\n",
      "Epoch 491/1000\n",
      " - 1s - loss: 0.0342 - recall_16: 0.9298\n",
      "Epoch 492/1000\n",
      " - 1s - loss: 0.0369 - recall_16: 0.9177\n",
      "Epoch 493/1000\n",
      " - 1s - loss: 0.0313 - recall_16: 0.9298\n",
      "Epoch 494/1000\n",
      " - 1s - loss: 0.0316 - recall_16: 0.9395\n",
      "Epoch 495/1000\n",
      " - 1s - loss: 0.0310 - recall_16: 0.9492\n",
      "Epoch 496/1000\n",
      " - 1s - loss: 0.0354 - recall_16: 0.9346\n",
      "Epoch 497/1000\n",
      " - 1s - loss: 0.0343 - recall_16: 0.9298\n",
      "Epoch 498/1000\n",
      " - 1s - loss: 0.0328 - recall_16: 0.9346\n",
      "Epoch 499/1000\n",
      " - 1s - loss: 0.0360 - recall_16: 0.9346\n",
      "Epoch 500/1000\n",
      " - 1s - loss: 0.0347 - recall_16: 0.9322\n",
      "Epoch 501/1000\n",
      " - 1s - loss: 0.0312 - recall_16: 0.9395\n",
      "Epoch 502/1000\n",
      " - 1s - loss: 0.0300 - recall_16: 0.9395\n",
      "Epoch 503/1000\n",
      " - 1s - loss: 0.0302 - recall_16: 0.9443\n",
      "Epoch 504/1000\n",
      " - 1s - loss: 0.0344 - recall_16: 0.9249\n",
      "Epoch 505/1000\n",
      " - 1s - loss: 0.0311 - recall_16: 0.9249\n",
      "Epoch 506/1000\n",
      " - 1s - loss: 0.0368 - recall_16: 0.9322\n",
      "Epoch 507/1000\n",
      " - 1s - loss: 0.0362 - recall_16: 0.9322\n",
      "Epoch 508/1000\n",
      " - 1s - loss: 0.0319 - recall_16: 0.9274\n",
      "Epoch 509/1000\n",
      " - 1s - loss: 0.0336 - recall_16: 0.9249\n",
      "Epoch 510/1000\n",
      " - 1s - loss: 0.0331 - recall_16: 0.9395\n",
      "Epoch 511/1000\n",
      " - 1s - loss: 0.0345 - recall_16: 0.9298\n",
      "Epoch 512/1000\n",
      " - 1s - loss: 0.0365 - recall_16: 0.9225\n",
      "Epoch 513/1000\n",
      " - 1s - loss: 0.0299 - recall_16: 0.9443\n",
      "Epoch 514/1000\n",
      " - 1s - loss: 0.0289 - recall_16: 0.9419\n",
      "Epoch 515/1000\n",
      " - 1s - loss: 0.0338 - recall_16: 0.9370\n",
      "Epoch 516/1000\n",
      " - 1s - loss: 0.0324 - recall_16: 0.9370\n",
      "Epoch 517/1000\n",
      " - 1s - loss: 0.0337 - recall_16: 0.9298\n",
      "Epoch 518/1000\n",
      " - 1s - loss: 0.0331 - recall_16: 0.9322\n",
      "Epoch 519/1000\n",
      " - 1s - loss: 0.0325 - recall_16: 0.9467\n",
      "Epoch 520/1000\n",
      " - 1s - loss: 0.0287 - recall_16: 0.9467\n",
      "Epoch 521/1000\n",
      " - 1s - loss: 0.0361 - recall_16: 0.9274\n",
      "Epoch 522/1000\n",
      " - 1s - loss: 0.0368 - recall_16: 0.9201\n",
      "Epoch 523/1000\n",
      " - 1s - loss: 0.0298 - recall_16: 0.9443\n",
      "Epoch 524/1000\n",
      " - 1s - loss: 0.0287 - recall_16: 0.9467\n",
      "Epoch 525/1000\n",
      " - 1s - loss: 0.0290 - recall_16: 0.9443\n",
      "Epoch 526/1000\n",
      " - 1s - loss: 0.0324 - recall_16: 0.9370\n",
      "Epoch 527/1000\n",
      " - 1s - loss: 0.0311 - recall_16: 0.9419\n",
      "Epoch 528/1000\n",
      " - 1s - loss: 0.0282 - recall_16: 0.9540\n",
      "Epoch 529/1000\n",
      " - 1s - loss: 0.0329 - recall_16: 0.9370\n",
      "Epoch 530/1000\n",
      " - 1s - loss: 0.0312 - recall_16: 0.9419\n",
      "Epoch 531/1000\n",
      " - 1s - loss: 0.0297 - recall_16: 0.9419\n",
      "Epoch 532/1000\n",
      " - 1s - loss: 0.0314 - recall_16: 0.9370\n",
      "Epoch 533/1000\n",
      " - 1s - loss: 0.0327 - recall_16: 0.9274\n",
      "Epoch 534/1000\n",
      " - 1s - loss: 0.0316 - recall_16: 0.9370\n",
      "Epoch 535/1000\n",
      " - 1s - loss: 0.0312 - recall_16: 0.9419\n",
      "Epoch 536/1000\n",
      " - 1s - loss: 0.0309 - recall_16: 0.9443\n",
      "Epoch 537/1000\n",
      " - 1s - loss: 0.0332 - recall_16: 0.9298\n",
      "Epoch 538/1000\n",
      " - 1s - loss: 0.0286 - recall_16: 0.9564\n",
      "Epoch 539/1000\n",
      " - 1s - loss: 0.0321 - recall_16: 0.9370\n",
      "Epoch 540/1000\n",
      " - 1s - loss: 0.0315 - recall_16: 0.9395\n",
      "Epoch 541/1000\n",
      " - 1s - loss: 0.0299 - recall_16: 0.9395\n",
      "Epoch 542/1000\n",
      " - 1s - loss: 0.0314 - recall_16: 0.9370\n",
      "Epoch 543/1000\n",
      " - 1s - loss: 0.0292 - recall_16: 0.9419\n",
      "Epoch 544/1000\n",
      " - 1s - loss: 0.0326 - recall_16: 0.9370\n",
      "Epoch 545/1000\n",
      " - 1s - loss: 0.0364 - recall_16: 0.9322\n",
      "Epoch 546/1000\n",
      " - 1s - loss: 0.0349 - recall_16: 0.9346\n",
      "Epoch 547/1000\n",
      " - 1s - loss: 0.0335 - recall_16: 0.9395\n",
      "Epoch 548/1000\n",
      " - 1s - loss: 0.0311 - recall_16: 0.9370\n",
      "Epoch 549/1000\n",
      " - 1s - loss: 0.0306 - recall_16: 0.9395\n",
      "Epoch 550/1000\n",
      " - 1s - loss: 0.0319 - recall_16: 0.9443\n",
      "Epoch 551/1000\n",
      " - 1s - loss: 0.0292 - recall_16: 0.9492\n",
      "Epoch 552/1000\n",
      " - 1s - loss: 0.0339 - recall_16: 0.9346\n",
      "Epoch 553/1000\n",
      " - 1s - loss: 0.0347 - recall_16: 0.9225\n",
      "Epoch 554/1000\n",
      " - 1s - loss: 0.0342 - recall_16: 0.9298\n",
      "Epoch 555/1000\n",
      " - 1s - loss: 0.0305 - recall_16: 0.9419\n",
      "Epoch 556/1000\n",
      " - 1s - loss: 0.0293 - recall_16: 0.9443\n",
      "Epoch 557/1000\n",
      " - 1s - loss: 0.0329 - recall_16: 0.9370\n",
      "Epoch 558/1000\n",
      " - 1s - loss: 0.0294 - recall_16: 0.9419\n",
      "Epoch 559/1000\n",
      " - 1s - loss: 0.0324 - recall_16: 0.9395\n",
      "Epoch 560/1000\n",
      " - 1s - loss: 0.0322 - recall_16: 0.9395\n",
      "Epoch 561/1000\n",
      " - 1s - loss: 0.0278 - recall_16: 0.9492\n",
      "Epoch 562/1000\n",
      " - 1s - loss: 0.0267 - recall_16: 0.9516\n",
      "Epoch 563/1000\n",
      " - 1s - loss: 0.0312 - recall_16: 0.9370\n",
      "Epoch 564/1000\n",
      " - 1s - loss: 0.0277 - recall_16: 0.9540\n",
      "Epoch 565/1000\n",
      " - 1s - loss: 0.0300 - recall_16: 0.9467\n",
      "Epoch 566/1000\n",
      " - 1s - loss: 0.0303 - recall_16: 0.9346\n",
      "Epoch 567/1000\n",
      " - 1s - loss: 0.0297 - recall_16: 0.9419\n",
      "Epoch 568/1000\n",
      " - 1s - loss: 0.0321 - recall_16: 0.9370\n",
      "Epoch 569/1000\n",
      " - 1s - loss: 0.0343 - recall_16: 0.9322\n",
      "Epoch 570/1000\n",
      " - 1s - loss: 0.0337 - recall_16: 0.9322\n",
      "Epoch 571/1000\n",
      " - 1s - loss: 0.0317 - recall_16: 0.9346\n",
      "Epoch 572/1000\n",
      " - 1s - loss: 0.0302 - recall_16: 0.9419\n",
      "Epoch 573/1000\n",
      " - 1s - loss: 0.0374 - recall_16: 0.9274\n",
      "Epoch 574/1000\n",
      " - 1s - loss: 0.0333 - recall_16: 0.9370\n",
      "Epoch 575/1000\n",
      " - 1s - loss: 0.0323 - recall_16: 0.9346\n",
      "Epoch 576/1000\n",
      " - 1s - loss: 0.0271 - recall_16: 0.9516\n",
      "Epoch 577/1000\n",
      " - 1s - loss: 0.0359 - recall_16: 0.9322\n",
      "Epoch 578/1000\n",
      " - 1s - loss: 0.0293 - recall_16: 0.9492\n",
      "Epoch 579/1000\n",
      " - 1s - loss: 0.0321 - recall_16: 0.9443\n",
      "Epoch 580/1000\n",
      " - 1s - loss: 0.0325 - recall_16: 0.9467\n",
      "Epoch 581/1000\n",
      " - 1s - loss: 0.0330 - recall_16: 0.9370\n",
      "Epoch 582/1000\n",
      " - 1s - loss: 0.0291 - recall_16: 0.9419\n",
      "Epoch 583/1000\n",
      " - 1s - loss: 0.0307 - recall_16: 0.9370\n",
      "Epoch 584/1000\n",
      " - 1s - loss: 0.0282 - recall_16: 0.9467\n",
      "Epoch 585/1000\n",
      " - 1s - loss: 0.0318 - recall_16: 0.9443\n",
      "Epoch 586/1000\n",
      " - 1s - loss: 0.0290 - recall_16: 0.9419\n",
      "Epoch 587/1000\n",
      " - 1s - loss: 0.0292 - recall_16: 0.9443\n",
      "Epoch 588/1000\n",
      " - 1s - loss: 0.0348 - recall_16: 0.9322\n",
      "Epoch 589/1000\n",
      " - 1s - loss: 0.0313 - recall_16: 0.9395\n",
      "Epoch 590/1000\n",
      " - 1s - loss: 0.0299 - recall_16: 0.9346\n",
      "Epoch 591/1000\n",
      " - 1s - loss: 0.0290 - recall_16: 0.9443\n",
      "Epoch 592/1000\n",
      " - 1s - loss: 0.0281 - recall_16: 0.9443\n",
      "Epoch 593/1000\n",
      " - 1s - loss: 0.0317 - recall_16: 0.9443\n",
      "Epoch 594/1000\n",
      " - 1s - loss: 0.0322 - recall_16: 0.9419\n",
      "Epoch 595/1000\n",
      " - 1s - loss: 0.0279 - recall_16: 0.9419\n",
      "Epoch 596/1000\n",
      " - 1s - loss: 0.0298 - recall_16: 0.9443\n",
      "Epoch 597/1000\n",
      " - 1s - loss: 0.0315 - recall_16: 0.9370\n",
      "Epoch 598/1000\n",
      " - 1s - loss: 0.0306 - recall_16: 0.9395\n",
      "Epoch 599/1000\n",
      " - 1s - loss: 0.0305 - recall_16: 0.9419\n",
      "Epoch 600/1000\n",
      " - 1s - loss: 0.0309 - recall_16: 0.9419\n",
      "Epoch 601/1000\n",
      " - 1s - loss: 0.0310 - recall_16: 0.9370\n",
      "Epoch 602/1000\n",
      " - 1s - loss: 0.0346 - recall_16: 0.9298\n",
      "Epoch 603/1000\n",
      " - 1s - loss: 0.0327 - recall_16: 0.9298\n",
      "Epoch 604/1000\n",
      " - 1s - loss: 0.0310 - recall_16: 0.9419\n",
      "Epoch 605/1000\n",
      " - 1s - loss: 0.0314 - recall_16: 0.9443\n",
      "Epoch 606/1000\n",
      " - 1s - loss: 0.0330 - recall_16: 0.9346\n",
      "Epoch 607/1000\n",
      " - 1s - loss: 0.0327 - recall_16: 0.9419\n",
      "Epoch 608/1000\n",
      " - 1s - loss: 0.0287 - recall_16: 0.9467\n",
      "Epoch 609/1000\n",
      " - 1s - loss: 0.0285 - recall_16: 0.9516\n",
      "Epoch 610/1000\n",
      " - 1s - loss: 0.0297 - recall_16: 0.9443\n",
      "Epoch 611/1000\n",
      " - 1s - loss: 0.0285 - recall_16: 0.9419\n",
      "Epoch 612/1000\n",
      " - 1s - loss: 0.0332 - recall_16: 0.9370\n",
      "Epoch 613/1000\n",
      " - 1s - loss: 0.0287 - recall_16: 0.9346\n",
      "Epoch 614/1000\n",
      " - 1s - loss: 0.0287 - recall_16: 0.9467\n",
      "Epoch 615/1000\n",
      " - 1s - loss: 0.0298 - recall_16: 0.9443\n",
      "Epoch 616/1000\n",
      " - 1s - loss: 0.0345 - recall_16: 0.9322\n",
      "Epoch 617/1000\n",
      " - 1s - loss: 0.0339 - recall_16: 0.9322\n",
      "Epoch 618/1000\n",
      " - 1s - loss: 0.0332 - recall_16: 0.9370\n",
      "Epoch 619/1000\n",
      " - 1s - loss: 0.0272 - recall_16: 0.9492\n",
      "Epoch 620/1000\n",
      " - 1s - loss: 0.0310 - recall_16: 0.9467\n",
      "Epoch 621/1000\n",
      " - 1s - loss: 0.0310 - recall_16: 0.9370\n",
      "Epoch 622/1000\n",
      " - 1s - loss: 0.0294 - recall_16: 0.9419\n",
      "Epoch 623/1000\n",
      " - 1s - loss: 0.0297 - recall_16: 0.9419\n",
      "Epoch 624/1000\n",
      " - 1s - loss: 0.0292 - recall_16: 0.9492\n",
      "Epoch 625/1000\n",
      " - 1s - loss: 0.0299 - recall_16: 0.9395\n",
      "Epoch 626/1000\n",
      " - 1s - loss: 0.0285 - recall_16: 0.9516\n",
      "Epoch 627/1000\n",
      " - 1s - loss: 0.0279 - recall_16: 0.9492\n",
      "Epoch 628/1000\n",
      " - 1s - loss: 0.0302 - recall_16: 0.9443\n",
      "Epoch 629/1000\n",
      " - 1s - loss: 0.0310 - recall_16: 0.9395\n",
      "Epoch 630/1000\n",
      " - 1s - loss: 0.0291 - recall_16: 0.9492\n",
      "Epoch 631/1000\n",
      " - 1s - loss: 0.0311 - recall_16: 0.9467\n",
      "Epoch 632/1000\n",
      " - 1s - loss: 0.0316 - recall_16: 0.9395\n",
      "Epoch 633/1000\n",
      " - 1s - loss: 0.0310 - recall_16: 0.9370\n",
      "Epoch 634/1000\n",
      " - 1s - loss: 0.0296 - recall_16: 0.9419\n",
      "Epoch 635/1000\n",
      " - 1s - loss: 0.0307 - recall_16: 0.9443\n",
      "Epoch 636/1000\n",
      " - 1s - loss: 0.0267 - recall_16: 0.9467\n",
      "Epoch 637/1000\n",
      " - 1s - loss: 0.0282 - recall_16: 0.9443\n",
      "Epoch 638/1000\n",
      " - 1s - loss: 0.0305 - recall_16: 0.9443\n",
      "Epoch 639/1000\n",
      " - 1s - loss: 0.0296 - recall_16: 0.9443\n",
      "Epoch 640/1000\n",
      " - 1s - loss: 0.0310 - recall_16: 0.9443\n",
      "Epoch 641/1000\n",
      " - 1s - loss: 0.0329 - recall_16: 0.9322\n",
      "Epoch 642/1000\n",
      " - 1s - loss: 0.0280 - recall_16: 0.9443\n",
      "Epoch 643/1000\n",
      " - 1s - loss: 0.0300 - recall_16: 0.9443\n",
      "Epoch 644/1000\n",
      " - 1s - loss: 0.0275 - recall_16: 0.9419\n",
      "Epoch 645/1000\n",
      " - 1s - loss: 0.0283 - recall_16: 0.9540\n",
      "Epoch 646/1000\n",
      " - 1s - loss: 0.0306 - recall_16: 0.9419\n",
      "Epoch 647/1000\n",
      " - 1s - loss: 0.0302 - recall_16: 0.9492\n",
      "Epoch 648/1000\n",
      " - 1s - loss: 0.0282 - recall_16: 0.9443\n",
      "Epoch 649/1000\n",
      " - 1s - loss: 0.0304 - recall_16: 0.9419\n",
      "Epoch 650/1000\n",
      " - 1s - loss: 0.0290 - recall_16: 0.9395\n",
      "Epoch 651/1000\n",
      " - 1s - loss: 0.0343 - recall_16: 0.9322\n",
      "Epoch 652/1000\n",
      " - 1s - loss: 0.0326 - recall_16: 0.9298\n",
      "Epoch 653/1000\n",
      " - 1s - loss: 0.0321 - recall_16: 0.9370\n",
      "Epoch 654/1000\n",
      " - 1s - loss: 0.0291 - recall_16: 0.9492\n",
      "Epoch 655/1000\n",
      " - 1s - loss: 0.0299 - recall_16: 0.9395\n",
      "Epoch 656/1000\n",
      " - 1s - loss: 0.0285 - recall_16: 0.9467\n",
      "Epoch 657/1000\n",
      " - 1s - loss: 0.0285 - recall_16: 0.9395\n",
      "Epoch 658/1000\n",
      " - 1s - loss: 0.0271 - recall_16: 0.9492\n",
      "Epoch 659/1000\n",
      " - 1s - loss: 0.0292 - recall_16: 0.9492\n",
      "Epoch 660/1000\n",
      " - 1s - loss: 0.0319 - recall_16: 0.9370\n",
      "Epoch 661/1000\n",
      " - 1s - loss: 0.0310 - recall_16: 0.9395\n",
      "Epoch 662/1000\n",
      " - 1s - loss: 0.0319 - recall_16: 0.9346\n",
      "Epoch 663/1000\n",
      " - 1s - loss: 0.0285 - recall_16: 0.9467\n",
      "Epoch 664/1000\n",
      " - 1s - loss: 0.0262 - recall_16: 0.9516\n",
      "Epoch 665/1000\n",
      " - 1s - loss: 0.0282 - recall_16: 0.9467\n",
      "Epoch 666/1000\n",
      " - 1s - loss: 0.0286 - recall_16: 0.9492\n",
      "Epoch 667/1000\n",
      " - 1s - loss: 0.0299 - recall_16: 0.9492\n",
      "Epoch 668/1000\n",
      " - 1s - loss: 0.0299 - recall_16: 0.9395\n",
      "Epoch 669/1000\n",
      " - 1s - loss: 0.0269 - recall_16: 0.9492\n",
      "Epoch 670/1000\n",
      " - 1s - loss: 0.0284 - recall_16: 0.9395\n",
      "Epoch 671/1000\n",
      " - 1s - loss: 0.0289 - recall_16: 0.9443\n",
      "Epoch 672/1000\n",
      " - 1s - loss: 0.0337 - recall_16: 0.9395\n",
      "Epoch 673/1000\n",
      " - 1s - loss: 0.0283 - recall_16: 0.9492\n",
      "Epoch 674/1000\n",
      " - 1s - loss: 0.0297 - recall_16: 0.9467\n",
      "Epoch 675/1000\n",
      " - 1s - loss: 0.0309 - recall_16: 0.9419\n",
      "Epoch 676/1000\n",
      " - 1s - loss: 0.0334 - recall_16: 0.9274\n",
      "Epoch 677/1000\n",
      " - 1s - loss: 0.0283 - recall_16: 0.9516\n",
      "Epoch 678/1000\n",
      " - 1s - loss: 0.0331 - recall_16: 0.9370\n",
      "Epoch 679/1000\n",
      " - 1s - loss: 0.0299 - recall_16: 0.9467\n",
      "Epoch 680/1000\n",
      " - 1s - loss: 0.0305 - recall_16: 0.9370\n",
      "Epoch 681/1000\n",
      " - 1s - loss: 0.0291 - recall_16: 0.9492\n",
      "Epoch 682/1000\n",
      " - 1s - loss: 0.0297 - recall_16: 0.9395\n",
      "Epoch 683/1000\n",
      " - 1s - loss: 0.0320 - recall_16: 0.9443\n",
      "Epoch 684/1000\n",
      " - 1s - loss: 0.0298 - recall_16: 0.9467\n",
      "Epoch 685/1000\n",
      " - 1s - loss: 0.0322 - recall_16: 0.9395\n",
      "Epoch 686/1000\n",
      " - 1s - loss: 0.0307 - recall_16: 0.9346\n",
      "Epoch 687/1000\n",
      " - 1s - loss: 0.0297 - recall_16: 0.9492\n",
      "Epoch 688/1000\n",
      " - 1s - loss: 0.0254 - recall_16: 0.9516\n",
      "Epoch 689/1000\n",
      " - 1s - loss: 0.0300 - recall_16: 0.9395\n",
      "Epoch 690/1000\n",
      " - 1s - loss: 0.0325 - recall_16: 0.9322\n",
      "Epoch 691/1000\n",
      " - 1s - loss: 0.0271 - recall_16: 0.9516\n",
      "Epoch 692/1000\n",
      " - 1s - loss: 0.0271 - recall_16: 0.9516\n",
      "Epoch 693/1000\n",
      " - 1s - loss: 0.0281 - recall_16: 0.9419\n",
      "Epoch 694/1000\n",
      " - 1s - loss: 0.0261 - recall_16: 0.9516\n",
      "Epoch 695/1000\n",
      " - 1s - loss: 0.0295 - recall_16: 0.9443\n",
      "Epoch 696/1000\n",
      " - 1s - loss: 0.0304 - recall_16: 0.9346\n",
      "Epoch 697/1000\n",
      " - 1s - loss: 0.0293 - recall_16: 0.9516\n",
      "Epoch 698/1000\n",
      " - 1s - loss: 0.0299 - recall_16: 0.9443\n",
      "Epoch 699/1000\n",
      " - 1s - loss: 0.0290 - recall_16: 0.9419\n",
      "Epoch 700/1000\n",
      " - 1s - loss: 0.0269 - recall_16: 0.9467\n",
      "Epoch 701/1000\n",
      " - 1s - loss: 0.0314 - recall_16: 0.9370\n",
      "Epoch 702/1000\n",
      " - 1s - loss: 0.0314 - recall_16: 0.9370\n",
      "Epoch 703/1000\n",
      " - 1s - loss: 0.0310 - recall_16: 0.9370\n",
      "Epoch 704/1000\n",
      " - 1s - loss: 0.0318 - recall_16: 0.9370\n",
      "Epoch 705/1000\n",
      " - 1s - loss: 0.0300 - recall_16: 0.9467\n",
      "Epoch 706/1000\n",
      " - 1s - loss: 0.0259 - recall_16: 0.9516\n",
      "Epoch 707/1000\n",
      " - 1s - loss: 0.0284 - recall_16: 0.9492\n",
      "Epoch 708/1000\n",
      " - 1s - loss: 0.0309 - recall_16: 0.9419\n",
      "Epoch 709/1000\n",
      " - 1s - loss: 0.0278 - recall_16: 0.9467\n",
      "Epoch 710/1000\n",
      " - 1s - loss: 0.0266 - recall_16: 0.9467\n",
      "Epoch 711/1000\n",
      " - 1s - loss: 0.0297 - recall_16: 0.9443\n",
      "Epoch 712/1000\n",
      " - 1s - loss: 0.0257 - recall_16: 0.9516\n",
      "Epoch 713/1000\n",
      " - 1s - loss: 0.0292 - recall_16: 0.9370\n",
      "Epoch 714/1000\n",
      " - 1s - loss: 0.0275 - recall_16: 0.9467\n",
      "Epoch 715/1000\n",
      " - 1s - loss: 0.0265 - recall_16: 0.9492\n",
      "Epoch 716/1000\n",
      " - 1s - loss: 0.0288 - recall_16: 0.9492\n",
      "Epoch 717/1000\n",
      " - 1s - loss: 0.0298 - recall_16: 0.9395\n",
      "Epoch 718/1000\n",
      " - 1s - loss: 0.0264 - recall_16: 0.9516\n",
      "Epoch 719/1000\n",
      " - 1s - loss: 0.0275 - recall_16: 0.9467\n",
      "Epoch 720/1000\n",
      " - 1s - loss: 0.0323 - recall_16: 0.9419\n",
      "Epoch 721/1000\n",
      " - 1s - loss: 0.0304 - recall_16: 0.9419\n",
      "Epoch 722/1000\n",
      " - 1s - loss: 0.0329 - recall_16: 0.9370\n",
      "Epoch 723/1000\n",
      " - 1s - loss: 0.0303 - recall_16: 0.9443\n",
      "Epoch 724/1000\n",
      " - 1s - loss: 0.0285 - recall_16: 0.9443\n",
      "Epoch 725/1000\n",
      " - 1s - loss: 0.0289 - recall_16: 0.9492\n",
      "Epoch 726/1000\n",
      " - 1s - loss: 0.0328 - recall_16: 0.9419\n",
      "Epoch 727/1000\n",
      " - 1s - loss: 0.0261 - recall_16: 0.9492\n",
      "Epoch 728/1000\n",
      " - 1s - loss: 0.0272 - recall_16: 0.9516\n",
      "Epoch 729/1000\n",
      " - 1s - loss: 0.0247 - recall_16: 0.9540\n",
      "Epoch 730/1000\n",
      " - 1s - loss: 0.0271 - recall_16: 0.9467\n",
      "Epoch 731/1000\n",
      " - 1s - loss: 0.0293 - recall_16: 0.9492\n",
      "Epoch 732/1000\n",
      " - 1s - loss: 0.0278 - recall_16: 0.9516\n",
      "Epoch 733/1000\n",
      " - 1s - loss: 0.0294 - recall_16: 0.9492\n",
      "Epoch 734/1000\n",
      " - 1s - loss: 0.0270 - recall_16: 0.9419\n",
      "Epoch 735/1000\n",
      " - 1s - loss: 0.0292 - recall_16: 0.9395\n",
      "Epoch 736/1000\n",
      " - 1s - loss: 0.0301 - recall_16: 0.9443\n",
      "Epoch 737/1000\n",
      " - 1s - loss: 0.0345 - recall_16: 0.9322\n",
      "Epoch 738/1000\n",
      " - 1s - loss: 0.0263 - recall_16: 0.9540\n",
      "Epoch 739/1000\n",
      " - 1s - loss: 0.0297 - recall_16: 0.9443\n",
      "Epoch 740/1000\n",
      " - 1s - loss: 0.0308 - recall_16: 0.9346\n",
      "Epoch 741/1000\n",
      " - 1s - loss: 0.0236 - recall_16: 0.9564\n",
      "Epoch 742/1000\n",
      " - 1s - loss: 0.0254 - recall_16: 0.9564\n",
      "Epoch 743/1000\n",
      " - 1s - loss: 0.0306 - recall_16: 0.9419\n",
      "Epoch 744/1000\n",
      " - 1s - loss: 0.0261 - recall_16: 0.9516\n",
      "Epoch 745/1000\n",
      " - 1s - loss: 0.0285 - recall_16: 0.9516\n",
      "Epoch 746/1000\n",
      " - 1s - loss: 0.0295 - recall_16: 0.9443\n",
      "Epoch 747/1000\n",
      " - 1s - loss: 0.0284 - recall_16: 0.9443\n",
      "Epoch 748/1000\n",
      " - 1s - loss: 0.0289 - recall_16: 0.9419\n",
      "Epoch 749/1000\n",
      " - 1s - loss: 0.0306 - recall_16: 0.9419\n",
      "Epoch 750/1000\n",
      " - 1s - loss: 0.0247 - recall_16: 0.9492\n",
      "Epoch 751/1000\n",
      " - 1s - loss: 0.0302 - recall_16: 0.9395\n",
      "Epoch 752/1000\n",
      " - 1s - loss: 0.0271 - recall_16: 0.9492\n",
      "Epoch 753/1000\n",
      " - 1s - loss: 0.0260 - recall_16: 0.9564\n",
      "Epoch 754/1000\n",
      " - 1s - loss: 0.0281 - recall_16: 0.9443\n",
      "Epoch 755/1000\n",
      " - 1s - loss: 0.0294 - recall_16: 0.9516\n",
      "Epoch 756/1000\n",
      " - 1s - loss: 0.0300 - recall_16: 0.9443\n",
      "Epoch 757/1000\n",
      " - 1s - loss: 0.0285 - recall_16: 0.9419\n",
      "Epoch 758/1000\n",
      " - 1s - loss: 0.0294 - recall_16: 0.9492\n",
      "Epoch 759/1000\n",
      " - 1s - loss: 0.0273 - recall_16: 0.9467\n",
      "Epoch 760/1000\n",
      " - 1s - loss: 0.0269 - recall_16: 0.9516\n",
      "Epoch 761/1000\n",
      " - 1s - loss: 0.0272 - recall_16: 0.9443\n",
      "Epoch 762/1000\n",
      " - 1s - loss: 0.0285 - recall_16: 0.9443\n",
      "Epoch 763/1000\n",
      " - 1s - loss: 0.0291 - recall_16: 0.9516\n",
      "Epoch 764/1000\n",
      " - 1s - loss: 0.0268 - recall_16: 0.9588\n",
      "Epoch 765/1000\n",
      " - 1s - loss: 0.0279 - recall_16: 0.9492\n",
      "Epoch 766/1000\n",
      " - 1s - loss: 0.0256 - recall_16: 0.9516\n",
      "Epoch 767/1000\n",
      " - 1s - loss: 0.0260 - recall_16: 0.9443\n",
      "Epoch 768/1000\n",
      " - 1s - loss: 0.0265 - recall_16: 0.9540\n",
      "Epoch 769/1000\n",
      " - 1s - loss: 0.0284 - recall_16: 0.9443\n",
      "Epoch 770/1000\n",
      " - 1s - loss: 0.0281 - recall_16: 0.9419\n",
      "Epoch 771/1000\n",
      " - 1s - loss: 0.0304 - recall_16: 0.9443\n",
      "Epoch 772/1000\n",
      " - 1s - loss: 0.0260 - recall_16: 0.9540\n",
      "Epoch 773/1000\n",
      " - 1s - loss: 0.0300 - recall_16: 0.9443\n",
      "Epoch 774/1000\n",
      " - 1s - loss: 0.0273 - recall_16: 0.9492\n",
      "Epoch 775/1000\n",
      " - 1s - loss: 0.0264 - recall_16: 0.9492\n",
      "Epoch 776/1000\n",
      " - 1s - loss: 0.0280 - recall_16: 0.9443\n",
      "Epoch 777/1000\n",
      " - 1s - loss: 0.0292 - recall_16: 0.9467\n",
      "Epoch 778/1000\n",
      " - 1s - loss: 0.0331 - recall_16: 0.9322\n",
      "Epoch 779/1000\n",
      " - 1s - loss: 0.0236 - recall_16: 0.9540\n",
      "Epoch 780/1000\n",
      " - 1s - loss: 0.0283 - recall_16: 0.9492\n",
      "Epoch 781/1000\n",
      " - 1s - loss: 0.0252 - recall_16: 0.9540\n",
      "Epoch 782/1000\n",
      " - 1s - loss: 0.0257 - recall_16: 0.9516\n",
      "Epoch 783/1000\n",
      " - 1s - loss: 0.0284 - recall_16: 0.9467\n",
      "Epoch 784/1000\n",
      " - 1s - loss: 0.0278 - recall_16: 0.9492\n",
      "Epoch 785/1000\n",
      " - 1s - loss: 0.0279 - recall_16: 0.9467\n",
      "Epoch 786/1000\n",
      " - 1s - loss: 0.0232 - recall_16: 0.9516\n",
      "Epoch 787/1000\n",
      " - 1s - loss: 0.0286 - recall_16: 0.9467\n",
      "Epoch 788/1000\n",
      " - 1s - loss: 0.0285 - recall_16: 0.9516\n",
      "Epoch 789/1000\n",
      " - 1s - loss: 0.0272 - recall_16: 0.9492\n",
      "Epoch 790/1000\n",
      " - 1s - loss: 0.0297 - recall_16: 0.9516\n",
      "Epoch 791/1000\n",
      " - 1s - loss: 0.0279 - recall_16: 0.9492\n",
      "Epoch 792/1000\n",
      " - 1s - loss: 0.0273 - recall_16: 0.9467\n",
      "Epoch 793/1000\n",
      " - 1s - loss: 0.0246 - recall_16: 0.9588\n",
      "Epoch 794/1000\n",
      " - 1s - loss: 0.0257 - recall_16: 0.9540\n",
      "Epoch 795/1000\n",
      " - 1s - loss: 0.0265 - recall_16: 0.9564\n",
      "Epoch 796/1000\n",
      " - 1s - loss: 0.0317 - recall_16: 0.9395\n",
      "Epoch 797/1000\n",
      " - 1s - loss: 0.0263 - recall_16: 0.9492\n",
      "Epoch 798/1000\n",
      " - 1s - loss: 0.0262 - recall_16: 0.9467\n",
      "Epoch 799/1000\n",
      " - 1s - loss: 0.0296 - recall_16: 0.9395\n",
      "Epoch 800/1000\n",
      " - 1s - loss: 0.0258 - recall_16: 0.9492\n",
      "Epoch 801/1000\n",
      " - 1s - loss: 0.0295 - recall_16: 0.9419\n",
      "Epoch 802/1000\n",
      " - 1s - loss: 0.0259 - recall_16: 0.9564\n",
      "Epoch 803/1000\n",
      " - 1s - loss: 0.0258 - recall_16: 0.9540\n",
      "Epoch 804/1000\n",
      " - 1s - loss: 0.0252 - recall_16: 0.9467\n",
      "Epoch 805/1000\n",
      " - 1s - loss: 0.0279 - recall_16: 0.9492\n",
      "Epoch 806/1000\n",
      " - 1s - loss: 0.0277 - recall_16: 0.9492\n",
      "Epoch 807/1000\n",
      " - 1s - loss: 0.0288 - recall_16: 0.9443\n",
      "Epoch 808/1000\n",
      " - 1s - loss: 0.0248 - recall_16: 0.9540\n",
      "Epoch 809/1000\n",
      " - 1s - loss: 0.0256 - recall_16: 0.9564\n",
      "Epoch 810/1000\n",
      " - 1s - loss: 0.0308 - recall_16: 0.9346\n",
      "Epoch 811/1000\n",
      " - 1s - loss: 0.0278 - recall_16: 0.9419\n",
      "Epoch 812/1000\n",
      " - 1s - loss: 0.0246 - recall_16: 0.9564\n",
      "Epoch 813/1000\n",
      " - 1s - loss: 0.0300 - recall_16: 0.9395\n",
      "Epoch 814/1000\n",
      " - 1s - loss: 0.0288 - recall_16: 0.9443\n",
      "Epoch 815/1000\n",
      " - 1s - loss: 0.0279 - recall_16: 0.9467\n",
      "Epoch 816/1000\n",
      " - 1s - loss: 0.0278 - recall_16: 0.9540\n",
      "Epoch 817/1000\n",
      " - 1s - loss: 0.0272 - recall_16: 0.9516\n",
      "Epoch 818/1000\n",
      " - 1s - loss: 0.0274 - recall_16: 0.9492\n",
      "Epoch 819/1000\n",
      " - 1s - loss: 0.0284 - recall_16: 0.9419\n",
      "Epoch 820/1000\n",
      " - 1s - loss: 0.0280 - recall_16: 0.9467\n",
      "Epoch 821/1000\n",
      " - 1s - loss: 0.0269 - recall_16: 0.9516\n",
      "Epoch 822/1000\n",
      " - 1s - loss: 0.0311 - recall_16: 0.9419\n",
      "Epoch 823/1000\n",
      " - 1s - loss: 0.0249 - recall_16: 0.9516\n",
      "Epoch 824/1000\n",
      " - 1s - loss: 0.0272 - recall_16: 0.9516\n",
      "Epoch 825/1000\n",
      " - 1s - loss: 0.0248 - recall_16: 0.9564\n",
      "Epoch 826/1000\n",
      " - 1s - loss: 0.0297 - recall_16: 0.9419\n",
      "Epoch 827/1000\n",
      " - 1s - loss: 0.0264 - recall_16: 0.9492\n",
      "Epoch 828/1000\n",
      " - 1s - loss: 0.0276 - recall_16: 0.9467\n",
      "Epoch 829/1000\n",
      " - 1s - loss: 0.0304 - recall_16: 0.9443\n",
      "Epoch 830/1000\n",
      " - 1s - loss: 0.0271 - recall_16: 0.9492\n",
      "Epoch 831/1000\n",
      " - 1s - loss: 0.0282 - recall_16: 0.9492\n",
      "Epoch 832/1000\n",
      " - 1s - loss: 0.0278 - recall_16: 0.9540\n",
      "Epoch 833/1000\n",
      " - 1s - loss: 0.0270 - recall_16: 0.9492\n",
      "Epoch 834/1000\n",
      " - 1s - loss: 0.0257 - recall_16: 0.9467\n",
      "Epoch 835/1000\n",
      " - 1s - loss: 0.0284 - recall_16: 0.9443\n",
      "Epoch 836/1000\n",
      " - 1s - loss: 0.0264 - recall_16: 0.9516\n",
      "Epoch 837/1000\n",
      " - 1s - loss: 0.0256 - recall_16: 0.9516\n",
      "Epoch 838/1000\n",
      " - 1s - loss: 0.0259 - recall_16: 0.9540\n",
      "Epoch 839/1000\n",
      " - 1s - loss: 0.0263 - recall_16: 0.9443\n",
      "Epoch 840/1000\n",
      " - 1s - loss: 0.0275 - recall_16: 0.9419\n",
      "Epoch 841/1000\n",
      " - 1s - loss: 0.0264 - recall_16: 0.9492\n",
      "Epoch 842/1000\n",
      " - 1s - loss: 0.0288 - recall_16: 0.9419\n",
      "Epoch 843/1000\n",
      " - 1s - loss: 0.0280 - recall_16: 0.9492\n",
      "Epoch 844/1000\n",
      " - 1s - loss: 0.0265 - recall_16: 0.9564\n",
      "Epoch 845/1000\n",
      " - 1s - loss: 0.0272 - recall_16: 0.9492\n",
      "Epoch 846/1000\n",
      " - 1s - loss: 0.0292 - recall_16: 0.9492\n",
      "Epoch 847/1000\n",
      " - 1s - loss: 0.0283 - recall_16: 0.9443\n",
      "Epoch 848/1000\n",
      " - 1s - loss: 0.0261 - recall_16: 0.9516\n",
      "Epoch 849/1000\n",
      " - 1s - loss: 0.0267 - recall_16: 0.9467\n",
      "Epoch 850/1000\n",
      " - 1s - loss: 0.0271 - recall_16: 0.9540\n",
      "Epoch 851/1000\n",
      " - 1s - loss: 0.0264 - recall_16: 0.9467\n",
      "Epoch 852/1000\n",
      " - 1s - loss: 0.0278 - recall_16: 0.9467\n",
      "Epoch 853/1000\n",
      " - 1s - loss: 0.0290 - recall_16: 0.9443\n",
      "Epoch 854/1000\n",
      " - 1s - loss: 0.0318 - recall_16: 0.9419\n",
      "Epoch 855/1000\n",
      " - 1s - loss: 0.0265 - recall_16: 0.9516\n",
      "Epoch 856/1000\n",
      " - 1s - loss: 0.0264 - recall_16: 0.9467\n",
      "Epoch 857/1000\n",
      " - 1s - loss: 0.0307 - recall_16: 0.9346\n",
      "Epoch 858/1000\n",
      " - 1s - loss: 0.0267 - recall_16: 0.9467\n",
      "Epoch 859/1000\n",
      " - 1s - loss: 0.0255 - recall_16: 0.9564\n",
      "Epoch 860/1000\n",
      " - 1s - loss: 0.0248 - recall_16: 0.9516\n",
      "Epoch 861/1000\n",
      " - 1s - loss: 0.0287 - recall_16: 0.9467\n",
      "Epoch 862/1000\n",
      " - 1s - loss: 0.0262 - recall_16: 0.9540\n",
      "Epoch 863/1000\n",
      " - 1s - loss: 0.0256 - recall_16: 0.9419\n",
      "Epoch 864/1000\n",
      " - 1s - loss: 0.0259 - recall_16: 0.9516\n",
      "Epoch 865/1000\n",
      " - 1s - loss: 0.0268 - recall_16: 0.9492\n",
      "Epoch 866/1000\n",
      " - 1s - loss: 0.0239 - recall_16: 0.9516\n",
      "Epoch 867/1000\n",
      " - 1s - loss: 0.0266 - recall_16: 0.9492\n",
      "Epoch 868/1000\n",
      " - 1s - loss: 0.0303 - recall_16: 0.9395\n",
      "Epoch 869/1000\n",
      " - 1s - loss: 0.0296 - recall_16: 0.9443\n",
      "Epoch 870/1000\n",
      " - 1s - loss: 0.0228 - recall_16: 0.9588\n",
      "Epoch 871/1000\n",
      " - 1s - loss: 0.0271 - recall_16: 0.9467\n",
      "Epoch 872/1000\n",
      " - 1s - loss: 0.0268 - recall_16: 0.9492\n",
      "Epoch 873/1000\n",
      " - 1s - loss: 0.0291 - recall_16: 0.9443\n",
      "Epoch 874/1000\n",
      " - 1s - loss: 0.0237 - recall_16: 0.9540\n",
      "Epoch 875/1000\n",
      " - 1s - loss: 0.0247 - recall_16: 0.9516\n",
      "Epoch 876/1000\n",
      " - 1s - loss: 0.0251 - recall_16: 0.9516\n",
      "Epoch 877/1000\n",
      " - 1s - loss: 0.0291 - recall_16: 0.9467\n",
      "Epoch 878/1000\n",
      " - 1s - loss: 0.0287 - recall_16: 0.9443\n",
      "Epoch 879/1000\n",
      " - 1s - loss: 0.0292 - recall_16: 0.9395\n",
      "Epoch 880/1000\n",
      " - 1s - loss: 0.0253 - recall_16: 0.9540\n",
      "Epoch 881/1000\n",
      " - 1s - loss: 0.0253 - recall_16: 0.9492\n",
      "Epoch 882/1000\n",
      " - 1s - loss: 0.0261 - recall_16: 0.9516\n",
      "Epoch 883/1000\n",
      " - 1s - loss: 0.0236 - recall_16: 0.9564\n",
      "Epoch 884/1000\n",
      " - 1s - loss: 0.0313 - recall_16: 0.9419\n",
      "Epoch 885/1000\n",
      " - 1s - loss: 0.0266 - recall_16: 0.9588\n",
      "Epoch 886/1000\n",
      " - 1s - loss: 0.0249 - recall_16: 0.9516\n",
      "Epoch 887/1000\n",
      " - 1s - loss: 0.0265 - recall_16: 0.9492\n",
      "Epoch 888/1000\n",
      " - 1s - loss: 0.0300 - recall_16: 0.9346\n",
      "Epoch 889/1000\n",
      " - 1s - loss: 0.0275 - recall_16: 0.9443\n",
      "Epoch 890/1000\n",
      " - 1s - loss: 0.0249 - recall_16: 0.9516\n",
      "Epoch 891/1000\n",
      " - 1s - loss: 0.0305 - recall_16: 0.9346\n",
      "Epoch 892/1000\n",
      " - 1s - loss: 0.0277 - recall_16: 0.9443\n",
      "Epoch 893/1000\n",
      " - 1s - loss: 0.0275 - recall_16: 0.9540\n",
      "Epoch 894/1000\n",
      " - 1s - loss: 0.0261 - recall_16: 0.9516\n",
      "Epoch 895/1000\n",
      " - 1s - loss: 0.0244 - recall_16: 0.9516\n",
      "Epoch 896/1000\n",
      " - 1s - loss: 0.0268 - recall_16: 0.9443\n",
      "Epoch 897/1000\n",
      " - 1s - loss: 0.0267 - recall_16: 0.9467\n",
      "Epoch 898/1000\n",
      " - 1s - loss: 0.0294 - recall_16: 0.9443\n",
      "Epoch 899/1000\n",
      " - 1s - loss: 0.0311 - recall_16: 0.9370\n",
      "Epoch 900/1000\n",
      " - 1s - loss: 0.0290 - recall_16: 0.9492\n",
      "Epoch 901/1000\n",
      " - 1s - loss: 0.0269 - recall_16: 0.9516\n",
      "Epoch 902/1000\n",
      " - 1s - loss: 0.0317 - recall_16: 0.9370\n",
      "Epoch 903/1000\n",
      " - 1s - loss: 0.0301 - recall_16: 0.9492\n",
      "Epoch 904/1000\n",
      " - 1s - loss: 0.0276 - recall_16: 0.9492\n",
      "Epoch 905/1000\n",
      " - 1s - loss: 0.0272 - recall_16: 0.9419\n",
      "Epoch 906/1000\n",
      " - 1s - loss: 0.0261 - recall_16: 0.9516\n",
      "Epoch 907/1000\n",
      " - 1s - loss: 0.0263 - recall_16: 0.9516\n",
      "Epoch 908/1000\n",
      " - 1s - loss: 0.0247 - recall_16: 0.9540\n",
      "Epoch 909/1000\n",
      " - 1s - loss: 0.0281 - recall_16: 0.9540\n",
      "Epoch 910/1000\n",
      " - 1s - loss: 0.0242 - recall_16: 0.9540\n",
      "Epoch 911/1000\n",
      " - 1s - loss: 0.0271 - recall_16: 0.9467\n",
      "Epoch 912/1000\n",
      " - 1s - loss: 0.0269 - recall_16: 0.9467\n",
      "Epoch 913/1000\n",
      " - 1s - loss: 0.0274 - recall_16: 0.9540\n",
      "Epoch 914/1000\n",
      " - 1s - loss: 0.0259 - recall_16: 0.9516\n",
      "Epoch 915/1000\n",
      " - 1s - loss: 0.0283 - recall_16: 0.9395\n",
      "Epoch 916/1000\n",
      " - 1s - loss: 0.0265 - recall_16: 0.9588\n",
      "Epoch 917/1000\n",
      " - 1s - loss: 0.0302 - recall_16: 0.9419\n",
      "Epoch 918/1000\n",
      " - 1s - loss: 0.0278 - recall_16: 0.9467\n",
      "Epoch 919/1000\n",
      " - 1s - loss: 0.0246 - recall_16: 0.9564\n",
      "Epoch 920/1000\n",
      " - 1s - loss: 0.0251 - recall_16: 0.9540\n",
      "Epoch 921/1000\n",
      " - 1s - loss: 0.0233 - recall_16: 0.9588\n",
      "Epoch 922/1000\n",
      " - 1s - loss: 0.0248 - recall_16: 0.9516\n",
      "Epoch 923/1000\n",
      " - 1s - loss: 0.0286 - recall_16: 0.9492\n",
      "Epoch 924/1000\n",
      " - 1s - loss: 0.0268 - recall_16: 0.9443\n",
      "Epoch 925/1000\n",
      " - 1s - loss: 0.0260 - recall_16: 0.9564\n",
      "Epoch 926/1000\n",
      " - 1s - loss: 0.0268 - recall_16: 0.9492\n",
      "Epoch 927/1000\n",
      " - 1s - loss: 0.0261 - recall_16: 0.9516\n",
      "Epoch 928/1000\n",
      " - 1s - loss: 0.0235 - recall_16: 0.9613\n",
      "Epoch 929/1000\n",
      " - 1s - loss: 0.0266 - recall_16: 0.9492\n",
      "Epoch 930/1000\n",
      " - 1s - loss: 0.0255 - recall_16: 0.9540\n",
      "Epoch 931/1000\n",
      " - 1s - loss: 0.0269 - recall_16: 0.9492\n",
      "Epoch 932/1000\n",
      " - 1s - loss: 0.0259 - recall_16: 0.9516\n",
      "Epoch 933/1000\n",
      " - 1s - loss: 0.0271 - recall_16: 0.9443\n",
      "Epoch 934/1000\n",
      " - 1s - loss: 0.0268 - recall_16: 0.9467\n",
      "Epoch 935/1000\n",
      " - 1s - loss: 0.0276 - recall_16: 0.9443\n",
      "Epoch 936/1000\n",
      " - 1s - loss: 0.0309 - recall_16: 0.9322\n",
      "Epoch 937/1000\n",
      " - 1s - loss: 0.0297 - recall_16: 0.9467\n",
      "Epoch 938/1000\n",
      " - 1s - loss: 0.0281 - recall_16: 0.9467\n",
      "Epoch 939/1000\n",
      " - 1s - loss: 0.0275 - recall_16: 0.9516\n",
      "Epoch 940/1000\n",
      " - 1s - loss: 0.0249 - recall_16: 0.9492\n",
      "Epoch 941/1000\n",
      " - 1s - loss: 0.0286 - recall_16: 0.9467\n",
      "Epoch 942/1000\n",
      " - 1s - loss: 0.0269 - recall_16: 0.9443\n",
      "Epoch 943/1000\n",
      " - 1s - loss: 0.0266 - recall_16: 0.9443\n",
      "Epoch 944/1000\n",
      " - 1s - loss: 0.0237 - recall_16: 0.9564\n",
      "Epoch 945/1000\n",
      " - 1s - loss: 0.0240 - recall_16: 0.9492\n",
      "Epoch 946/1000\n",
      " - 1s - loss: 0.0277 - recall_16: 0.9467\n",
      "Epoch 947/1000\n",
      " - 1s - loss: 0.0247 - recall_16: 0.9467\n",
      "Epoch 948/1000\n",
      " - 1s - loss: 0.0265 - recall_16: 0.9443\n",
      "Epoch 949/1000\n",
      " - 1s - loss: 0.0268 - recall_16: 0.9443\n",
      "Epoch 950/1000\n",
      " - 1s - loss: 0.0281 - recall_16: 0.9443\n",
      "Epoch 951/1000\n",
      " - 1s - loss: 0.0267 - recall_16: 0.9516\n",
      "Epoch 952/1000\n",
      " - 1s - loss: 0.0261 - recall_16: 0.9492\n",
      "Epoch 953/1000\n",
      " - 1s - loss: 0.0264 - recall_16: 0.9516\n",
      "Epoch 954/1000\n",
      " - 1s - loss: 0.0246 - recall_16: 0.9564\n",
      "Epoch 955/1000\n",
      " - 1s - loss: 0.0267 - recall_16: 0.9516\n",
      "Epoch 956/1000\n",
      " - 1s - loss: 0.0250 - recall_16: 0.9540\n",
      "Epoch 957/1000\n",
      " - 1s - loss: 0.0234 - recall_16: 0.9564\n",
      "Epoch 958/1000\n",
      " - 1s - loss: 0.0292 - recall_16: 0.9419\n",
      "Epoch 959/1000\n",
      " - 1s - loss: 0.0277 - recall_16: 0.9540\n",
      "Epoch 960/1000\n",
      " - 1s - loss: 0.0273 - recall_16: 0.9443\n",
      "Epoch 961/1000\n",
      " - 1s - loss: 0.0252 - recall_16: 0.9540\n",
      "Epoch 962/1000\n",
      " - 1s - loss: 0.0266 - recall_16: 0.9419\n",
      "Epoch 963/1000\n",
      " - 1s - loss: 0.0288 - recall_16: 0.9492\n",
      "Epoch 964/1000\n",
      " - 1s - loss: 0.0264 - recall_16: 0.9467\n",
      "Epoch 965/1000\n",
      " - 1s - loss: 0.0295 - recall_16: 0.9467\n",
      "Epoch 966/1000\n",
      " - 1s - loss: 0.0246 - recall_16: 0.9564\n",
      "Epoch 967/1000\n",
      " - 1s - loss: 0.0261 - recall_16: 0.9540\n",
      "Epoch 968/1000\n",
      " - 1s - loss: 0.0282 - recall_16: 0.9467\n",
      "Epoch 969/1000\n",
      " - 1s - loss: 0.0300 - recall_16: 0.9467\n",
      "Epoch 970/1000\n",
      " - 1s - loss: 0.0248 - recall_16: 0.9540\n",
      "Epoch 971/1000\n",
      " - 1s - loss: 0.0287 - recall_16: 0.9492\n",
      "Epoch 972/1000\n",
      " - 1s - loss: 0.0263 - recall_16: 0.9516\n",
      "Epoch 973/1000\n",
      " - 1s - loss: 0.0271 - recall_16: 0.9516\n",
      "Epoch 974/1000\n",
      " - 1s - loss: 0.0250 - recall_16: 0.9564\n",
      "Epoch 975/1000\n",
      " - 1s - loss: 0.0272 - recall_16: 0.9492\n",
      "Epoch 976/1000\n",
      " - 1s - loss: 0.0265 - recall_16: 0.9516\n",
      "Epoch 977/1000\n",
      " - 1s - loss: 0.0308 - recall_16: 0.9395\n",
      "Epoch 978/1000\n",
      " - 1s - loss: 0.0281 - recall_16: 0.9492\n",
      "Epoch 979/1000\n",
      " - 1s - loss: 0.0249 - recall_16: 0.9540\n",
      "Epoch 980/1000\n",
      " - 1s - loss: 0.0265 - recall_16: 0.9443\n",
      "Epoch 981/1000\n",
      " - 1s - loss: 0.0279 - recall_16: 0.9492\n",
      "Epoch 982/1000\n",
      " - 1s - loss: 0.0229 - recall_16: 0.9588\n",
      "Epoch 983/1000\n",
      " - 1s - loss: 0.0284 - recall_16: 0.9443\n",
      "Epoch 984/1000\n",
      " - 1s - loss: 0.0300 - recall_16: 0.9419\n",
      "Epoch 985/1000\n",
      " - 1s - loss: 0.0249 - recall_16: 0.9564\n",
      "Epoch 986/1000\n",
      " - 1s - loss: 0.0252 - recall_16: 0.9613\n",
      "Epoch 987/1000\n",
      " - 1s - loss: 0.0255 - recall_16: 0.9564\n",
      "Epoch 988/1000\n",
      " - 1s - loss: 0.0279 - recall_16: 0.9516\n",
      "Epoch 989/1000\n",
      " - 1s - loss: 0.0270 - recall_16: 0.9467\n",
      "Epoch 990/1000\n",
      " - 1s - loss: 0.0230 - recall_16: 0.9564\n",
      "Epoch 991/1000\n",
      " - 1s - loss: 0.0262 - recall_16: 0.9516\n",
      "Epoch 992/1000\n",
      " - 1s - loss: 0.0269 - recall_16: 0.9492\n",
      "Epoch 993/1000\n",
      " - 1s - loss: 0.0250 - recall_16: 0.9492\n",
      "Epoch 994/1000\n",
      " - 1s - loss: 0.0267 - recall_16: 0.9540\n",
      "Epoch 995/1000\n",
      " - 1s - loss: 0.0266 - recall_16: 0.9467\n",
      "Epoch 996/1000\n",
      " - 1s - loss: 0.0287 - recall_16: 0.9467\n",
      "Epoch 997/1000\n",
      " - 1s - loss: 0.0245 - recall_16: 0.9516\n",
      "Epoch 998/1000\n",
      " - 1s - loss: 0.0253 - recall_16: 0.9492\n",
      "Epoch 999/1000\n",
      " - 1s - loss: 0.0231 - recall_16: 0.9540\n",
      "Epoch 1000/1000\n",
      " - 1s - loss: 0.0279 - recall_16: 0.9492\n",
      "score: [0.013902985512387415, 0.9863013625144958]\n"
     ]
    }
   ],
   "source": [
    "# Train the model here\n",
    "\n",
    "model = alex()   # alex(), nvidia_model(), leNet()\n",
    "\n",
    "# 9. Fit model on training data\n",
    "history_mask = model.fit(X_train, Y_train, batch_size = 64, epochs=1000, verbose=2)\n",
    "\n",
    "\n",
    "# 10. Evaluate model on test data\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "print(\"score: \"+str(score))\n",
    "\n",
    "#model.save('my_modelDec17_sign_best.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "lines_to_next_cell": 2,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training accuracy or recall\n",
    "plt.plot(history_mask.history['recall_16'])\n",
    "#plt.title('Training set Recall')\n",
    "#plt.ylabel('Recall')\n",
    "#plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.5",
    "jupytext_version": "1.3.0"
   }
  },
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
